[ Thu Jan  9 21:54:13 2025 ] using warm up, epoch: 25
[ Thu Jan  9 21:54:14 2025 ] Parameters:
{'work_dir': './output/original_48_newPE/', 'model_saved_name': './output/original_48_newPE/runs', 'config': './config/SkateFormer_newPE_j_NEW.yaml', 'weights': None, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ma52_NEW.Feeder', 'num_worker': 6, 'train_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'train', 'data_type': 'j', 'repeat': 10, 'p': 0.5, 'debug': False, 'partition': True}, 'test_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'val', 'data_type': 'j', 'repeat': 1, 'partition': True}, 'model': 'model.SkateFormer_newPE.SkateFormer_', 'model_args': {'in_channels': 2, 'num_classes': 52, 'num_people': 1, 'num_points': 48, 'kernel_size': 7, 'num_heads': 32, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.2, 'type_1_size': [8, 12], 'type_2_size': [8, 24], 'type_3_size': [8, 12], 'type_4_size': [8, 24], 'mlp_ratio': 1.0, 'index_t': True}, 'ignore_weights': [], 'base_lr': 0.001, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 25, 'grad_clip': True, 'grad_max': 1.0, 'device': [0], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 48, 'test_batch_size': 48, 'start_epoch': 0, 'num_epoch': 100, 'weight_decay': 0.1, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Thu Jan  9 21:54:14 2025 ] # Parameters: 2587198
[ Thu Jan  9 21:54:14 2025 ] Training epoch: 1
[ Thu Jan  9 21:54:41 2025 ] using warm up, epoch: 25
[ Thu Jan  9 21:54:42 2025 ] Parameters:
{'work_dir': './output/original_48_newPE/', 'model_saved_name': './output/original_48_newPE/runs', 'config': './config/SkateFormer_newPE_j_NEW.yaml', 'weights': None, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ma52_NEW.Feeder', 'num_worker': 6, 'train_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'train', 'data_type': 'j', 'repeat': 10, 'p': 0.5, 'debug': False, 'partition': True}, 'test_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'val', 'data_type': 'j', 'repeat': 1, 'partition': True}, 'model': 'model.SkateFormer_newPE.SkateFormer_', 'model_args': {'in_channels': 2, 'num_classes': 52, 'num_people': 1, 'num_points': 48, 'kernel_size': 7, 'num_heads': 32, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.2, 'type_1_size': [8, 12], 'type_2_size': [8, 24], 'type_3_size': [8, 12], 'type_4_size': [8, 24], 'mlp_ratio': 1.0, 'index_t': True}, 'ignore_weights': [], 'base_lr': 0.001, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 25, 'grad_clip': True, 'grad_max': 1.0, 'device': [0, 1, 2, 3], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 288, 'test_batch_size': 288, 'start_epoch': 0, 'num_epoch': 100, 'weight_decay': 0.1, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Thu Jan  9 21:54:42 2025 ] # Parameters: 2587198
[ Thu Jan  9 21:54:42 2025 ] Training epoch: 1
[ Thu Jan  9 21:57:20 2025 ] 	Mean training loss: 3.7018.  Mean training acc: 9.20%.
[ Thu Jan  9 21:57:20 2025 ] 	Learning Rate: 0.00003999
[ Thu Jan  9 21:57:20 2025 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jan  9 21:57:20 2025 ] Eval epoch: 1
[ Thu Jan  9 21:57:28 2025 ] 	Mean test loss of 20 batches: 3.450336253643036.
[ Thu Jan  9 21:57:28 2025 ] 	Top1: 11.73%
[ Thu Jan  9 21:57:28 2025 ] 	Top5: 42.25%
[ Thu Jan  9 21:57:28 2025 ] Training epoch: 2
[ Thu Jan  9 21:59:56 2025 ] 	Mean training loss: 3.3692.  Mean training acc: 13.06%.
[ Thu Jan  9 21:59:56 2025 ] 	Learning Rate: 0.00007999
[ Thu Jan  9 21:59:56 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 21:59:56 2025 ] Eval epoch: 2
[ Thu Jan  9 22:00:02 2025 ] 	Mean test loss of 20 batches: 3.481613564491272.
[ Thu Jan  9 22:00:02 2025 ] 	Top1: 10.58%
[ Thu Jan  9 22:00:02 2025 ] 	Top5: 43.04%
[ Thu Jan  9 22:00:02 2025 ] Training epoch: 3
[ Thu Jan  9 22:02:29 2025 ] 	Mean training loss: 3.1583.  Mean training acc: 17.22%.
[ Thu Jan  9 22:02:29 2025 ] 	Learning Rate: 0.00011999
[ Thu Jan  9 22:02:29 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:02:29 2025 ] Eval epoch: 3
[ Thu Jan  9 22:02:35 2025 ] 	Mean test loss of 20 batches: 3.0007266998291016.
[ Thu Jan  9 22:02:36 2025 ] 	Top1: 19.51%
[ Thu Jan  9 22:02:36 2025 ] 	Top5: 59.15%
[ Thu Jan  9 22:02:36 2025 ] Training epoch: 4
[ Thu Jan  9 22:05:02 2025 ] 	Mean training loss: 2.9769.  Mean training acc: 21.44%.
[ Thu Jan  9 22:05:02 2025 ] 	Learning Rate: 0.00015998
[ Thu Jan  9 22:05:02 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:05:02 2025 ] Eval epoch: 4
[ Thu Jan  9 22:05:09 2025 ] 	Mean test loss of 20 batches: 3.1995455741882326.
[ Thu Jan  9 22:05:09 2025 ] 	Top1: 15.02%
[ Thu Jan  9 22:05:09 2025 ] 	Top5: 53.94%
[ Thu Jan  9 22:05:09 2025 ] Training epoch: 5
[ Thu Jan  9 22:07:36 2025 ] 	Mean training loss: 2.8354.  Mean training acc: 25.79%.
[ Thu Jan  9 22:07:36 2025 ] 	Learning Rate: 0.00019998
[ Thu Jan  9 22:07:36 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:07:36 2025 ] Eval epoch: 5
[ Thu Jan  9 22:07:43 2025 ] 	Mean test loss of 20 batches: 2.6656004428863525.
[ Thu Jan  9 22:07:43 2025 ] 	Top1: 30.84%
[ Thu Jan  9 22:07:43 2025 ] 	Top5: 71.70%
[ Thu Jan  9 22:07:43 2025 ] Training epoch: 6
[ Thu Jan  9 22:10:10 2025 ] 	Mean training loss: 2.7122.  Mean training acc: 29.76%.
[ Thu Jan  9 22:10:10 2025 ] 	Learning Rate: 0.00023997
[ Thu Jan  9 22:10:10 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:10:10 2025 ] Eval epoch: 6
[ Thu Jan  9 22:10:16 2025 ] 	Mean test loss of 20 batches: 2.5498847484588625.
[ Thu Jan  9 22:10:16 2025 ] 	Top1: 36.61%
[ Thu Jan  9 22:10:17 2025 ] 	Top5: 74.87%
[ Thu Jan  9 22:10:17 2025 ] Training epoch: 7
[ Thu Jan  9 22:12:44 2025 ] 	Mean training loss: 2.5791.  Mean training acc: 34.48%.
[ Thu Jan  9 22:12:44 2025 ] 	Learning Rate: 0.00027997
[ Thu Jan  9 22:12:44 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:12:44 2025 ] Eval epoch: 7
[ Thu Jan  9 22:12:50 2025 ] 	Mean test loss of 20 batches: 2.3824582576751707.
[ Thu Jan  9 22:12:50 2025 ] 	Top1: 42.32%
[ Thu Jan  9 22:12:50 2025 ] 	Top5: 79.34%
[ Thu Jan  9 22:12:50 2025 ] Training epoch: 8
[ Thu Jan  9 22:15:19 2025 ] 	Mean training loss: 2.4462.  Mean training acc: 39.08%.
[ Thu Jan  9 22:15:19 2025 ] 	Learning Rate: 0.00031997
[ Thu Jan  9 22:15:19 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Jan  9 22:15:19 2025 ] Eval epoch: 8
[ Thu Jan  9 22:15:26 2025 ] 	Mean test loss of 20 batches: 2.3307241916656496.
[ Thu Jan  9 22:15:26 2025 ] 	Top1: 45.26%
[ Thu Jan  9 22:15:26 2025 ] 	Top5: 81.04%
[ Thu Jan  9 22:15:26 2025 ] Training epoch: 9
[ Thu Jan  9 22:17:54 2025 ] 	Mean training loss: 2.3262.  Mean training acc: 43.38%.
[ Thu Jan  9 22:17:54 2025 ] 	Learning Rate: 0.00035996
[ Thu Jan  9 22:17:54 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:17:54 2025 ] Eval epoch: 9
[ Thu Jan  9 22:18:00 2025 ] 	Mean test loss of 20 batches: 2.1882608413696287.
[ Thu Jan  9 22:18:00 2025 ] 	Top1: 49.30%
[ Thu Jan  9 22:18:00 2025 ] 	Top5: 83.46%
[ Thu Jan  9 22:18:00 2025 ] Training epoch: 10
[ Thu Jan  9 22:20:27 2025 ] 	Mean training loss: 2.2223.  Mean training acc: 46.83%.
[ Thu Jan  9 22:20:27 2025 ] 	Learning Rate: 0.00039996
[ Thu Jan  9 22:20:27 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:20:27 2025 ] Eval epoch: 10
[ Thu Jan  9 22:20:33 2025 ] 	Mean test loss of 20 batches: 2.105673056840897.
[ Thu Jan  9 22:20:33 2025 ] 	Top1: 52.54%
[ Thu Jan  9 22:20:33 2025 ] 	Top5: 85.46%
[ Thu Jan  9 22:20:33 2025 ] Training epoch: 11
[ Thu Jan  9 22:23:00 2025 ] 	Mean training loss: 2.1276.  Mean training acc: 50.09%.
[ Thu Jan  9 22:23:00 2025 ] 	Learning Rate: 0.00043995
[ Thu Jan  9 22:23:00 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:23:00 2025 ] Eval epoch: 11
[ Thu Jan  9 22:23:07 2025 ] 	Mean test loss of 20 batches: 2.0602988481521605.
[ Thu Jan  9 22:23:07 2025 ] 	Top1: 53.99%
[ Thu Jan  9 22:23:07 2025 ] 	Top5: 85.68%
[ Thu Jan  9 22:23:07 2025 ] Training epoch: 12
[ Thu Jan  9 22:25:34 2025 ] 	Mean training loss: 2.0451.  Mean training acc: 53.16%.
[ Thu Jan  9 22:25:34 2025 ] 	Learning Rate: 0.00047995
[ Thu Jan  9 22:25:34 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:25:34 2025 ] Eval epoch: 12
[ Thu Jan  9 22:25:40 2025 ] 	Mean test loss of 20 batches: 2.066921716928482.
[ Thu Jan  9 22:25:40 2025 ] 	Top1: 54.22%
[ Thu Jan  9 22:25:40 2025 ] 	Top5: 85.54%
[ Thu Jan  9 22:25:40 2025 ] Training epoch: 13
[ Thu Jan  9 22:28:07 2025 ] 	Mean training loss: 1.9813.  Mean training acc: 55.36%.
[ Thu Jan  9 22:28:07 2025 ] 	Learning Rate: 0.00051995
[ Thu Jan  9 22:28:07 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:28:07 2025 ] Eval epoch: 13
[ Thu Jan  9 22:28:14 2025 ] 	Mean test loss of 20 batches: 2.0551460146903993.
[ Thu Jan  9 22:28:14 2025 ] 	Top1: 55.59%
[ Thu Jan  9 22:28:14 2025 ] 	Top5: 86.00%
[ Thu Jan  9 22:28:14 2025 ] Training epoch: 14
[ Thu Jan  9 22:30:41 2025 ] 	Mean training loss: 1.9059.  Mean training acc: 57.88%.
[ Thu Jan  9 22:30:41 2025 ] 	Learning Rate: 0.00055994
[ Thu Jan  9 22:30:41 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:30:41 2025 ] Eval epoch: 14
[ Thu Jan  9 22:30:47 2025 ] 	Mean test loss of 20 batches: 2.0689919114112856.
[ Thu Jan  9 22:30:47 2025 ] 	Top1: 54.99%
[ Thu Jan  9 22:30:47 2025 ] 	Top5: 86.09%
[ Thu Jan  9 22:30:47 2025 ] Training epoch: 15
[ Thu Jan  9 22:33:16 2025 ] 	Mean training loss: 1.8455.  Mean training acc: 60.13%.
[ Thu Jan  9 22:33:16 2025 ] 	Learning Rate: 0.00059994
[ Thu Jan  9 22:33:16 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:33:16 2025 ] Eval epoch: 15
[ Thu Jan  9 22:33:22 2025 ] 	Mean test loss of 20 batches: 2.067648947238922.
[ Thu Jan  9 22:33:22 2025 ] 	Top1: 56.25%
[ Thu Jan  9 22:33:22 2025 ] 	Top5: 86.31%
[ Thu Jan  9 22:33:22 2025 ] Training epoch: 16
[ Thu Jan  9 22:35:49 2025 ] 	Mean training loss: 1.7907.  Mean training acc: 61.88%.
[ Thu Jan  9 22:35:49 2025 ] 	Learning Rate: 0.00063993
[ Thu Jan  9 22:35:49 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:35:49 2025 ] Eval epoch: 16
[ Thu Jan  9 22:35:56 2025 ] 	Mean test loss of 20 batches: 2.0540496945381164.
[ Thu Jan  9 22:35:56 2025 ] 	Top1: 56.16%
[ Thu Jan  9 22:35:56 2025 ] 	Top5: 86.54%
[ Thu Jan  9 22:35:56 2025 ] Training epoch: 17
[ Thu Jan  9 22:38:23 2025 ] 	Mean training loss: 1.7380.  Mean training acc: 63.95%.
[ Thu Jan  9 22:38:23 2025 ] 	Learning Rate: 0.00067993
[ Thu Jan  9 22:38:23 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:38:23 2025 ] Eval epoch: 17
[ Thu Jan  9 22:38:29 2025 ] 	Mean test loss of 20 batches: 2.054908788204193.
[ Thu Jan  9 22:38:29 2025 ] 	Top1: 56.64%
[ Thu Jan  9 22:38:29 2025 ] 	Top5: 87.04%
[ Thu Jan  9 22:38:29 2025 ] Training epoch: 18
[ Thu Jan  9 22:40:56 2025 ] 	Mean training loss: 1.6863.  Mean training acc: 65.92%.
[ Thu Jan  9 22:40:56 2025 ] 	Learning Rate: 0.00071993
[ Thu Jan  9 22:40:56 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:40:56 2025 ] Eval epoch: 18
[ Thu Jan  9 22:41:03 2025 ] 	Mean test loss of 20 batches: 2.064728718996048.
[ Thu Jan  9 22:41:03 2025 ] 	Top1: 56.23%
[ Thu Jan  9 22:41:03 2025 ] 	Top5: 87.09%
[ Thu Jan  9 22:41:03 2025 ] Training epoch: 19
[ Thu Jan  9 22:43:30 2025 ] 	Mean training loss: 1.6406.  Mean training acc: 67.66%.
[ Thu Jan  9 22:43:30 2025 ] 	Learning Rate: 0.00075992
[ Thu Jan  9 22:43:30 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:43:30 2025 ] Eval epoch: 19
[ Thu Jan  9 22:43:37 2025 ] 	Mean test loss of 20 batches: 2.106946438550949.
[ Thu Jan  9 22:43:37 2025 ] 	Top1: 56.23%
[ Thu Jan  9 22:43:37 2025 ] 	Top5: 85.91%
[ Thu Jan  9 22:43:37 2025 ] Training epoch: 20
[ Thu Jan  9 22:46:03 2025 ] 	Mean training loss: 1.6023.  Mean training acc: 69.02%.
[ Thu Jan  9 22:46:03 2025 ] 	Learning Rate: 0.00079992
[ Thu Jan  9 22:46:03 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:46:03 2025 ] Eval epoch: 20
[ Thu Jan  9 22:46:10 2025 ] 	Mean test loss of 20 batches: 2.144193983078003.
[ Thu Jan  9 22:46:10 2025 ] 	Top1: 55.84%
[ Thu Jan  9 22:46:10 2025 ] 	Top5: 85.30%
[ Thu Jan  9 22:46:10 2025 ] Training epoch: 21
[ Thu Jan  9 22:48:37 2025 ] 	Mean training loss: 1.5693.  Mean training acc: 70.40%.
[ Thu Jan  9 22:48:37 2025 ] 	Learning Rate: 0.00083991
[ Thu Jan  9 22:48:37 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:48:37 2025 ] Eval epoch: 21
[ Thu Jan  9 22:48:43 2025 ] 	Mean test loss of 20 batches: 2.1358306646347045.
[ Thu Jan  9 22:48:43 2025 ] 	Top1: 56.44%
[ Thu Jan  9 22:48:43 2025 ] 	Top5: 85.50%
[ Thu Jan  9 22:48:43 2025 ] Training epoch: 22
[ Thu Jan  9 22:51:12 2025 ] 	Mean training loss: 1.5407.  Mean training acc: 71.53%.
[ Thu Jan  9 22:51:12 2025 ] 	Learning Rate: 0.00087991
[ Thu Jan  9 22:51:12 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:51:12 2025 ] Eval epoch: 22
[ Thu Jan  9 22:51:18 2025 ] 	Mean test loss of 20 batches: 2.160906207561493.
[ Thu Jan  9 22:51:19 2025 ] 	Top1: 55.82%
[ Thu Jan  9 22:51:19 2025 ] 	Top5: 85.73%
[ Thu Jan  9 22:51:19 2025 ] Training epoch: 23
[ Thu Jan  9 22:53:45 2025 ] 	Mean training loss: 1.5158.  Mean training acc: 72.45%.
[ Thu Jan  9 22:53:45 2025 ] 	Learning Rate: 0.00091991
[ Thu Jan  9 22:53:45 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:53:45 2025 ] Eval epoch: 23
[ Thu Jan  9 22:53:51 2025 ] 	Mean test loss of 20 batches: 2.166319739818573.
[ Thu Jan  9 22:53:51 2025 ] 	Top1: 55.60%
[ Thu Jan  9 22:53:52 2025 ] 	Top5: 85.45%
[ Thu Jan  9 22:53:52 2025 ] Training epoch: 24
[ Thu Jan  9 22:56:19 2025 ] 	Mean training loss: 1.4871.  Mean training acc: 73.47%.
[ Thu Jan  9 22:56:19 2025 ] 	Learning Rate: 0.00095990
[ Thu Jan  9 22:56:19 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:56:19 2025 ] Eval epoch: 24
[ Thu Jan  9 22:56:25 2025 ] 	Mean test loss of 20 batches: 2.177569770812988.
[ Thu Jan  9 22:56:25 2025 ] 	Top1: 56.50%
[ Thu Jan  9 22:56:25 2025 ] 	Top5: 84.89%
[ Thu Jan  9 22:56:25 2025 ] Training epoch: 25
[ Thu Jan  9 22:58:52 2025 ] 	Mean training loss: 1.4701.  Mean training acc: 74.15%.
[ Thu Jan  9 22:58:52 2025 ] 	Learning Rate: 0.00099990
[ Thu Jan  9 22:58:52 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 22:58:52 2025 ] Eval epoch: 25
[ Thu Jan  9 22:58:59 2025 ] 	Mean test loss of 20 batches: 2.151356118917465.
[ Thu Jan  9 22:58:59 2025 ] 	Top1: 56.16%
[ Thu Jan  9 22:58:59 2025 ] 	Top5: 84.98%
[ Thu Jan  9 22:58:59 2025 ] Training epoch: 26
[ Thu Jan  9 23:01:26 2025 ] 	Mean training loss: 1.3942.  Mean training acc: 77.15%.
[ Thu Jan  9 23:01:26 2025 ] 	Learning Rate: 0.00084388
[ Thu Jan  9 23:01:26 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:01:26 2025 ] Eval epoch: 26
[ Thu Jan  9 23:01:33 2025 ] 	Mean test loss of 20 batches: 2.1318031430244444.
[ Thu Jan  9 23:01:33 2025 ] 	Top1: 57.52%
[ Thu Jan  9 23:01:33 2025 ] 	Top5: 86.04%
[ Thu Jan  9 23:01:33 2025 ] Training epoch: 27
[ Thu Jan  9 23:04:02 2025 ] 	Mean training loss: 1.3564.  Mean training acc: 78.58%.
[ Thu Jan  9 23:04:02 2025 ] 	Learning Rate: 0.00083238
[ Thu Jan  9 23:04:02 2025 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jan  9 23:04:02 2025 ] Eval epoch: 27
[ Thu Jan  9 23:04:09 2025 ] 	Mean test loss of 20 batches: 2.1419467508792875.
[ Thu Jan  9 23:04:09 2025 ] 	Top1: 57.09%
[ Thu Jan  9 23:04:09 2025 ] 	Top5: 85.77%
[ Thu Jan  9 23:04:09 2025 ] Training epoch: 28
[ Thu Jan  9 23:06:37 2025 ] 	Mean training loss: 1.3247.  Mean training acc: 79.78%.
[ Thu Jan  9 23:06:37 2025 ] 	Learning Rate: 0.00082056
[ Thu Jan  9 23:06:37 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:06:37 2025 ] Eval epoch: 28
[ Thu Jan  9 23:06:43 2025 ] 	Mean test loss of 20 batches: 2.168849641084671.
[ Thu Jan  9 23:06:43 2025 ] 	Top1: 55.87%
[ Thu Jan  9 23:06:43 2025 ] 	Top5: 85.43%
[ Thu Jan  9 23:06:43 2025 ] Training epoch: 29
[ Thu Jan  9 23:09:13 2025 ] 	Mean training loss: 1.3021.  Mean training acc: 80.77%.
[ Thu Jan  9 23:09:13 2025 ] 	Learning Rate: 0.00080842
[ Thu Jan  9 23:09:13 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Jan  9 23:09:13 2025 ] Eval epoch: 29
[ Thu Jan  9 23:09:19 2025 ] 	Mean test loss of 20 batches: 2.1591187715530396.
[ Thu Jan  9 23:09:19 2025 ] 	Top1: 57.84%
[ Thu Jan  9 23:09:19 2025 ] 	Top5: 85.52%
[ Thu Jan  9 23:09:19 2025 ] Training epoch: 30
[ Thu Jan  9 23:11:50 2025 ] 	Mean training loss: 1.2760.  Mean training acc: 81.77%.
[ Thu Jan  9 23:11:50 2025 ] 	Learning Rate: 0.00079599
[ Thu Jan  9 23:11:50 2025 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jan  9 23:11:50 2025 ] Eval epoch: 30
[ Thu Jan  9 23:11:56 2025 ] 	Mean test loss of 20 batches: 2.167765313386917.
[ Thu Jan  9 23:11:56 2025 ] 	Top1: 56.95%
[ Thu Jan  9 23:11:56 2025 ] 	Top5: 85.36%
[ Thu Jan  9 23:11:56 2025 ] Training epoch: 31
[ Thu Jan  9 23:14:26 2025 ] 	Mean training loss: 1.2568.  Mean training acc: 82.54%.
[ Thu Jan  9 23:14:26 2025 ] 	Learning Rate: 0.00078326
[ Thu Jan  9 23:14:26 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:14:26 2025 ] Eval epoch: 31
[ Thu Jan  9 23:14:32 2025 ] 	Mean test loss of 20 batches: 2.174654644727707.
[ Thu Jan  9 23:14:33 2025 ] 	Top1: 56.73%
[ Thu Jan  9 23:14:33 2025 ] 	Top5: 84.94%
[ Thu Jan  9 23:14:33 2025 ] Training epoch: 32
[ Thu Jan  9 23:16:59 2025 ] 	Mean training loss: 1.2364.  Mean training acc: 83.29%.
[ Thu Jan  9 23:16:59 2025 ] 	Learning Rate: 0.00077027
[ Thu Jan  9 23:16:59 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:16:59 2025 ] Eval epoch: 32
[ Thu Jan  9 23:17:05 2025 ] 	Mean test loss of 20 batches: 2.1803148567676542.
[ Thu Jan  9 23:17:05 2025 ] 	Top1: 55.96%
[ Thu Jan  9 23:17:05 2025 ] 	Top5: 85.07%
[ Thu Jan  9 23:17:05 2025 ] Training epoch: 33
[ Thu Jan  9 23:19:32 2025 ] 	Mean training loss: 1.2164.  Mean training acc: 84.05%.
[ Thu Jan  9 23:19:32 2025 ] 	Learning Rate: 0.00075701
[ Thu Jan  9 23:19:32 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:19:32 2025 ] Eval epoch: 33
[ Thu Jan  9 23:19:39 2025 ] 	Mean test loss of 20 batches: 2.1866187036037443.
[ Thu Jan  9 23:19:39 2025 ] 	Top1: 56.61%
[ Thu Jan  9 23:19:39 2025 ] 	Top5: 85.11%
[ Thu Jan  9 23:19:39 2025 ] Training epoch: 34
[ Thu Jan  9 23:22:07 2025 ] 	Mean training loss: 1.2038.  Mean training acc: 84.55%.
[ Thu Jan  9 23:22:07 2025 ] 	Learning Rate: 0.00074350
[ Thu Jan  9 23:22:07 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:22:07 2025 ] Eval epoch: 34
[ Thu Jan  9 23:22:14 2025 ] 	Mean test loss of 20 batches: 2.175988054275513.
[ Thu Jan  9 23:22:14 2025 ] 	Top1: 57.54%
[ Thu Jan  9 23:22:14 2025 ] 	Top5: 85.59%
[ Thu Jan  9 23:22:14 2025 ] Training epoch: 35
[ Thu Jan  9 23:24:41 2025 ] 	Mean training loss: 1.1845.  Mean training acc: 85.18%.
[ Thu Jan  9 23:24:41 2025 ] 	Learning Rate: 0.00072976
[ Thu Jan  9 23:24:41 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:24:41 2025 ] Eval epoch: 35
[ Thu Jan  9 23:24:47 2025 ] 	Mean test loss of 20 batches: 2.1885283529758452.
[ Thu Jan  9 23:24:47 2025 ] 	Top1: 57.43%
[ Thu Jan  9 23:24:47 2025 ] 	Top5: 84.82%
[ Thu Jan  9 23:24:47 2025 ] Training epoch: 36
[ Thu Jan  9 23:27:14 2025 ] 	Mean training loss: 1.1714.  Mean training acc: 85.61%.
[ Thu Jan  9 23:27:14 2025 ] 	Learning Rate: 0.00071580
[ Thu Jan  9 23:27:14 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:27:14 2025 ] Eval epoch: 36
[ Thu Jan  9 23:27:20 2025 ] 	Mean test loss of 20 batches: 2.192548614740372.
[ Thu Jan  9 23:27:20 2025 ] 	Top1: 57.30%
[ Thu Jan  9 23:27:20 2025 ] 	Top5: 84.35%
[ Thu Jan  9 23:27:20 2025 ] Training epoch: 37
[ Thu Jan  9 23:29:48 2025 ] 	Mean training loss: 1.1612.  Mean training acc: 86.06%.
[ Thu Jan  9 23:29:48 2025 ] 	Learning Rate: 0.00070162
[ Thu Jan  9 23:29:48 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:29:48 2025 ] Eval epoch: 37
[ Thu Jan  9 23:29:54 2025 ] 	Mean test loss of 20 batches: 2.172058230638504.
[ Thu Jan  9 23:29:54 2025 ] 	Top1: 57.48%
[ Thu Jan  9 23:29:54 2025 ] 	Top5: 84.41%
[ Thu Jan  9 23:29:54 2025 ] Training epoch: 38
[ Thu Jan  9 23:32:21 2025 ] 	Mean training loss: 1.1458.  Mean training acc: 86.53%.
[ Thu Jan  9 23:32:21 2025 ] 	Learning Rate: 0.00068726
[ Thu Jan  9 23:32:21 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:32:21 2025 ] Eval epoch: 38
[ Thu Jan  9 23:32:27 2025 ] 	Mean test loss of 20 batches: 2.201633036136627.
[ Thu Jan  9 23:32:27 2025 ] 	Top1: 56.80%
[ Thu Jan  9 23:32:27 2025 ] 	Top5: 84.66%
[ Thu Jan  9 23:32:27 2025 ] Training epoch: 39
[ Thu Jan  9 23:34:56 2025 ] 	Mean training loss: 1.1276.  Mean training acc: 87.39%.
[ Thu Jan  9 23:34:56 2025 ] 	Learning Rate: 0.00067271
[ Thu Jan  9 23:34:56 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:34:56 2025 ] Eval epoch: 39
[ Thu Jan  9 23:35:03 2025 ] 	Mean test loss of 20 batches: 2.1986307978630064.
[ Thu Jan  9 23:35:03 2025 ] 	Top1: 57.34%
[ Thu Jan  9 23:35:03 2025 ] 	Top5: 84.94%
[ Thu Jan  9 23:35:03 2025 ] Training epoch: 40
[ Thu Jan  9 23:37:33 2025 ] 	Mean training loss: 1.1140.  Mean training acc: 87.74%.
[ Thu Jan  9 23:37:33 2025 ] 	Learning Rate: 0.00065800
[ Thu Jan  9 23:37:33 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Jan  9 23:37:33 2025 ] Eval epoch: 40
[ Thu Jan  9 23:37:39 2025 ] 	Mean test loss of 20 batches: 2.2180580258369447.
[ Thu Jan  9 23:37:39 2025 ] 	Top1: 56.30%
[ Thu Jan  9 23:37:39 2025 ] 	Top5: 84.69%
[ Thu Jan  9 23:37:39 2025 ] Training epoch: 41
[ Thu Jan  9 23:40:09 2025 ] 	Mean training loss: 1.1049.  Mean training acc: 88.08%.
[ Thu Jan  9 23:40:09 2025 ] 	Learning Rate: 0.00064314
[ Thu Jan  9 23:40:09 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Thu Jan  9 23:40:09 2025 ] Eval epoch: 41
[ Thu Jan  9 23:40:17 2025 ] 	Mean test loss of 20 batches: 2.2005638659000395.
[ Thu Jan  9 23:40:17 2025 ] 	Top1: 56.34%
[ Thu Jan  9 23:40:17 2025 ] 	Top5: 84.41%
[ Thu Jan  9 23:40:17 2025 ] Training epoch: 42
[ Thu Jan  9 23:42:46 2025 ] 	Mean training loss: 1.0952.  Mean training acc: 88.49%.
[ Thu Jan  9 23:42:46 2025 ] 	Learning Rate: 0.00062814
[ Thu Jan  9 23:42:46 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:42:46 2025 ] Eval epoch: 42
[ Thu Jan  9 23:42:54 2025 ] 	Mean test loss of 20 batches: 2.2065599501132964.
[ Thu Jan  9 23:42:54 2025 ] 	Top1: 55.98%
[ Thu Jan  9 23:42:54 2025 ] 	Top5: 84.68%
[ Thu Jan  9 23:42:54 2025 ] Training epoch: 43
[ Thu Jan  9 23:45:24 2025 ] 	Mean training loss: 1.0878.  Mean training acc: 88.64%.
[ Thu Jan  9 23:45:24 2025 ] 	Learning Rate: 0.00061302
[ Thu Jan  9 23:45:24 2025 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jan  9 23:45:24 2025 ] Eval epoch: 43
[ Thu Jan  9 23:45:31 2025 ] 	Mean test loss of 20 batches: 2.1670236766338347.
[ Thu Jan  9 23:45:31 2025 ] 	Top1: 57.11%
[ Thu Jan  9 23:45:31 2025 ] 	Top5: 85.03%
[ Thu Jan  9 23:45:31 2025 ] Training epoch: 44
[ Thu Jan  9 23:47:58 2025 ] 	Mean training loss: 1.0728.  Mean training acc: 89.27%.
[ Thu Jan  9 23:47:58 2025 ] 	Learning Rate: 0.00059779
[ Thu Jan  9 23:47:58 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jan  9 23:47:58 2025 ] Eval epoch: 44
[ Thu Jan  9 23:48:05 2025 ] 	Mean test loss of 20 batches: 2.185726660490036.
[ Thu Jan  9 23:48:05 2025 ] 	Top1: 56.46%
[ Thu Jan  9 23:48:05 2025 ] 	Top5: 85.00%
[ Thu Jan  9 23:48:05 2025 ] Training epoch: 45
[ Thu Jan  9 23:49:03 2025 ] using warm up, epoch: 25
[ Thu Jan  9 23:49:04 2025 ] Parameters:
{'work_dir': './output/original_48_newPE/', 'model_saved_name': './output/original_48_newPE/runs', 'config': './config/SkateFormer_newPE_j_NEW.yaml', 'weights': None, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ma52_NEW.Feeder', 'num_worker': 6, 'train_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'train', 'data_type': 'j', 'repeat': 10, 'p': 0.3, 'debug': False, 'partition': True}, 'test_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'val', 'data_type': 'j', 'repeat': 1, 'partition': True}, 'model': 'model.SkateFormer_newPE.SkateFormer_', 'model_args': {'in_channels': 2, 'num_classes': 52, 'num_people': 1, 'num_points': 48, 'kernel_size': 7, 'num_heads': 32, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.2, 'type_1_size': [8, 12], 'type_2_size': [8, 24], 'type_3_size': [8, 12], 'type_4_size': [8, 24], 'mlp_ratio': 1.0, 'index_t': True}, 'ignore_weights': [], 'base_lr': 0.001, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 25, 'grad_clip': True, 'grad_max': 1.0, 'device': [0, 1, 2, 3], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 288, 'test_batch_size': 288, 'start_epoch': 0, 'num_epoch': 100, 'weight_decay': 0.1, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Thu Jan  9 23:49:04 2025 ] # Parameters: 2587198
[ Thu Jan  9 23:49:04 2025 ] Training epoch: 1
[ Thu Jan  9 23:51:39 2025 ] 	Mean training loss: 3.6928.  Mean training acc: 9.32%.
[ Thu Jan  9 23:51:39 2025 ] 	Learning Rate: 0.00003999
[ Thu Jan  9 23:51:39 2025 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jan  9 23:51:40 2025 ] Eval epoch: 1
[ Thu Jan  9 23:51:46 2025 ] 	Mean test loss of 20 batches: 3.420643353462219.
[ Thu Jan  9 23:51:46 2025 ] 	Top1: 11.85%
[ Thu Jan  9 23:51:46 2025 ] 	Top5: 43.18%
[ Thu Jan  9 23:54:18 2025 ] using warm up, epoch: 25
[ Thu Jan  9 23:54:19 2025 ] Parameters:
{'work_dir': './output/original_48_newPE/', 'model_saved_name': './output/original_48_newPE/runs', 'config': './config/SkateFormer_newPE_j_NEW.yaml', 'weights': None, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ma52_NEW.Feeder', 'num_worker': 6, 'train_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'train', 'data_type': 'j', 'repeat': 10, 'p': 0.3, 'debug': False, 'partition': True}, 'test_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'val', 'data_type': 'j', 'repeat': 1, 'partition': True}, 'model': 'model.SkateFormer_newPE.SkateFormer_', 'model_args': {'in_channels': 2, 'num_classes': 52, 'num_people': 1, 'num_points': 48, 'kernel_size': 7, 'num_heads': 32, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.2, 'type_1_size': [8, 12], 'type_2_size': [8, 24], 'type_3_size': [8, 12], 'type_4_size': [8, 24], 'mlp_ratio': 1.0, 'index_t': True}, 'ignore_weights': [], 'base_lr': 0.001, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 25, 'grad_clip': True, 'grad_max': 1.0, 'device': [0, 1, 2, 3], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 288, 'test_batch_size': 288, 'start_epoch': 0, 'num_epoch': 100, 'weight_decay': 0.1, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Thu Jan  9 23:54:19 2025 ] # Parameters: 2587198
[ Thu Jan  9 23:54:19 2025 ] Training epoch: 1
[ Thu Jan  9 23:56:55 2025 ] 	Mean training loss: 3.6926.  Mean training acc: 9.30%.
[ Thu Jan  9 23:56:55 2025 ] 	Learning Rate: 0.00003999
[ Thu Jan  9 23:56:55 2025 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jan  9 23:56:55 2025 ] Eval epoch: 1
[ Thu Jan  9 23:57:01 2025 ] 	Mean test loss of 20 batches: 3.4335693597793577.
[ Thu Jan  9 23:57:01 2025 ] 	Top1: 11.87%
[ Thu Jan  9 23:57:01 2025 ] 	Top5: 43.81%
[ Thu Jan  9 23:58:52 2025 ] using warm up, epoch: 25
[ Thu Jan  9 23:58:53 2025 ] Parameters:
{'work_dir': './output/original_48_newPE/', 'model_saved_name': './output/original_48_newPE/runs', 'config': './config/SkateFormer_newPE_j_NEW.yaml', 'weights': None, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ma52_NEW.Feeder', 'num_worker': 6, 'train_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'train', 'data_type': 'j', 'repeat': 10, 'p': 0.3, 'debug': False, 'partition': True}, 'test_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'val', 'data_type': 'j', 'repeat': 1, 'partition': True}, 'model': 'model.SkateFormer_newPE.SkateFormer_', 'model_args': {'in_channels': 2, 'num_classes': 52, 'num_people': 1, 'num_points': 48, 'kernel_size': 7, 'num_heads': 32, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.2, 'type_1_size': [8, 12], 'type_2_size': [8, 24], 'type_3_size': [8, 12], 'type_4_size': [8, 24], 'mlp_ratio': 1.0, 'index_t': True}, 'ignore_weights': [], 'base_lr': 0.001, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 25, 'grad_clip': True, 'grad_max': 1.0, 'device': [0, 1, 2, 3], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 288, 'test_batch_size': 288, 'start_epoch': 0, 'num_epoch': 100, 'weight_decay': 0.1, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Thu Jan  9 23:58:53 2025 ] # Parameters: 2587198
[ Thu Jan  9 23:58:53 2025 ] Training epoch: 1
[ Fri Jan 10 00:01:27 2025 ] 	Mean training loss: 3.6926.  Mean training acc: 9.34%.
[ Fri Jan 10 00:01:27 2025 ] 	Learning Rate: 0.00003999
[ Fri Jan 10 00:01:27 2025 ] 	Time consumption: [Data]03%, [Network]97%
[ Fri Jan 10 00:01:27 2025 ] Eval epoch: 1
[ Fri Jan 10 00:01:33 2025 ] 	Mean test loss of 20 batches: 3.455668008327484.
[ Fri Jan 10 00:01:33 2025 ] 	Top1: 11.53%
[ Fri Jan 10 00:01:33 2025 ] 	Top5: 42.82%
[ Fri Jan 10 00:03:30 2025 ] using warm up, epoch: 25
[ Fri Jan 10 00:03:32 2025 ] Parameters:
{'work_dir': './output/original_48_newPE/', 'model_saved_name': './output/original_48_newPE/runs', 'config': './config/SkateFormer_newPE_j_NEW.yaml', 'weights': None, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ma52_NEW.Feeder', 'num_worker': 6, 'train_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'train', 'data_type': 'j', 'repeat': 10, 'p': 0.3, 'debug': False, 'partition': True}, 'test_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'val', 'data_type': 'j', 'repeat': 1, 'partition': True}, 'model': 'model.SkateFormer_newPE.SkateFormer_', 'model_args': {'in_channels': 2, 'num_classes': 52, 'num_people': 1, 'num_points': 48, 'kernel_size': 7, 'num_heads': 32, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.2, 'type_1_size': [8, 12], 'type_2_size': [8, 24], 'type_3_size': [8, 12], 'type_4_size': [8, 24], 'mlp_ratio': 1.0, 'index_t': True}, 'ignore_weights': [], 'base_lr': 0.001, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 25, 'grad_clip': True, 'grad_max': 1.0, 'device': [0, 1, 2, 3], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 288, 'test_batch_size': 288, 'start_epoch': 0, 'num_epoch': 100, 'weight_decay': 0.1, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Fri Jan 10 00:03:32 2025 ] # Parameters: 2587198
[ Fri Jan 10 00:03:32 2025 ] Training epoch: 1
[ Fri Jan 10 00:06:07 2025 ] 	Mean training loss: 3.6927.  Mean training acc: 9.31%.
[ Fri Jan 10 00:06:07 2025 ] 	Learning Rate: 0.00003999
[ Fri Jan 10 00:06:07 2025 ] 	Time consumption: [Data]03%, [Network]97%
[ Fri Jan 10 00:06:07 2025 ] Eval epoch: 1
[ Fri Jan 10 00:06:14 2025 ] 	Mean test loss of 20 batches: 3.4634186387062074.
[ Fri Jan 10 00:06:14 2025 ] 	Top1: 11.17%
[ Fri Jan 10 00:06:14 2025 ] 	Top5: 41.84%
[ Fri Jan 10 00:06:14 2025 ] Training epoch: 2
[ Fri Jan 10 00:08:40 2025 ] 	Mean training loss: 3.3378.  Mean training acc: 13.43%.
[ Fri Jan 10 00:08:40 2025 ] 	Learning Rate: 0.00007999
[ Fri Jan 10 00:08:40 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:08:40 2025 ] Eval epoch: 2
[ Fri Jan 10 00:08:47 2025 ] 	Mean test loss of 20 batches: 4.204246962070465.
[ Fri Jan 10 00:08:47 2025 ] 	Top1: 4.80%
[ Fri Jan 10 00:08:47 2025 ] 	Top5: 19.67%
[ Fri Jan 10 00:08:47 2025 ] Training epoch: 3
[ Fri Jan 10 00:11:14 2025 ] 	Mean training loss: 3.1137.  Mean training acc: 18.04%.
[ Fri Jan 10 00:11:14 2025 ] 	Learning Rate: 0.00011999
[ Fri Jan 10 00:11:14 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:11:14 2025 ] Eval epoch: 3
[ Fri Jan 10 00:11:20 2025 ] 	Mean test loss of 20 batches: 2.953250062465668.
[ Fri Jan 10 00:11:20 2025 ] 	Top1: 22.00%
[ Fri Jan 10 00:11:20 2025 ] 	Top5: 61.42%
[ Fri Jan 10 00:11:20 2025 ] Training epoch: 4
[ Fri Jan 10 00:13:48 2025 ] 	Mean training loss: 2.9166.  Mean training acc: 22.85%.
[ Fri Jan 10 00:13:48 2025 ] 	Learning Rate: 0.00015998
[ Fri Jan 10 00:13:48 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:13:48 2025 ] Eval epoch: 4
[ Fri Jan 10 00:13:54 2025 ] 	Mean test loss of 20 batches: 3.493441939353943.
[ Fri Jan 10 00:13:54 2025 ] 	Top1: 9.36%
[ Fri Jan 10 00:13:54 2025 ] 	Top5: 49.55%
[ Fri Jan 10 00:13:54 2025 ] Training epoch: 5
[ Fri Jan 10 00:16:22 2025 ] 	Mean training loss: 2.7653.  Mean training acc: 27.61%.
[ Fri Jan 10 00:16:22 2025 ] 	Learning Rate: 0.00019998
[ Fri Jan 10 00:16:22 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:16:22 2025 ] Eval epoch: 5
[ Fri Jan 10 00:16:29 2025 ] 	Mean test loss of 20 batches: 2.649682319164276.
[ Fri Jan 10 00:16:29 2025 ] 	Top1: 30.34%
[ Fri Jan 10 00:16:29 2025 ] 	Top5: 72.23%
[ Fri Jan 10 00:16:29 2025 ] Training epoch: 6
[ Fri Jan 10 00:18:55 2025 ] 	Mean training loss: 2.6120.  Mean training acc: 32.73%.
[ Fri Jan 10 00:18:55 2025 ] 	Learning Rate: 0.00023997
[ Fri Jan 10 00:18:55 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:18:55 2025 ] Eval epoch: 6
[ Fri Jan 10 00:19:02 2025 ] 	Mean test loss of 20 batches: 2.5248283624649046.
[ Fri Jan 10 00:19:02 2025 ] 	Top1: 36.99%
[ Fri Jan 10 00:19:02 2025 ] 	Top5: 75.85%
[ Fri Jan 10 00:19:02 2025 ] Training epoch: 7
[ Fri Jan 10 00:21:29 2025 ] 	Mean training loss: 2.4503.  Mean training acc: 39.19%.
[ Fri Jan 10 00:21:29 2025 ] 	Learning Rate: 0.00027997
[ Fri Jan 10 00:21:29 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:21:29 2025 ] Eval epoch: 7
[ Fri Jan 10 00:21:36 2025 ] 	Mean test loss of 20 batches: 2.5453745841979982.
[ Fri Jan 10 00:21:36 2025 ] 	Top1: 38.45%
[ Fri Jan 10 00:21:36 2025 ] 	Top5: 75.42%
[ Fri Jan 10 00:21:36 2025 ] Training epoch: 8
[ Fri Jan 10 00:24:03 2025 ] 	Mean training loss: 2.3056.  Mean training acc: 44.33%.
[ Fri Jan 10 00:24:03 2025 ] 	Learning Rate: 0.00031997
[ Fri Jan 10 00:24:03 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:24:03 2025 ] Eval epoch: 8
[ Fri Jan 10 00:24:10 2025 ] 	Mean test loss of 20 batches: 2.243086063861847.
[ Fri Jan 10 00:24:10 2025 ] 	Top1: 47.60%
[ Fri Jan 10 00:24:10 2025 ] 	Top5: 82.38%
[ Fri Jan 10 00:24:10 2025 ] Training epoch: 9
[ Fri Jan 10 00:26:36 2025 ] 	Mean training loss: 2.1800.  Mean training acc: 48.63%.
[ Fri Jan 10 00:26:36 2025 ] 	Learning Rate: 0.00035996
[ Fri Jan 10 00:26:36 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:26:36 2025 ] Eval epoch: 9
[ Fri Jan 10 00:26:43 2025 ] 	Mean test loss of 20 batches: 2.1833743929862974.
[ Fri Jan 10 00:26:43 2025 ] 	Top1: 50.41%
[ Fri Jan 10 00:26:43 2025 ] 	Top5: 83.53%
[ Fri Jan 10 00:26:43 2025 ] Training epoch: 10
[ Fri Jan 10 00:29:10 2025 ] 	Mean training loss: 2.0682.  Mean training acc: 52.54%.
[ Fri Jan 10 00:29:10 2025 ] 	Learning Rate: 0.00039996
[ Fri Jan 10 00:29:10 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:29:10 2025 ] Eval epoch: 10
[ Fri Jan 10 00:29:16 2025 ] 	Mean test loss of 20 batches: 2.1027938425540924.
[ Fri Jan 10 00:29:16 2025 ] 	Top1: 53.15%
[ Fri Jan 10 00:29:16 2025 ] 	Top5: 85.89%
[ Fri Jan 10 00:29:16 2025 ] Training epoch: 11
[ Fri Jan 10 00:31:43 2025 ] 	Mean training loss: 1.9688.  Mean training acc: 56.04%.
[ Fri Jan 10 00:31:43 2025 ] 	Learning Rate: 0.00043995
[ Fri Jan 10 00:31:43 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:31:43 2025 ] Eval epoch: 11
[ Fri Jan 10 00:31:50 2025 ] 	Mean test loss of 20 batches: 2.0965308964252474.
[ Fri Jan 10 00:31:50 2025 ] 	Top1: 54.22%
[ Fri Jan 10 00:31:50 2025 ] 	Top5: 85.36%
[ Fri Jan 10 00:31:50 2025 ] Training epoch: 12
[ Fri Jan 10 00:34:18 2025 ] 	Mean training loss: 1.8814.  Mean training acc: 59.25%.
[ Fri Jan 10 00:34:18 2025 ] 	Learning Rate: 0.00047995
[ Fri Jan 10 00:34:18 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:34:18 2025 ] Eval epoch: 12
[ Fri Jan 10 00:34:24 2025 ] 	Mean test loss of 20 batches: 2.080312943458557.
[ Fri Jan 10 00:34:24 2025 ] 	Top1: 54.78%
[ Fri Jan 10 00:34:24 2025 ] 	Top5: 85.45%
[ Fri Jan 10 00:34:24 2025 ] Training epoch: 13
[ Fri Jan 10 00:36:51 2025 ] 	Mean training loss: 1.8112.  Mean training acc: 61.69%.
[ Fri Jan 10 00:36:51 2025 ] 	Learning Rate: 0.00051995
[ Fri Jan 10 00:36:51 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:36:51 2025 ] Eval epoch: 13
[ Fri Jan 10 00:36:57 2025 ] 	Mean test loss of 20 batches: 2.0985833168029786.
[ Fri Jan 10 00:36:57 2025 ] 	Top1: 55.48%
[ Fri Jan 10 00:36:57 2025 ] 	Top5: 85.59%
[ Fri Jan 10 00:36:57 2025 ] Training epoch: 14
[ Fri Jan 10 00:39:24 2025 ] 	Mean training loss: 1.7378.  Mean training acc: 64.36%.
[ Fri Jan 10 00:39:24 2025 ] 	Learning Rate: 0.00055994
[ Fri Jan 10 00:39:24 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:39:24 2025 ] Eval epoch: 14
[ Fri Jan 10 00:39:30 2025 ] 	Mean test loss of 20 batches: 2.0993728935718536.
[ Fri Jan 10 00:39:30 2025 ] 	Top1: 55.62%
[ Fri Jan 10 00:39:30 2025 ] 	Top5: 85.66%
[ Fri Jan 10 00:39:30 2025 ] Training epoch: 15
[ Fri Jan 10 00:41:57 2025 ] 	Mean training loss: 1.6822.  Mean training acc: 66.59%.
[ Fri Jan 10 00:41:57 2025 ] 	Learning Rate: 0.00059994
[ Fri Jan 10 00:41:57 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:41:57 2025 ] Eval epoch: 15
[ Fri Jan 10 00:42:04 2025 ] 	Mean test loss of 20 batches: 2.106454700231552.
[ Fri Jan 10 00:42:04 2025 ] 	Top1: 56.61%
[ Fri Jan 10 00:42:04 2025 ] 	Top5: 86.23%
[ Fri Jan 10 00:42:04 2025 ] Training epoch: 16
[ Fri Jan 10 00:44:30 2025 ] 	Mean training loss: 1.6275.  Mean training acc: 68.52%.
[ Fri Jan 10 00:44:30 2025 ] 	Learning Rate: 0.00063993
[ Fri Jan 10 00:44:30 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:44:31 2025 ] Eval epoch: 16
[ Fri Jan 10 00:44:37 2025 ] 	Mean test loss of 20 batches: 2.109598386287689.
[ Fri Jan 10 00:44:37 2025 ] 	Top1: 56.00%
[ Fri Jan 10 00:44:37 2025 ] 	Top5: 87.18%
[ Fri Jan 10 00:44:37 2025 ] Training epoch: 17
[ Fri Jan 10 00:47:04 2025 ] 	Mean training loss: 1.5834.  Mean training acc: 70.32%.
[ Fri Jan 10 00:47:04 2025 ] 	Learning Rate: 0.00067993
[ Fri Jan 10 00:47:04 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:47:04 2025 ] Eval epoch: 17
[ Fri Jan 10 00:47:11 2025 ] 	Mean test loss of 20 batches: 2.1094141483306883.
[ Fri Jan 10 00:47:11 2025 ] 	Top1: 55.94%
[ Fri Jan 10 00:47:11 2025 ] 	Top5: 86.77%
[ Fri Jan 10 00:47:11 2025 ] Training epoch: 18
[ Fri Jan 10 00:49:40 2025 ] 	Mean training loss: 1.5399.  Mean training acc: 71.82%.
[ Fri Jan 10 00:49:40 2025 ] 	Learning Rate: 0.00071993
[ Fri Jan 10 00:49:40 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 00:49:40 2025 ] Eval epoch: 18
[ Fri Jan 10 00:49:47 2025 ] 	Mean test loss of 20 batches: 2.1239257156848907.
[ Fri Jan 10 00:49:47 2025 ] 	Top1: 56.91%
[ Fri Jan 10 00:49:47 2025 ] 	Top5: 85.71%
[ Fri Jan 10 00:49:47 2025 ] Training epoch: 19
[ Fri Jan 10 00:52:17 2025 ] 	Mean training loss: 1.5086.  Mean training acc: 73.05%.
[ Fri Jan 10 00:52:17 2025 ] 	Learning Rate: 0.00075992
[ Fri Jan 10 00:52:17 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 00:52:17 2025 ] Eval epoch: 19
[ Fri Jan 10 00:52:24 2025 ] 	Mean test loss of 20 batches: 2.13326558470726.
[ Fri Jan 10 00:52:24 2025 ] 	Top1: 56.41%
[ Fri Jan 10 00:52:24 2025 ] 	Top5: 85.39%
[ Fri Jan 10 00:52:24 2025 ] Training epoch: 20
[ Fri Jan 10 00:54:54 2025 ] 	Mean training loss: 1.4776.  Mean training acc: 74.27%.
[ Fri Jan 10 00:54:54 2025 ] 	Learning Rate: 0.00079992
[ Fri Jan 10 00:54:54 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 00:54:54 2025 ] Eval epoch: 20
[ Fri Jan 10 00:55:01 2025 ] 	Mean test loss of 20 batches: 2.1526832401752474.
[ Fri Jan 10 00:55:01 2025 ] 	Top1: 55.51%
[ Fri Jan 10 00:55:01 2025 ] 	Top5: 85.91%
[ Fri Jan 10 00:55:01 2025 ] Training epoch: 21
[ Fri Jan 10 00:57:28 2025 ] 	Mean training loss: 1.4423.  Mean training acc: 75.67%.
[ Fri Jan 10 00:57:28 2025 ] 	Learning Rate: 0.00083991
[ Fri Jan 10 00:57:28 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 00:57:28 2025 ] Eval epoch: 21
[ Fri Jan 10 00:57:35 2025 ] 	Mean test loss of 20 batches: 2.1568396270275114.
[ Fri Jan 10 00:57:35 2025 ] 	Top1: 56.46%
[ Fri Jan 10 00:57:35 2025 ] 	Top5: 85.64%
[ Fri Jan 10 00:57:35 2025 ] Training epoch: 22
[ Fri Jan 10 01:00:03 2025 ] 	Mean training loss: 1.4223.  Mean training acc: 76.49%.
[ Fri Jan 10 01:00:03 2025 ] 	Learning Rate: 0.00087991
[ Fri Jan 10 01:00:03 2025 ] 	Time consumption: [Data]04%, [Network]95%
[ Fri Jan 10 01:00:03 2025 ] Eval epoch: 22
[ Fri Jan 10 01:00:10 2025 ] 	Mean test loss of 20 batches: 2.1468382716178893.
[ Fri Jan 10 01:00:10 2025 ] 	Top1: 56.12%
[ Fri Jan 10 01:00:10 2025 ] 	Top5: 85.32%
[ Fri Jan 10 01:00:10 2025 ] Training epoch: 23
[ Fri Jan 10 01:02:37 2025 ] 	Mean training loss: 1.4081.  Mean training acc: 76.81%.
[ Fri Jan 10 01:02:37 2025 ] 	Learning Rate: 0.00091991
[ Fri Jan 10 01:02:37 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:02:37 2025 ] Eval epoch: 23
[ Fri Jan 10 01:02:43 2025 ] 	Mean test loss of 20 batches: 2.1708436489105223.
[ Fri Jan 10 01:02:43 2025 ] 	Top1: 56.25%
[ Fri Jan 10 01:02:43 2025 ] 	Top5: 84.85%
[ Fri Jan 10 01:02:43 2025 ] Training epoch: 24
[ Fri Jan 10 01:05:11 2025 ] 	Mean training loss: 1.3877.  Mean training acc: 77.49%.
[ Fri Jan 10 01:05:11 2025 ] 	Learning Rate: 0.00095990
[ Fri Jan 10 01:05:11 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:05:11 2025 ] Eval epoch: 24
[ Fri Jan 10 01:05:17 2025 ] 	Mean test loss of 20 batches: 2.1585463523864745.
[ Fri Jan 10 01:05:17 2025 ] 	Top1: 55.96%
[ Fri Jan 10 01:05:17 2025 ] 	Top5: 85.70%
[ Fri Jan 10 01:05:17 2025 ] Training epoch: 25
[ Fri Jan 10 01:07:48 2025 ] 	Mean training loss: 1.3657.  Mean training acc: 78.56%.
[ Fri Jan 10 01:07:48 2025 ] 	Learning Rate: 0.00099990
[ Fri Jan 10 01:07:48 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 01:07:48 2025 ] Eval epoch: 25
[ Fri Jan 10 01:07:54 2025 ] 	Mean test loss of 20 batches: 2.1799637377262115.
[ Fri Jan 10 01:07:54 2025 ] 	Top1: 55.48%
[ Fri Jan 10 01:07:54 2025 ] 	Top5: 85.43%
[ Fri Jan 10 01:07:54 2025 ] Training epoch: 26
[ Fri Jan 10 01:10:21 2025 ] 	Mean training loss: 1.3090.  Mean training acc: 80.71%.
[ Fri Jan 10 01:10:21 2025 ] 	Learning Rate: 0.00084388
[ Fri Jan 10 01:10:21 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:10:21 2025 ] Eval epoch: 26
[ Fri Jan 10 01:10:28 2025 ] 	Mean test loss of 20 batches: 2.158381628990173.
[ Fri Jan 10 01:10:28 2025 ] 	Top1: 56.62%
[ Fri Jan 10 01:10:28 2025 ] 	Top5: 85.14%
[ Fri Jan 10 01:10:28 2025 ] Training epoch: 27
[ Fri Jan 10 01:12:55 2025 ] 	Mean training loss: 1.2756.  Mean training acc: 81.90%.
[ Fri Jan 10 01:12:55 2025 ] 	Learning Rate: 0.00083238
[ Fri Jan 10 01:12:55 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:12:55 2025 ] Eval epoch: 27
[ Fri Jan 10 01:13:02 2025 ] 	Mean test loss of 20 batches: 2.1418466567993164.
[ Fri Jan 10 01:13:02 2025 ] 	Top1: 56.71%
[ Fri Jan 10 01:13:02 2025 ] 	Top5: 85.39%
[ Fri Jan 10 01:13:02 2025 ] Training epoch: 28
[ Fri Jan 10 01:15:29 2025 ] 	Mean training loss: 1.2482.  Mean training acc: 82.91%.
[ Fri Jan 10 01:15:29 2025 ] 	Learning Rate: 0.00082056
[ Fri Jan 10 01:15:29 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:15:29 2025 ] Eval epoch: 28
[ Fri Jan 10 01:15:36 2025 ] 	Mean test loss of 20 batches: 2.1863078832626344.
[ Fri Jan 10 01:15:36 2025 ] 	Top1: 56.80%
[ Fri Jan 10 01:15:36 2025 ] 	Top5: 84.69%
[ Fri Jan 10 01:15:36 2025 ] Training epoch: 29
[ Fri Jan 10 01:18:02 2025 ] 	Mean training loss: 1.2285.  Mean training acc: 83.71%.
[ Fri Jan 10 01:18:02 2025 ] 	Learning Rate: 0.00080842
[ Fri Jan 10 01:18:02 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:18:03 2025 ] Eval epoch: 29
[ Fri Jan 10 01:18:09 2025 ] 	Mean test loss of 20 batches: 2.1402368187904357.
[ Fri Jan 10 01:18:09 2025 ] 	Top1: 57.66%
[ Fri Jan 10 01:18:09 2025 ] 	Top5: 85.02%
[ Fri Jan 10 01:18:09 2025 ] Training epoch: 30
[ Fri Jan 10 01:20:36 2025 ] 	Mean training loss: 1.2132.  Mean training acc: 84.30%.
[ Fri Jan 10 01:20:36 2025 ] 	Learning Rate: 0.00079599
[ Fri Jan 10 01:20:36 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:20:36 2025 ] Eval epoch: 30
[ Fri Jan 10 01:20:42 2025 ] 	Mean test loss of 20 batches: 2.1855881810188293.
[ Fri Jan 10 01:20:42 2025 ] 	Top1: 57.36%
[ Fri Jan 10 01:20:42 2025 ] 	Top5: 85.28%
[ Fri Jan 10 01:20:42 2025 ] Training epoch: 31
[ Fri Jan 10 01:23:10 2025 ] 	Mean training loss: 1.1955.  Mean training acc: 84.83%.
[ Fri Jan 10 01:23:10 2025 ] 	Learning Rate: 0.00078326
[ Fri Jan 10 01:23:10 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:23:10 2025 ] Eval epoch: 31
[ Fri Jan 10 01:23:16 2025 ] 	Mean test loss of 20 batches: 2.1586547613143923.
[ Fri Jan 10 01:23:16 2025 ] 	Top1: 57.09%
[ Fri Jan 10 01:23:16 2025 ] 	Top5: 84.96%
[ Fri Jan 10 01:23:16 2025 ] Training epoch: 32
[ Fri Jan 10 01:25:43 2025 ] 	Mean training loss: 1.1772.  Mean training acc: 85.46%.
[ Fri Jan 10 01:25:43 2025 ] 	Learning Rate: 0.00077027
[ Fri Jan 10 01:25:43 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:25:43 2025 ] Eval epoch: 32
[ Fri Jan 10 01:25:50 2025 ] 	Mean test loss of 20 batches: 2.1609373092651367.
[ Fri Jan 10 01:25:50 2025 ] 	Top1: 57.61%
[ Fri Jan 10 01:25:50 2025 ] 	Top5: 85.09%
[ Fri Jan 10 01:25:50 2025 ] Training epoch: 33
[ Fri Jan 10 01:28:16 2025 ] 	Mean training loss: 1.1656.  Mean training acc: 85.94%.
[ Fri Jan 10 01:28:16 2025 ] 	Learning Rate: 0.00075701
[ Fri Jan 10 01:28:16 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:28:16 2025 ] Eval epoch: 33
[ Fri Jan 10 01:28:23 2025 ] 	Mean test loss of 20 batches: 2.159904843568802.
[ Fri Jan 10 01:28:23 2025 ] 	Top1: 57.88%
[ Fri Jan 10 01:28:23 2025 ] 	Top5: 84.69%
[ Fri Jan 10 01:28:23 2025 ] Training epoch: 34
[ Fri Jan 10 01:30:50 2025 ] 	Mean training loss: 1.1502.  Mean training acc: 86.36%.
[ Fri Jan 10 01:30:50 2025 ] 	Learning Rate: 0.00074350
[ Fri Jan 10 01:30:50 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:30:50 2025 ] Eval epoch: 34
[ Fri Jan 10 01:30:57 2025 ] 	Mean test loss of 20 batches: 2.1585957050323485.
[ Fri Jan 10 01:30:57 2025 ] 	Top1: 58.45%
[ Fri Jan 10 01:30:57 2025 ] 	Top5: 85.41%
[ Fri Jan 10 01:30:57 2025 ] Training epoch: 35
[ Fri Jan 10 01:33:26 2025 ] 	Mean training loss: 1.1360.  Mean training acc: 86.90%.
[ Fri Jan 10 01:33:26 2025 ] 	Learning Rate: 0.00072976
[ Fri Jan 10 01:33:26 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 01:33:26 2025 ] Eval epoch: 35
[ Fri Jan 10 01:33:32 2025 ] 	Mean test loss of 20 batches: 2.169030022621155.
[ Fri Jan 10 01:33:32 2025 ] 	Top1: 57.82%
[ Fri Jan 10 01:33:33 2025 ] 	Top5: 84.73%
[ Fri Jan 10 01:33:33 2025 ] Training epoch: 36
[ Fri Jan 10 01:36:00 2025 ] 	Mean training loss: 1.1276.  Mean training acc: 87.27%.
[ Fri Jan 10 01:36:00 2025 ] 	Learning Rate: 0.00071580
[ Fri Jan 10 01:36:00 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:36:00 2025 ] Eval epoch: 36
[ Fri Jan 10 01:36:06 2025 ] 	Mean test loss of 20 batches: 2.18175784945488.
[ Fri Jan 10 01:36:06 2025 ] 	Top1: 57.11%
[ Fri Jan 10 01:36:07 2025 ] 	Top5: 84.09%
[ Fri Jan 10 01:36:07 2025 ] Training epoch: 37
[ Fri Jan 10 01:38:33 2025 ] 	Mean training loss: 1.1159.  Mean training acc: 87.59%.
[ Fri Jan 10 01:38:33 2025 ] 	Learning Rate: 0.00070162
[ Fri Jan 10 01:38:33 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:38:33 2025 ] Eval epoch: 37
[ Fri Jan 10 01:38:40 2025 ] 	Mean test loss of 20 batches: 2.1356112718582154.
[ Fri Jan 10 01:38:40 2025 ] 	Top1: 58.65%
[ Fri Jan 10 01:38:40 2025 ] 	Top5: 85.77%
[ Fri Jan 10 01:38:40 2025 ] Training epoch: 38
[ Fri Jan 10 01:41:07 2025 ] 	Mean training loss: 1.1047.  Mean training acc: 87.94%.
[ Fri Jan 10 01:41:07 2025 ] 	Learning Rate: 0.00068726
[ Fri Jan 10 01:41:07 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:41:07 2025 ] Eval epoch: 38
[ Fri Jan 10 01:41:14 2025 ] 	Mean test loss of 20 batches: 2.2127469182014465.
[ Fri Jan 10 01:41:14 2025 ] 	Top1: 57.95%
[ Fri Jan 10 01:41:14 2025 ] 	Top5: 84.19%
[ Fri Jan 10 01:41:14 2025 ] Training epoch: 39
[ Fri Jan 10 01:43:43 2025 ] 	Mean training loss: 1.0950.  Mean training acc: 88.34%.
[ Fri Jan 10 01:43:43 2025 ] 	Learning Rate: 0.00067271
[ Fri Jan 10 01:43:43 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 01:43:43 2025 ] Eval epoch: 39
[ Fri Jan 10 01:43:50 2025 ] 	Mean test loss of 20 batches: 2.162651741504669.
[ Fri Jan 10 01:43:50 2025 ] 	Top1: 57.98%
[ Fri Jan 10 01:43:50 2025 ] 	Top5: 85.27%
[ Fri Jan 10 01:43:50 2025 ] Training epoch: 40
[ Fri Jan 10 01:46:19 2025 ] 	Mean training loss: 1.0836.  Mean training acc: 88.65%.
[ Fri Jan 10 01:46:19 2025 ] 	Learning Rate: 0.00065800
[ Fri Jan 10 01:46:19 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 01:46:19 2025 ] Eval epoch: 40
[ Fri Jan 10 01:46:26 2025 ] 	Mean test loss of 20 batches: 2.206421512365341.
[ Fri Jan 10 01:46:26 2025 ] 	Top1: 58.11%
[ Fri Jan 10 01:46:26 2025 ] 	Top5: 84.43%
[ Fri Jan 10 01:46:26 2025 ] Training epoch: 41
[ Fri Jan 10 01:48:54 2025 ] 	Mean training loss: 1.0766.  Mean training acc: 88.94%.
[ Fri Jan 10 01:48:54 2025 ] 	Learning Rate: 0.00064314
[ Fri Jan 10 01:48:54 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:48:54 2025 ] Eval epoch: 41
[ Fri Jan 10 01:49:00 2025 ] 	Mean test loss of 20 batches: 2.1560628533363344.
[ Fri Jan 10 01:49:00 2025 ] 	Top1: 57.61%
[ Fri Jan 10 01:49:00 2025 ] 	Top5: 84.51%
[ Fri Jan 10 01:49:00 2025 ] Training epoch: 42
[ Fri Jan 10 01:51:27 2025 ] 	Mean training loss: 1.0675.  Mean training acc: 89.22%.
[ Fri Jan 10 01:51:27 2025 ] 	Learning Rate: 0.00062814
[ Fri Jan 10 01:51:27 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:51:27 2025 ] Eval epoch: 42
[ Fri Jan 10 01:51:34 2025 ] 	Mean test loss of 20 batches: 2.172034281492233.
[ Fri Jan 10 01:51:34 2025 ] 	Top1: 58.31%
[ Fri Jan 10 01:51:34 2025 ] 	Top5: 84.00%
[ Fri Jan 10 01:51:34 2025 ] Training epoch: 43
[ Fri Jan 10 01:54:00 2025 ] 	Mean training loss: 1.0527.  Mean training acc: 89.80%.
[ Fri Jan 10 01:54:00 2025 ] 	Learning Rate: 0.00061302
[ Fri Jan 10 01:54:00 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:54:01 2025 ] Eval epoch: 43
[ Fri Jan 10 01:54:07 2025 ] 	Mean test loss of 20 batches: 2.158135348558426.
[ Fri Jan 10 01:54:07 2025 ] 	Top1: 58.68%
[ Fri Jan 10 01:54:07 2025 ] 	Top5: 84.37%
[ Fri Jan 10 01:54:07 2025 ] Training epoch: 44
[ Fri Jan 10 01:56:34 2025 ] 	Mean training loss: 1.0415.  Mean training acc: 90.10%.
[ Fri Jan 10 01:56:34 2025 ] 	Learning Rate: 0.00059779
[ Fri Jan 10 01:56:34 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:56:34 2025 ] Eval epoch: 44
[ Fri Jan 10 01:56:41 2025 ] 	Mean test loss of 20 batches: 2.1720064759254454.
[ Fri Jan 10 01:56:41 2025 ] 	Top1: 58.32%
[ Fri Jan 10 01:56:41 2025 ] 	Top5: 84.51%
[ Fri Jan 10 01:56:41 2025 ] Training epoch: 45
[ Fri Jan 10 01:59:07 2025 ] 	Mean training loss: 1.0428.  Mean training acc: 90.01%.
[ Fri Jan 10 01:59:07 2025 ] 	Learning Rate: 0.00058247
[ Fri Jan 10 01:59:07 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 01:59:07 2025 ] Eval epoch: 45
[ Fri Jan 10 01:59:14 2025 ] 	Mean test loss of 20 batches: 2.1889611959457396.
[ Fri Jan 10 01:59:14 2025 ] 	Top1: 58.16%
[ Fri Jan 10 01:59:14 2025 ] 	Top5: 84.10%
[ Fri Jan 10 01:59:14 2025 ] Training epoch: 46
[ Fri Jan 10 02:01:44 2025 ] 	Mean training loss: 1.0307.  Mean training acc: 90.51%.
[ Fri Jan 10 02:01:44 2025 ] 	Learning Rate: 0.00056708
[ Fri Jan 10 02:01:44 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 02:01:44 2025 ] Eval epoch: 46
[ Fri Jan 10 02:01:52 2025 ] 	Mean test loss of 20 batches: 2.220329427719116.
[ Fri Jan 10 02:01:52 2025 ] 	Top1: 57.41%
[ Fri Jan 10 02:01:52 2025 ] 	Top5: 83.75%
[ Fri Jan 10 02:01:52 2025 ] Training epoch: 47
[ Fri Jan 10 02:04:21 2025 ] 	Mean training loss: 1.0213.  Mean training acc: 90.73%.
[ Fri Jan 10 02:04:21 2025 ] 	Learning Rate: 0.00055162
[ Fri Jan 10 02:04:21 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 02:04:21 2025 ] Eval epoch: 47
[ Fri Jan 10 02:04:28 2025 ] 	Mean test loss of 20 batches: 2.1990552842617035.
[ Fri Jan 10 02:04:28 2025 ] 	Top1: 57.97%
[ Fri Jan 10 02:04:28 2025 ] 	Top5: 84.16%
[ Fri Jan 10 02:04:28 2025 ] Training epoch: 48
[ Fri Jan 10 02:06:57 2025 ] 	Mean training loss: 1.0113.  Mean training acc: 91.10%.
[ Fri Jan 10 02:06:57 2025 ] 	Learning Rate: 0.00053612
[ Fri Jan 10 02:06:57 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 02:06:57 2025 ] Eval epoch: 48
[ Fri Jan 10 02:07:05 2025 ] 	Mean test loss of 20 batches: 2.1960562586784365.
[ Fri Jan 10 02:07:05 2025 ] 	Top1: 58.15%
[ Fri Jan 10 02:07:05 2025 ] 	Top5: 84.21%
[ Fri Jan 10 02:07:05 2025 ] Training epoch: 49
[ Fri Jan 10 02:09:35 2025 ] 	Mean training loss: 1.0105.  Mean training acc: 91.11%.
[ Fri Jan 10 02:09:35 2025 ] 	Learning Rate: 0.00052059
[ Fri Jan 10 02:09:35 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 02:09:35 2025 ] Eval epoch: 49
[ Fri Jan 10 02:09:42 2025 ] 	Mean test loss of 20 batches: 2.196931767463684.
[ Fri Jan 10 02:09:42 2025 ] 	Top1: 57.61%
[ Fri Jan 10 02:09:42 2025 ] 	Top5: 84.41%
[ Fri Jan 10 02:09:42 2025 ] Training epoch: 50
[ Fri Jan 10 02:12:08 2025 ] 	Mean training loss: 1.0010.  Mean training acc: 91.43%.
[ Fri Jan 10 02:12:08 2025 ] 	Learning Rate: 0.00050504
[ Fri Jan 10 02:12:08 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:12:08 2025 ] Eval epoch: 50
[ Fri Jan 10 02:12:15 2025 ] 	Mean test loss of 20 batches: 2.198901003599167.
[ Fri Jan 10 02:12:15 2025 ] 	Top1: 57.54%
[ Fri Jan 10 02:12:15 2025 ] 	Top5: 84.01%
[ Fri Jan 10 02:12:15 2025 ] Training epoch: 51
[ Fri Jan 10 02:14:41 2025 ] 	Mean training loss: 0.9928.  Mean training acc: 91.72%.
[ Fri Jan 10 02:14:41 2025 ] 	Learning Rate: 0.00048949
[ Fri Jan 10 02:14:41 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:14:41 2025 ] Eval epoch: 51
[ Fri Jan 10 02:14:49 2025 ] 	Mean test loss of 20 batches: 2.1980672597885134.
[ Fri Jan 10 02:14:49 2025 ] 	Top1: 57.57%
[ Fri Jan 10 02:14:49 2025 ] 	Top5: 83.57%
[ Fri Jan 10 02:14:49 2025 ] Training epoch: 52
[ Fri Jan 10 02:17:16 2025 ] 	Mean training loss: 0.9874.  Mean training acc: 91.91%.
[ Fri Jan 10 02:17:16 2025 ] 	Learning Rate: 0.00047396
[ Fri Jan 10 02:17:16 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:17:16 2025 ] Eval epoch: 52
[ Fri Jan 10 02:17:23 2025 ] 	Mean test loss of 20 batches: 2.225122106075287.
[ Fri Jan 10 02:17:23 2025 ] 	Top1: 57.12%
[ Fri Jan 10 02:17:23 2025 ] 	Top5: 84.32%
[ Fri Jan 10 02:17:23 2025 ] Training epoch: 53
[ Fri Jan 10 02:19:52 2025 ] 	Mean training loss: 0.9802.  Mean training acc: 92.08%.
[ Fri Jan 10 02:19:52 2025 ] 	Learning Rate: 0.00045846
[ Fri Jan 10 02:19:52 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 02:19:52 2025 ] Eval epoch: 53
[ Fri Jan 10 02:19:59 2025 ] 	Mean test loss of 20 batches: 2.210339629650116.
[ Fri Jan 10 02:19:59 2025 ] 	Top1: 58.27%
[ Fri Jan 10 02:19:59 2025 ] 	Top5: 83.80%
[ Fri Jan 10 02:19:59 2025 ] Training epoch: 54
[ Fri Jan 10 02:22:25 2025 ] 	Mean training loss: 0.9707.  Mean training acc: 92.40%.
[ Fri Jan 10 02:22:25 2025 ] 	Learning Rate: 0.00044300
[ Fri Jan 10 02:22:25 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:22:25 2025 ] Eval epoch: 54
[ Fri Jan 10 02:22:32 2025 ] 	Mean test loss of 20 batches: 2.169327998161316.
[ Fri Jan 10 02:22:32 2025 ] 	Top1: 58.52%
[ Fri Jan 10 02:22:32 2025 ] 	Top5: 84.01%
[ Fri Jan 10 02:22:32 2025 ] Training epoch: 55
[ Fri Jan 10 02:24:59 2025 ] 	Mean training loss: 0.9628.  Mean training acc: 92.68%.
[ Fri Jan 10 02:24:59 2025 ] 	Learning Rate: 0.00042760
[ Fri Jan 10 02:24:59 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:24:59 2025 ] Eval epoch: 55
[ Fri Jan 10 02:25:05 2025 ] 	Mean test loss of 20 batches: 2.194957321882248.
[ Fri Jan 10 02:25:05 2025 ] 	Top1: 57.91%
[ Fri Jan 10 02:25:05 2025 ] 	Top5: 83.69%
[ Fri Jan 10 02:25:05 2025 ] Training epoch: 56
[ Fri Jan 10 02:27:32 2025 ] 	Mean training loss: 0.9594.  Mean training acc: 92.78%.
[ Fri Jan 10 02:27:32 2025 ] 	Learning Rate: 0.00041229
[ Fri Jan 10 02:27:32 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:27:32 2025 ] Eval epoch: 56
[ Fri Jan 10 02:27:39 2025 ] 	Mean test loss of 20 batches: 2.19640566110611.
[ Fri Jan 10 02:27:39 2025 ] 	Top1: 58.22%
[ Fri Jan 10 02:27:39 2025 ] 	Top5: 83.53%
[ Fri Jan 10 02:27:39 2025 ] Training epoch: 57
[ Fri Jan 10 02:30:05 2025 ] 	Mean training loss: 0.9538.  Mean training acc: 93.05%.
[ Fri Jan 10 02:30:05 2025 ] 	Learning Rate: 0.00039706
[ Fri Jan 10 02:30:05 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:30:06 2025 ] Eval epoch: 57
[ Fri Jan 10 02:30:12 2025 ] 	Mean test loss of 20 batches: 2.213414204120636.
[ Fri Jan 10 02:30:12 2025 ] 	Top1: 58.04%
[ Fri Jan 10 02:30:12 2025 ] 	Top5: 83.42%
[ Fri Jan 10 02:30:12 2025 ] Training epoch: 58
[ Fri Jan 10 02:32:39 2025 ] 	Mean training loss: 0.9449.  Mean training acc: 93.28%.
[ Fri Jan 10 02:32:39 2025 ] 	Learning Rate: 0.00038194
[ Fri Jan 10 02:32:39 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:32:39 2025 ] Eval epoch: 58
[ Fri Jan 10 02:32:46 2025 ] 	Mean test loss of 20 batches: 2.211694288253784.
[ Fri Jan 10 02:32:46 2025 ] 	Top1: 57.72%
[ Fri Jan 10 02:32:46 2025 ] 	Top5: 83.80%
[ Fri Jan 10 02:32:46 2025 ] Training epoch: 59
[ Fri Jan 10 02:35:12 2025 ] 	Mean training loss: 0.9382.  Mean training acc: 93.51%.
[ Fri Jan 10 02:35:12 2025 ] 	Learning Rate: 0.00036694
[ Fri Jan 10 02:35:12 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:35:12 2025 ] Eval epoch: 59
[ Fri Jan 10 02:35:19 2025 ] 	Mean test loss of 20 batches: 2.2056747317314147.
[ Fri Jan 10 02:35:19 2025 ] 	Top1: 57.98%
[ Fri Jan 10 02:35:19 2025 ] 	Top5: 83.35%
[ Fri Jan 10 02:35:19 2025 ] Training epoch: 60
[ Fri Jan 10 02:37:45 2025 ] 	Mean training loss: 0.9318.  Mean training acc: 93.71%.
[ Fri Jan 10 02:37:45 2025 ] 	Learning Rate: 0.00035207
[ Fri Jan 10 02:37:45 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:37:45 2025 ] Eval epoch: 60
[ Fri Jan 10 02:37:52 2025 ] 	Mean test loss of 20 batches: 2.196070748567581.
[ Fri Jan 10 02:37:52 2025 ] 	Top1: 57.98%
[ Fri Jan 10 02:37:52 2025 ] 	Top5: 84.03%
[ Fri Jan 10 02:37:52 2025 ] Training epoch: 61
[ Fri Jan 10 02:40:19 2025 ] 	Mean training loss: 0.9253.  Mean training acc: 93.89%.
[ Fri Jan 10 02:40:19 2025 ] 	Learning Rate: 0.00033736
[ Fri Jan 10 02:40:19 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:40:19 2025 ] Eval epoch: 61
[ Fri Jan 10 02:40:25 2025 ] 	Mean test loss of 20 batches: 2.1912885785102842.
[ Fri Jan 10 02:40:25 2025 ] 	Top1: 58.29%
[ Fri Jan 10 02:40:25 2025 ] 	Top5: 83.78%
[ Fri Jan 10 02:40:25 2025 ] Training epoch: 62
[ Fri Jan 10 02:42:52 2025 ] 	Mean training loss: 0.9215.  Mean training acc: 94.05%.
[ Fri Jan 10 02:42:52 2025 ] 	Learning Rate: 0.00032282
[ Fri Jan 10 02:42:52 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:42:52 2025 ] Eval epoch: 62
[ Fri Jan 10 02:42:59 2025 ] 	Mean test loss of 20 batches: 2.1825627863407133.
[ Fri Jan 10 02:42:59 2025 ] 	Top1: 58.40%
[ Fri Jan 10 02:42:59 2025 ] 	Top5: 83.98%
[ Fri Jan 10 02:42:59 2025 ] Training epoch: 63
[ Fri Jan 10 02:45:26 2025 ] 	Mean training loss: 0.9163.  Mean training acc: 94.20%.
[ Fri Jan 10 02:45:26 2025 ] 	Learning Rate: 0.00030845
[ Fri Jan 10 02:45:26 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:45:26 2025 ] Eval epoch: 63
[ Fri Jan 10 02:45:32 2025 ] 	Mean test loss of 20 batches: 2.224015843868256.
[ Fri Jan 10 02:45:32 2025 ] 	Top1: 57.48%
[ Fri Jan 10 02:45:32 2025 ] 	Top5: 83.55%
[ Fri Jan 10 02:45:32 2025 ] Training epoch: 64
[ Fri Jan 10 02:47:59 2025 ] 	Mean training loss: 0.9098.  Mean training acc: 94.41%.
[ Fri Jan 10 02:47:59 2025 ] 	Learning Rate: 0.00029428
[ Fri Jan 10 02:47:59 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:47:59 2025 ] Eval epoch: 64
[ Fri Jan 10 02:48:05 2025 ] 	Mean test loss of 20 batches: 2.1874134242534637.
[ Fri Jan 10 02:48:06 2025 ] 	Top1: 58.49%
[ Fri Jan 10 02:48:06 2025 ] 	Top5: 84.35%
[ Fri Jan 10 02:48:06 2025 ] Training epoch: 65
[ Fri Jan 10 02:50:32 2025 ] 	Mean training loss: 0.9054.  Mean training acc: 94.59%.
[ Fri Jan 10 02:50:32 2025 ] 	Learning Rate: 0.00028031
[ Fri Jan 10 02:50:32 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:50:32 2025 ] Eval epoch: 65
[ Fri Jan 10 02:50:39 2025 ] 	Mean test loss of 20 batches: 2.171973580121994.
[ Fri Jan 10 02:50:39 2025 ] 	Top1: 58.49%
[ Fri Jan 10 02:50:39 2025 ] 	Top5: 83.80%
[ Fri Jan 10 02:50:39 2025 ] Training epoch: 66
[ Fri Jan 10 02:53:06 2025 ] 	Mean training loss: 0.9005.  Mean training acc: 94.81%.
[ Fri Jan 10 02:53:06 2025 ] 	Learning Rate: 0.00026657
[ Fri Jan 10 02:53:06 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:53:06 2025 ] Eval epoch: 66
[ Fri Jan 10 02:53:13 2025 ] 	Mean test loss of 20 batches: 2.1887469351291657.
[ Fri Jan 10 02:53:13 2025 ] 	Top1: 58.41%
[ Fri Jan 10 02:53:13 2025 ] 	Top5: 83.42%
[ Fri Jan 10 02:53:13 2025 ] Training epoch: 67
[ Fri Jan 10 02:55:39 2025 ] 	Mean training loss: 0.8928.  Mean training acc: 95.01%.
[ Fri Jan 10 02:55:39 2025 ] 	Learning Rate: 0.00025306
[ Fri Jan 10 02:55:39 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:55:39 2025 ] Eval epoch: 67
[ Fri Jan 10 02:55:46 2025 ] 	Mean test loss of 20 batches: 2.185231643915176.
[ Fri Jan 10 02:55:46 2025 ] 	Top1: 58.54%
[ Fri Jan 10 02:55:46 2025 ] 	Top5: 83.69%
[ Fri Jan 10 02:55:46 2025 ] Training epoch: 68
[ Fri Jan 10 02:58:12 2025 ] 	Mean training loss: 0.8865.  Mean training acc: 95.25%.
[ Fri Jan 10 02:58:12 2025 ] 	Learning Rate: 0.00023980
[ Fri Jan 10 02:58:12 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 02:58:12 2025 ] Eval epoch: 68
[ Fri Jan 10 02:58:19 2025 ] 	Mean test loss of 20 batches: 2.1909284710884096.
[ Fri Jan 10 02:58:19 2025 ] 	Top1: 59.13%
[ Fri Jan 10 02:58:19 2025 ] 	Top5: 83.85%
[ Fri Jan 10 02:58:19 2025 ] Training epoch: 69
[ Fri Jan 10 03:00:45 2025 ] 	Mean training loss: 0.8831.  Mean training acc: 95.31%.
[ Fri Jan 10 03:00:45 2025 ] 	Learning Rate: 0.00022680
[ Fri Jan 10 03:00:45 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:00:45 2025 ] Eval epoch: 69
[ Fri Jan 10 03:00:52 2025 ] 	Mean test loss of 20 batches: 2.2104166209697724.
[ Fri Jan 10 03:00:52 2025 ] 	Top1: 57.95%
[ Fri Jan 10 03:00:52 2025 ] 	Top5: 83.46%
[ Fri Jan 10 03:00:52 2025 ] Training epoch: 70
[ Fri Jan 10 03:03:22 2025 ] 	Mean training loss: 0.8749.  Mean training acc: 95.61%.
[ Fri Jan 10 03:03:22 2025 ] 	Learning Rate: 0.00021408
[ Fri Jan 10 03:03:22 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 03:03:22 2025 ] Eval epoch: 70
[ Fri Jan 10 03:03:30 2025 ] 	Mean test loss of 20 batches: 2.184777534008026.
[ Fri Jan 10 03:03:30 2025 ] 	Top1: 58.47%
[ Fri Jan 10 03:03:30 2025 ] 	Top5: 84.10%
[ Fri Jan 10 03:03:30 2025 ] Training epoch: 71
[ Fri Jan 10 03:05:59 2025 ] 	Mean training loss: 0.8721.  Mean training acc: 95.64%.
[ Fri Jan 10 03:05:59 2025 ] 	Learning Rate: 0.00020164
[ Fri Jan 10 03:05:59 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 03:06:00 2025 ] Eval epoch: 71
[ Fri Jan 10 03:06:07 2025 ] 	Mean test loss of 20 batches: 2.204114180803299.
[ Fri Jan 10 03:06:07 2025 ] 	Top1: 58.50%
[ Fri Jan 10 03:06:07 2025 ] 	Top5: 83.48%
[ Fri Jan 10 03:06:07 2025 ] Training epoch: 72
[ Fri Jan 10 03:08:37 2025 ] 	Mean training loss: 0.8692.  Mean training acc: 95.83%.
[ Fri Jan 10 03:08:37 2025 ] 	Learning Rate: 0.00018951
[ Fri Jan 10 03:08:37 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 03:08:37 2025 ] Eval epoch: 72
[ Fri Jan 10 03:08:44 2025 ] 	Mean test loss of 20 batches: 2.1890333235263824.
[ Fri Jan 10 03:08:44 2025 ] 	Top1: 58.27%
[ Fri Jan 10 03:08:44 2025 ] 	Top5: 83.98%
[ Fri Jan 10 03:08:44 2025 ] Training epoch: 73
[ Fri Jan 10 03:11:14 2025 ] 	Mean training loss: 0.8652.  Mean training acc: 95.94%.
[ Fri Jan 10 03:11:14 2025 ] 	Learning Rate: 0.00017768
[ Fri Jan 10 03:11:14 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 03:11:14 2025 ] Eval epoch: 73
[ Fri Jan 10 03:11:20 2025 ] 	Mean test loss of 20 batches: 2.1909317493438722.
[ Fri Jan 10 03:11:20 2025 ] 	Top1: 58.68%
[ Fri Jan 10 03:11:20 2025 ] 	Top5: 83.76%
[ Fri Jan 10 03:11:20 2025 ] Training epoch: 74
[ Fri Jan 10 03:13:47 2025 ] 	Mean training loss: 0.8604.  Mean training acc: 96.03%.
[ Fri Jan 10 03:13:47 2025 ] 	Learning Rate: 0.00016618
[ Fri Jan 10 03:13:47 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:13:47 2025 ] Eval epoch: 74
[ Fri Jan 10 03:13:54 2025 ] 	Mean test loss of 20 batches: 2.203718823194504.
[ Fri Jan 10 03:13:54 2025 ] 	Top1: 58.74%
[ Fri Jan 10 03:13:54 2025 ] 	Top5: 83.71%
[ Fri Jan 10 03:13:54 2025 ] Training epoch: 75
[ Fri Jan 10 03:16:24 2025 ] 	Mean training loss: 0.8543.  Mean training acc: 96.26%.
[ Fri Jan 10 03:16:24 2025 ] 	Learning Rate: 0.00015501
[ Fri Jan 10 03:16:24 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 03:16:24 2025 ] Eval epoch: 75
[ Fri Jan 10 03:16:30 2025 ] 	Mean test loss of 20 batches: 2.206296718120575.
[ Fri Jan 10 03:16:30 2025 ] 	Top1: 58.56%
[ Fri Jan 10 03:16:30 2025 ] 	Top5: 83.76%
[ Fri Jan 10 03:16:30 2025 ] Training epoch: 76
[ Fri Jan 10 03:18:56 2025 ] 	Mean training loss: 0.8514.  Mean training acc: 96.43%.
[ Fri Jan 10 03:18:56 2025 ] 	Learning Rate: 0.00014419
[ Fri Jan 10 03:18:56 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:18:56 2025 ] Eval epoch: 76
[ Fri Jan 10 03:19:03 2025 ] 	Mean test loss of 20 batches: 2.176478165388107.
[ Fri Jan 10 03:19:03 2025 ] 	Top1: 59.34%
[ Fri Jan 10 03:19:03 2025 ] 	Top5: 83.58%
[ Fri Jan 10 03:19:03 2025 ] Training epoch: 77
[ Fri Jan 10 03:21:29 2025 ] 	Mean training loss: 0.8474.  Mean training acc: 96.56%.
[ Fri Jan 10 03:21:29 2025 ] 	Learning Rate: 0.00013372
[ Fri Jan 10 03:21:29 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:21:29 2025 ] Eval epoch: 77
[ Fri Jan 10 03:21:36 2025 ] 	Mean test loss of 20 batches: 2.20210622549057.
[ Fri Jan 10 03:21:36 2025 ] 	Top1: 58.63%
[ Fri Jan 10 03:21:36 2025 ] 	Top5: 84.28%
[ Fri Jan 10 03:21:36 2025 ] Training epoch: 78
[ Fri Jan 10 03:24:02 2025 ] 	Mean training loss: 0.8393.  Mean training acc: 96.76%.
[ Fri Jan 10 03:24:02 2025 ] 	Learning Rate: 0.00012362
[ Fri Jan 10 03:24:02 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:24:02 2025 ] Eval epoch: 78
[ Fri Jan 10 03:24:09 2025 ] 	Mean test loss of 20 batches: 2.2084290087223053.
[ Fri Jan 10 03:24:09 2025 ] 	Top1: 58.50%
[ Fri Jan 10 03:24:09 2025 ] 	Top5: 83.26%
[ Fri Jan 10 03:24:09 2025 ] Training epoch: 79
[ Fri Jan 10 03:26:35 2025 ] 	Mean training loss: 0.8386.  Mean training acc: 96.84%.
[ Fri Jan 10 03:26:35 2025 ] 	Learning Rate: 0.00011390
[ Fri Jan 10 03:26:35 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:26:35 2025 ] Eval epoch: 79
[ Fri Jan 10 03:26:42 2025 ] 	Mean test loss of 20 batches: 2.2083866119384767.
[ Fri Jan 10 03:26:42 2025 ] 	Top1: 58.36%
[ Fri Jan 10 03:26:42 2025 ] 	Top5: 83.44%
[ Fri Jan 10 03:26:42 2025 ] Training epoch: 80
[ Fri Jan 10 03:29:08 2025 ] 	Mean training loss: 0.8339.  Mean training acc: 96.97%.
[ Fri Jan 10 03:29:08 2025 ] 	Learning Rate: 0.00010456
[ Fri Jan 10 03:29:08 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:29:08 2025 ] Eval epoch: 80
[ Fri Jan 10 03:29:15 2025 ] 	Mean test loss of 20 batches: 2.207402855157852.
[ Fri Jan 10 03:29:15 2025 ] 	Top1: 58.70%
[ Fri Jan 10 03:29:15 2025 ] 	Top5: 83.80%
[ Fri Jan 10 03:29:15 2025 ] Training epoch: 81
[ Fri Jan 10 03:31:42 2025 ] 	Mean training loss: 0.8302.  Mean training acc: 97.09%.
[ Fri Jan 10 03:31:42 2025 ] 	Learning Rate: 0.00009562
[ Fri Jan 10 03:31:42 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:31:42 2025 ] Eval epoch: 81
[ Fri Jan 10 03:31:48 2025 ] 	Mean test loss of 20 batches: 2.2064478576183317.
[ Fri Jan 10 03:31:49 2025 ] 	Top1: 58.56%
[ Fri Jan 10 03:31:49 2025 ] 	Top5: 83.85%
[ Fri Jan 10 03:31:49 2025 ] Training epoch: 82
[ Fri Jan 10 03:34:15 2025 ] 	Mean training loss: 0.8286.  Mean training acc: 97.19%.
[ Fri Jan 10 03:34:15 2025 ] 	Learning Rate: 0.00008708
[ Fri Jan 10 03:34:15 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:34:15 2025 ] Eval epoch: 82
[ Fri Jan 10 03:34:22 2025 ] 	Mean test loss of 20 batches: 2.215336525440216.
[ Fri Jan 10 03:34:22 2025 ] 	Top1: 58.99%
[ Fri Jan 10 03:34:22 2025 ] 	Top5: 83.46%
[ Fri Jan 10 03:34:22 2025 ] Training epoch: 83
[ Fri Jan 10 03:36:48 2025 ] 	Mean training loss: 0.8247.  Mean training acc: 97.21%.
[ Fri Jan 10 03:36:48 2025 ] 	Learning Rate: 0.00007895
[ Fri Jan 10 03:36:48 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:36:48 2025 ] Eval epoch: 83
[ Fri Jan 10 03:36:55 2025 ] 	Mean test loss of 20 batches: 2.209484785795212.
[ Fri Jan 10 03:36:55 2025 ] 	Top1: 58.63%
[ Fri Jan 10 03:36:55 2025 ] 	Top5: 82.81%
[ Fri Jan 10 03:36:55 2025 ] Training epoch: 84
[ Fri Jan 10 03:39:21 2025 ] 	Mean training loss: 0.8221.  Mean training acc: 97.33%.
[ Fri Jan 10 03:39:21 2025 ] 	Learning Rate: 0.00007125
[ Fri Jan 10 03:39:21 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:39:21 2025 ] Eval epoch: 84
[ Fri Jan 10 03:39:28 2025 ] 	Mean test loss of 20 batches: 2.2151372134685516.
[ Fri Jan 10 03:39:28 2025 ] 	Top1: 58.59%
[ Fri Jan 10 03:39:28 2025 ] 	Top5: 83.76%
[ Fri Jan 10 03:39:28 2025 ] Training epoch: 85
[ Fri Jan 10 03:41:54 2025 ] 	Mean training loss: 0.8173.  Mean training acc: 97.49%.
[ Fri Jan 10 03:41:54 2025 ] 	Learning Rate: 0.00006397
[ Fri Jan 10 03:41:54 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:41:54 2025 ] Eval epoch: 85
[ Fri Jan 10 03:42:01 2025 ] 	Mean test loss of 20 batches: 2.2161813974380493.
[ Fri Jan 10 03:42:01 2025 ] 	Top1: 58.40%
[ Fri Jan 10 03:42:01 2025 ] 	Top5: 83.14%
[ Fri Jan 10 03:42:01 2025 ] Training epoch: 86
[ Fri Jan 10 03:44:27 2025 ] 	Mean training loss: 0.8169.  Mean training acc: 97.50%.
[ Fri Jan 10 03:44:27 2025 ] 	Learning Rate: 0.00005713
[ Fri Jan 10 03:44:27 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:44:27 2025 ] Eval epoch: 86
[ Fri Jan 10 03:44:34 2025 ] 	Mean test loss of 20 batches: 2.21700798869133.
[ Fri Jan 10 03:44:34 2025 ] 	Top1: 58.65%
[ Fri Jan 10 03:44:34 2025 ] 	Top5: 83.06%
[ Fri Jan 10 03:44:34 2025 ] Training epoch: 87
[ Fri Jan 10 03:47:00 2025 ] 	Mean training loss: 0.8152.  Mean training acc: 97.61%.
[ Fri Jan 10 03:47:00 2025 ] 	Learning Rate: 0.00005073
[ Fri Jan 10 03:47:00 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:47:00 2025 ] Eval epoch: 87
[ Fri Jan 10 03:47:07 2025 ] 	Mean test loss of 20 batches: 2.2235632300376893.
[ Fri Jan 10 03:47:07 2025 ] 	Top1: 58.70%
[ Fri Jan 10 03:47:07 2025 ] 	Top5: 83.44%
[ Fri Jan 10 03:47:07 2025 ] Training epoch: 88
[ Fri Jan 10 03:49:33 2025 ] 	Mean training loss: 0.8122.  Mean training acc: 97.67%.
[ Fri Jan 10 03:49:33 2025 ] 	Learning Rate: 0.00004478
[ Fri Jan 10 03:49:33 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:49:33 2025 ] Eval epoch: 88
[ Fri Jan 10 03:49:40 2025 ] 	Mean test loss of 20 batches: 2.205185204744339.
[ Fri Jan 10 03:49:40 2025 ] 	Top1: 58.81%
[ Fri Jan 10 03:49:40 2025 ] 	Top5: 83.71%
[ Fri Jan 10 03:49:40 2025 ] Training epoch: 89
[ Fri Jan 10 03:52:06 2025 ] 	Mean training loss: 0.8104.  Mean training acc: 97.70%.
[ Fri Jan 10 03:52:06 2025 ] 	Learning Rate: 0.00003928
[ Fri Jan 10 03:52:06 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:52:06 2025 ] Eval epoch: 89
[ Fri Jan 10 03:52:12 2025 ] 	Mean test loss of 20 batches: 2.2101200222969055.
[ Fri Jan 10 03:52:12 2025 ] 	Top1: 58.84%
[ Fri Jan 10 03:52:12 2025 ] 	Top5: 83.44%
[ Fri Jan 10 03:52:12 2025 ] Training epoch: 90
[ Fri Jan 10 03:54:39 2025 ] 	Mean training loss: 0.8064.  Mean training acc: 97.89%.
[ Fri Jan 10 03:54:39 2025 ] 	Learning Rate: 0.00003424
[ Fri Jan 10 03:54:39 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:54:39 2025 ] Eval epoch: 90
[ Fri Jan 10 03:54:46 2025 ] 	Mean test loss of 20 batches: 2.2134049415588377.
[ Fri Jan 10 03:54:46 2025 ] 	Top1: 58.83%
[ Fri Jan 10 03:54:46 2025 ] 	Top5: 83.46%
[ Fri Jan 10 03:54:46 2025 ] Training epoch: 91
[ Fri Jan 10 03:57:13 2025 ] 	Mean training loss: 0.8060.  Mean training acc: 97.85%.
[ Fri Jan 10 03:57:13 2025 ] 	Learning Rate: 0.00002967
[ Fri Jan 10 03:57:13 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:57:13 2025 ] Eval epoch: 91
[ Fri Jan 10 03:57:19 2025 ] 	Mean test loss of 20 batches: 2.2182243883609774.
[ Fri Jan 10 03:57:20 2025 ] 	Top1: 58.65%
[ Fri Jan 10 03:57:20 2025 ] 	Top5: 83.55%
[ Fri Jan 10 03:57:20 2025 ] Training epoch: 92
[ Fri Jan 10 03:59:46 2025 ] 	Mean training loss: 0.8064.  Mean training acc: 97.83%.
[ Fri Jan 10 03:59:46 2025 ] 	Learning Rate: 0.00002556
[ Fri Jan 10 03:59:46 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 03:59:46 2025 ] Eval epoch: 92
[ Fri Jan 10 03:59:53 2025 ] 	Mean test loss of 20 batches: 2.2080040991306307.
[ Fri Jan 10 03:59:53 2025 ] 	Top1: 58.66%
[ Fri Jan 10 03:59:53 2025 ] 	Top5: 83.51%
[ Fri Jan 10 03:59:53 2025 ] Training epoch: 93
[ Fri Jan 10 04:02:23 2025 ] 	Mean training loss: 0.8018.  Mean training acc: 98.02%.
[ Fri Jan 10 04:02:23 2025 ] 	Learning Rate: 0.00002193
[ Fri Jan 10 04:02:23 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 04:02:23 2025 ] Eval epoch: 93
[ Fri Jan 10 04:02:31 2025 ] 	Mean test loss of 20 batches: 2.2132381916046144.
[ Fri Jan 10 04:02:31 2025 ] 	Top1: 58.68%
[ Fri Jan 10 04:02:31 2025 ] 	Top5: 83.58%
[ Fri Jan 10 04:02:31 2025 ] Training epoch: 94
[ Fri Jan 10 04:05:02 2025 ] 	Mean training loss: 0.8032.  Mean training acc: 97.99%.
[ Fri Jan 10 04:05:02 2025 ] 	Learning Rate: 0.00001878
[ Fri Jan 10 04:05:02 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Fri Jan 10 04:05:02 2025 ] Eval epoch: 94
[ Fri Jan 10 04:05:09 2025 ] 	Mean test loss of 20 batches: 2.2168953478336335.
[ Fri Jan 10 04:05:09 2025 ] 	Top1: 58.70%
[ Fri Jan 10 04:05:09 2025 ] 	Top5: 83.64%
[ Fri Jan 10 04:05:09 2025 ] Training epoch: 95
[ Fri Jan 10 04:07:35 2025 ] 	Mean training loss: 0.8025.  Mean training acc: 97.94%.
[ Fri Jan 10 04:07:35 2025 ] 	Learning Rate: 0.00001610
[ Fri Jan 10 04:07:35 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 04:07:35 2025 ] Eval epoch: 95
[ Fri Jan 10 04:07:42 2025 ] 	Mean test loss of 20 batches: 2.218281036615372.
[ Fri Jan 10 04:07:42 2025 ] 	Top1: 58.70%
[ Fri Jan 10 04:07:42 2025 ] 	Top5: 83.30%
[ Fri Jan 10 04:07:42 2025 ] Training epoch: 96
[ Fri Jan 10 04:10:09 2025 ] 	Mean training loss: 0.7996.  Mean training acc: 98.07%.
[ Fri Jan 10 04:10:09 2025 ] 	Learning Rate: 0.00001391
[ Fri Jan 10 04:10:09 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 04:10:09 2025 ] Eval epoch: 96
[ Fri Jan 10 04:10:16 2025 ] 	Mean test loss of 20 batches: 2.214457905292511.
[ Fri Jan 10 04:10:16 2025 ] 	Top1: 58.84%
[ Fri Jan 10 04:10:16 2025 ] 	Top5: 83.24%
[ Fri Jan 10 04:10:16 2025 ] Training epoch: 97
[ Fri Jan 10 04:12:42 2025 ] 	Mean training loss: 0.8012.  Mean training acc: 98.00%.
[ Fri Jan 10 04:12:42 2025 ] 	Learning Rate: 0.00001220
[ Fri Jan 10 04:12:42 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 04:12:42 2025 ] Eval epoch: 97
[ Fri Jan 10 04:12:49 2025 ] 	Mean test loss of 20 batches: 2.215065932273865.
[ Fri Jan 10 04:12:49 2025 ] 	Top1: 58.68%
[ Fri Jan 10 04:12:49 2025 ] 	Top5: 83.17%
[ Fri Jan 10 04:12:49 2025 ] Training epoch: 98
[ Fri Jan 10 04:15:16 2025 ] 	Mean training loss: 0.7980.  Mean training acc: 98.13%.
[ Fri Jan 10 04:15:16 2025 ] 	Learning Rate: 0.00001098
[ Fri Jan 10 04:15:16 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 04:15:16 2025 ] Eval epoch: 98
[ Fri Jan 10 04:15:22 2025 ] 	Mean test loss of 20 batches: 2.2147878468036652.
[ Fri Jan 10 04:15:22 2025 ] 	Top1: 58.65%
[ Fri Jan 10 04:15:22 2025 ] 	Top5: 83.24%
[ Fri Jan 10 04:15:22 2025 ] Training epoch: 99
[ Fri Jan 10 04:17:49 2025 ] 	Mean training loss: 0.7994.  Mean training acc: 98.09%.
[ Fri Jan 10 04:17:49 2025 ] 	Learning Rate: 0.00001025
[ Fri Jan 10 04:17:49 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 04:17:49 2025 ] Eval epoch: 99
[ Fri Jan 10 04:17:55 2025 ] 	Mean test loss of 20 batches: 2.219754946231842.
[ Fri Jan 10 04:17:55 2025 ] 	Top1: 58.47%
[ Fri Jan 10 04:17:56 2025 ] 	Top5: 83.23%
[ Fri Jan 10 04:17:56 2025 ] Training epoch: 100
[ Fri Jan 10 04:20:22 2025 ] 	Mean training loss: 0.7985.  Mean training acc: 98.10%.
[ Fri Jan 10 04:20:22 2025 ] 	Learning Rate: 0.00001000
[ Fri Jan 10 04:20:22 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Fri Jan 10 04:20:22 2025 ] Eval epoch: 100
[ Fri Jan 10 04:20:29 2025 ] 	Mean test loss of 20 batches: 2.2161652028560637.
[ Fri Jan 10 04:20:29 2025 ] 	Top1: 58.77%
[ Fri Jan 10 04:20:29 2025 ] 	Top5: 83.37%
[ Fri Jan 10 04:20:36 2025 ] Best accuracy: 0.5934479054779807
[ Fri Jan 10 04:20:36 2025 ] Epoch number: 76
[ Fri Jan 10 04:20:36 2025 ] Model name: ./output/original_48_newPE/
[ Fri Jan 10 04:20:36 2025 ] Model total number of params: 2587198
[ Fri Jan 10 04:20:36 2025 ] Weight decay: 0.1
[ Fri Jan 10 04:20:36 2025 ] Base LR: 0.001
[ Fri Jan 10 04:20:36 2025 ] Batch Size: 288
[ Fri Jan 10 04:20:36 2025 ] Test Batch Size: 288
[ Fri Jan 10 04:20:36 2025 ] seed: 1
[ Thu Feb 13 20:24:25 2025 ] Load weights from output/original_48_newPE/runs-76-29640.pt.
[ Thu Feb 13 20:24:31 2025 ] using warm up, epoch: 25
[ Thu Feb 13 20:25:25 2025 ] Load weights from output/original_48_newPE/runs-76-29640.pt.
[ Thu Feb 13 20:25:31 2025 ] using warm up, epoch: 25
[ Thu Feb 13 20:25:31 2025 ] Parameters:
{'work_dir': './output/original_48_newPE/', 'model_saved_name': './output/original_48_newPE/runs', 'config': './config/SkateFormer_newPE_j_NEW.yaml', 'weights': 'output/original_48_newPE/runs-76-29640.pt', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ma52_NEW.Feeder', 'num_worker': 6, 'train_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'train', 'data_type': 'j', 'repeat': 10, 'p': 0.3, 'debug': False, 'partition': True}, 'test_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'val', 'data_type': 'j', 'repeat': 1, 'partition': True}, 'model': 'model.SkateFormer_newPE.SkateFormer_', 'model_args': {'in_channels': 2, 'num_classes': 52, 'num_people': 1, 'num_points': 48, 'kernel_size': 7, 'num_heads': 32, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.2, 'type_1_size': [8, 12], 'type_2_size': [8, 24], 'type_3_size': [8, 12], 'type_4_size': [8, 24], 'mlp_ratio': 1.0, 'index_t': True}, 'ignore_weights': [], 'base_lr': 0.001, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 25, 'grad_clip': True, 'grad_max': 1.0, 'device': [0], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 100, 'weight_decay': 0.1, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Thu Feb 13 20:25:31 2025 ] # Parameters: 2587198
[ Thu Feb 13 20:25:31 2025 ] Eval epoch: 1
