[ Tue Jan  7 06:08:49 2025 ] using warm up, epoch: 25
[ Tue Jan  7 06:08:50 2025 ] Parameters:
{'work_dir': './output/original_48_4w/', 'model_saved_name': './output/original_48_4w/runs', 'config': './config/SkateFormer_4w_j_NEW.yaml', 'weights': None, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ma52_NEW.Feeder', 'num_worker': 6, 'train_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'train', 'data_type': 'j', 'repeat': 10, 'p': 0.3, 'debug': False, 'partition': True}, 'test_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'val', 'data_type': 'j', 'repeat': 1, 'partition': True}, 'model': 'model.SkateFormer_4w.SkateFormer_', 'model_args': {'in_channels': 2, 'num_classes': 52, 'num_people': 1, 'num_points': 48, 'kernel_size': 7, 'num_heads': 32, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.2, 'type_1_size': [8, 12], 'type_2_size': [8, 24], 'type_3_size': [8, 12], 'type_4_size': [8, 24], 'mlp_ratio': 1.0, 'index_t': True}, 'ignore_weights': [], 'base_lr': 0.001, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 25, 'grad_clip': True, 'grad_max': 1.0, 'device': [0, 1, 2, 3, 4, 5], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 432, 'test_batch_size': 432, 'start_epoch': 0, 'num_epoch': 100, 'weight_decay': 0.1, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Tue Jan  7 06:08:50 2025 ] # Parameters: 2587230
[ Tue Jan  7 06:08:50 2025 ] Training epoch: 1
[ Tue Jan  7 06:10:54 2025 ] using warm up, epoch: 25
[ Tue Jan  7 06:11:18 2025 ] using warm up, epoch: 25
[ Tue Jan  7 06:11:20 2025 ] Parameters:
{'work_dir': './output/original_48_4w/', 'model_saved_name': './output/original_48_4w/runs', 'config': './config/SkateFormer_4w_j_NEW.yaml', 'weights': None, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ma52_NEW.Feeder', 'num_worker': 6, 'train_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'train', 'data_type': 'j', 'repeat': 10, 'p': 0.3, 'debug': False, 'partition': True}, 'test_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'val', 'data_type': 'j', 'repeat': 1, 'partition': True}, 'model': 'model.SkateFormer_4w.SkateFormer_', 'model_args': {'in_channels': 2, 'num_classes': 52, 'num_people': 1, 'num_points': 48, 'kernel_size': 7, 'num_heads': 32, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.2, 'type_1_size': [8, 12], 'type_2_size': [8, 24], 'type_3_size': [8, 12], 'type_4_size': [8, 24], 'mlp_ratio': 1.0, 'index_t': True}, 'ignore_weights': [], 'base_lr': 0.001, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 25, 'grad_clip': True, 'grad_max': 1.0, 'device': [0, 1, 2, 3], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 288, 'test_batch_size': 288, 'start_epoch': 0, 'num_epoch': 100, 'weight_decay': 0.1, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Tue Jan  7 06:11:20 2025 ] # Parameters: 2587230
[ Tue Jan  7 06:11:20 2025 ] Training epoch: 1
[ Tue Jan  7 06:13:58 2025 ] 	Mean training loss: 3.6745.  Mean training acc: 9.50%.
[ Tue Jan  7 06:13:58 2025 ] 	Learning Rate: 0.00003999
[ Tue Jan  7 06:13:58 2025 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jan  7 06:13:58 2025 ] Eval epoch: 1
[ Tue Jan  7 06:14:04 2025 ] 	Mean test loss of 20 batches: 3.376985728740692.
[ Tue Jan  7 06:14:04 2025 ] 	Top1: 13.14%
[ Tue Jan  7 06:14:04 2025 ] 	Top5: 45.17%
[ Tue Jan  7 06:14:04 2025 ] Training epoch: 2
[ Tue Jan  7 06:15:30 2025 ] using warm up, epoch: 25
[ Tue Jan  7 06:16:34 2025 ] 	Mean training loss: 3.2648.  Mean training acc: 15.17%.
[ Tue Jan  7 06:16:34 2025 ] 	Learning Rate: 0.00007999
[ Tue Jan  7 06:16:34 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:16:34 2025 ] Eval epoch: 2
[ Tue Jan  7 06:16:40 2025 ] 	Mean test loss of 20 batches: 4.383470511436462.
[ Tue Jan  7 06:16:40 2025 ] 	Top1: 2.38%
[ Tue Jan  7 06:16:40 2025 ] 	Top5: 11.89%
[ Tue Jan  7 06:16:40 2025 ] Training epoch: 3
[ Tue Jan  7 06:19:10 2025 ] 	Mean training loss: 3.0445.  Mean training acc: 19.80%.
[ Tue Jan  7 06:19:10 2025 ] 	Learning Rate: 0.00011999
[ Tue Jan  7 06:19:10 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:19:10 2025 ] Eval epoch: 3
[ Tue Jan  7 06:19:16 2025 ] 	Mean test loss of 20 batches: 3.018482768535614.
[ Tue Jan  7 06:19:16 2025 ] 	Top1: 20.37%
[ Tue Jan  7 06:19:16 2025 ] 	Top5: 60.20%
[ Tue Jan  7 06:19:16 2025 ] Training epoch: 4
[ Tue Jan  7 06:21:45 2025 ] 	Mean training loss: 2.8457.  Mean training acc: 25.54%.
[ Tue Jan  7 06:21:45 2025 ] 	Learning Rate: 0.00015998
[ Tue Jan  7 06:21:45 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:21:45 2025 ] Eval epoch: 4
[ Tue Jan  7 06:21:52 2025 ] 	Mean test loss of 20 batches: 2.865725100040436.
[ Tue Jan  7 06:21:52 2025 ] 	Top1: 25.81%
[ Tue Jan  7 06:21:52 2025 ] 	Top5: 66.74%
[ Tue Jan  7 06:21:52 2025 ] Training epoch: 5
[ Tue Jan  7 06:24:21 2025 ] 	Mean training loss: 2.7080.  Mean training acc: 29.86%.
[ Tue Jan  7 06:24:21 2025 ] 	Learning Rate: 0.00019998
[ Tue Jan  7 06:24:21 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:24:21 2025 ] Eval epoch: 5
[ Tue Jan  7 06:24:27 2025 ] 	Mean test loss of 20 batches: 2.863748812675476.
[ Tue Jan  7 06:24:27 2025 ] 	Top1: 25.19%
[ Tue Jan  7 06:24:27 2025 ] 	Top5: 66.17%
[ Tue Jan  7 06:24:27 2025 ] Training epoch: 6
[ Tue Jan  7 06:26:56 2025 ] 	Mean training loss: 2.5770.  Mean training acc: 34.06%.
[ Tue Jan  7 06:26:56 2025 ] 	Learning Rate: 0.00023997
[ Tue Jan  7 06:26:56 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:26:56 2025 ] Eval epoch: 6
[ Tue Jan  7 06:27:03 2025 ] 	Mean test loss of 20 batches: 2.611964750289917.
[ Tue Jan  7 06:27:03 2025 ] 	Top1: 34.39%
[ Tue Jan  7 06:27:03 2025 ] 	Top5: 72.57%
[ Tue Jan  7 06:27:03 2025 ] Training epoch: 7
[ Tue Jan  7 06:29:32 2025 ] 	Mean training loss: 2.4473.  Mean training acc: 38.70%.
[ Tue Jan  7 06:29:32 2025 ] 	Learning Rate: 0.00027997
[ Tue Jan  7 06:29:32 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:29:32 2025 ] Eval epoch: 7
[ Tue Jan  7 06:29:38 2025 ] 	Mean test loss of 20 batches: 2.4074026584625243.
[ Tue Jan  7 06:29:38 2025 ] 	Top1: 40.67%
[ Tue Jan  7 06:29:38 2025 ] 	Top5: 79.31%
[ Tue Jan  7 06:29:38 2025 ] Training epoch: 8
[ Tue Jan  7 06:32:08 2025 ] 	Mean training loss: 2.3205.  Mean training acc: 43.06%.
[ Tue Jan  7 06:32:08 2025 ] 	Learning Rate: 0.00031997
[ Tue Jan  7 06:32:08 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:32:08 2025 ] Eval epoch: 8
[ Tue Jan  7 06:32:14 2025 ] 	Mean test loss of 20 batches: 2.407787585258484.
[ Tue Jan  7 06:32:14 2025 ] 	Top1: 41.17%
[ Tue Jan  7 06:32:14 2025 ] 	Top5: 79.52%
[ Tue Jan  7 06:32:14 2025 ] Training epoch: 9
[ Tue Jan  7 06:34:44 2025 ] 	Mean training loss: 2.2024.  Mean training acc: 47.54%.
[ Tue Jan  7 06:34:44 2025 ] 	Learning Rate: 0.00035996
[ Tue Jan  7 06:34:44 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:34:44 2025 ] Eval epoch: 9
[ Tue Jan  7 06:34:51 2025 ] 	Mean test loss of 20 batches: 2.453971970081329.
[ Tue Jan  7 06:34:51 2025 ] 	Top1: 42.28%
[ Tue Jan  7 06:34:51 2025 ] 	Top5: 78.36%
[ Tue Jan  7 06:34:51 2025 ] Training epoch: 10
[ Tue Jan  7 06:37:21 2025 ] 	Mean training loss: 2.1050.  Mean training acc: 50.67%.
[ Tue Jan  7 06:37:21 2025 ] 	Learning Rate: 0.00039996
[ Tue Jan  7 06:37:21 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:37:21 2025 ] Eval epoch: 10
[ Tue Jan  7 06:37:27 2025 ] 	Mean test loss of 20 batches: 2.292560565471649.
[ Tue Jan  7 06:37:27 2025 ] 	Top1: 47.42%
[ Tue Jan  7 06:37:27 2025 ] 	Top5: 81.15%
[ Tue Jan  7 06:37:27 2025 ] Training epoch: 11
[ Tue Jan  7 06:39:57 2025 ] 	Mean training loss: 2.0045.  Mean training acc: 54.31%.
[ Tue Jan  7 06:39:57 2025 ] 	Learning Rate: 0.00043995
[ Tue Jan  7 06:39:57 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:39:57 2025 ] Eval epoch: 11
[ Tue Jan  7 06:40:03 2025 ] 	Mean test loss of 20 batches: 2.252613639831543.
[ Tue Jan  7 06:40:03 2025 ] 	Top1: 48.41%
[ Tue Jan  7 06:40:03 2025 ] 	Top5: 82.19%
[ Tue Jan  7 06:40:03 2025 ] Training epoch: 12
[ Tue Jan  7 06:42:32 2025 ] 	Mean training loss: 1.9116.  Mean training acc: 57.79%.
[ Tue Jan  7 06:42:32 2025 ] 	Learning Rate: 0.00047995
[ Tue Jan  7 06:42:32 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:42:32 2025 ] Eval epoch: 12
[ Tue Jan  7 06:42:38 2025 ] 	Mean test loss of 20 batches: 2.264614814519882.
[ Tue Jan  7 06:42:38 2025 ] 	Top1: 48.94%
[ Tue Jan  7 06:42:38 2025 ] 	Top5: 83.30%
[ Tue Jan  7 06:42:39 2025 ] Training epoch: 13
[ Tue Jan  7 06:45:08 2025 ] 	Mean training loss: 1.8302.  Mean training acc: 60.77%.
[ Tue Jan  7 06:45:08 2025 ] 	Learning Rate: 0.00051995
[ Tue Jan  7 06:45:08 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:45:08 2025 ] Eval epoch: 13
[ Tue Jan  7 06:45:14 2025 ] 	Mean test loss of 20 batches: 2.24247088432312.
[ Tue Jan  7 06:45:14 2025 ] 	Top1: 50.81%
[ Tue Jan  7 06:45:14 2025 ] 	Top5: 82.65%
[ Tue Jan  7 06:45:14 2025 ] Training epoch: 14
[ Tue Jan  7 06:47:44 2025 ] 	Mean training loss: 1.7511.  Mean training acc: 63.65%.
[ Tue Jan  7 06:47:44 2025 ] 	Learning Rate: 0.00055994
[ Tue Jan  7 06:47:44 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:47:44 2025 ] Eval epoch: 14
[ Tue Jan  7 06:47:50 2025 ] 	Mean test loss of 20 batches: 2.1706986248493196.
[ Tue Jan  7 06:47:50 2025 ] 	Top1: 53.17%
[ Tue Jan  7 06:47:50 2025 ] 	Top5: 84.25%
[ Tue Jan  7 06:47:50 2025 ] Training epoch: 15
[ Tue Jan  7 06:50:19 2025 ] 	Mean training loss: 1.6837.  Mean training acc: 66.29%.
[ Tue Jan  7 06:50:19 2025 ] 	Learning Rate: 0.00059994
[ Tue Jan  7 06:50:19 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:50:19 2025 ] Eval epoch: 15
[ Tue Jan  7 06:50:26 2025 ] 	Mean test loss of 20 batches: 2.1912946164608003.
[ Tue Jan  7 06:50:26 2025 ] 	Top1: 53.74%
[ Tue Jan  7 06:50:26 2025 ] 	Top5: 84.57%
[ Tue Jan  7 06:50:26 2025 ] Training epoch: 16
[ Tue Jan  7 06:52:55 2025 ] 	Mean training loss: 1.6217.  Mean training acc: 68.67%.
[ Tue Jan  7 06:52:55 2025 ] 	Learning Rate: 0.00063993
[ Tue Jan  7 06:52:55 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:52:55 2025 ] Eval epoch: 16
[ Tue Jan  7 06:53:02 2025 ] 	Mean test loss of 20 batches: 2.171165007352829.
[ Tue Jan  7 06:53:02 2025 ] 	Top1: 54.89%
[ Tue Jan  7 06:53:02 2025 ] 	Top5: 84.66%
[ Tue Jan  7 06:53:02 2025 ] Training epoch: 17
[ Tue Jan  7 06:55:31 2025 ] 	Mean training loss: 1.5751.  Mean training acc: 70.47%.
[ Tue Jan  7 06:55:31 2025 ] 	Learning Rate: 0.00067993
[ Tue Jan  7 06:55:31 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:55:31 2025 ] Eval epoch: 17
[ Tue Jan  7 06:55:38 2025 ] 	Mean test loss of 20 batches: 2.180345910787582.
[ Tue Jan  7 06:55:38 2025 ] 	Top1: 54.96%
[ Tue Jan  7 06:55:38 2025 ] 	Top5: 85.39%
[ Tue Jan  7 06:55:38 2025 ] Training epoch: 18
[ Tue Jan  7 06:58:07 2025 ] 	Mean training loss: 1.5267.  Mean training acc: 72.25%.
[ Tue Jan  7 06:58:07 2025 ] 	Learning Rate: 0.00071993
[ Tue Jan  7 06:58:07 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 06:58:07 2025 ] Eval epoch: 18
[ Tue Jan  7 06:58:13 2025 ] 	Mean test loss of 20 batches: 2.281801927089691.
[ Tue Jan  7 06:58:13 2025 ] 	Top1: 52.61%
[ Tue Jan  7 06:58:13 2025 ] 	Top5: 83.30%
[ Tue Jan  7 06:58:13 2025 ] Training epoch: 19
[ Tue Jan  7 07:00:42 2025 ] 	Mean training loss: 1.4962.  Mean training acc: 73.52%.
[ Tue Jan  7 07:00:42 2025 ] 	Learning Rate: 0.00075992
[ Tue Jan  7 07:00:42 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 07:00:42 2025 ] Eval epoch: 19
[ Tue Jan  7 07:00:49 2025 ] 	Mean test loss of 20 batches: 2.23719779253006.
[ Tue Jan  7 07:00:49 2025 ] 	Top1: 54.56%
[ Tue Jan  7 07:00:49 2025 ] 	Top5: 84.03%
[ Tue Jan  7 07:00:49 2025 ] Training epoch: 20
[ Tue Jan  7 07:03:18 2025 ] 	Mean training loss: 1.4586.  Mean training acc: 74.89%.
[ Tue Jan  7 07:03:18 2025 ] 	Learning Rate: 0.00079992
[ Tue Jan  7 07:03:18 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 07:03:18 2025 ] Eval epoch: 20
[ Tue Jan  7 07:03:24 2025 ] 	Mean test loss of 20 batches: 2.1795488715171816.
[ Tue Jan  7 07:03:24 2025 ] 	Top1: 54.74%
[ Tue Jan  7 07:03:24 2025 ] 	Top5: 85.34%
[ Tue Jan  7 07:03:24 2025 ] Training epoch: 21
[ Tue Jan  7 07:05:53 2025 ] 	Mean training loss: 1.4326.  Mean training acc: 75.91%.
[ Tue Jan  7 07:05:53 2025 ] 	Learning Rate: 0.00083991
[ Tue Jan  7 07:05:53 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 07:05:53 2025 ] Eval epoch: 21
[ Tue Jan  7 07:06:00 2025 ] 	Mean test loss of 20 batches: 2.227960056066513.
[ Tue Jan  7 07:06:00 2025 ] 	Top1: 54.91%
[ Tue Jan  7 07:06:00 2025 ] 	Top5: 84.16%
[ Tue Jan  7 07:06:00 2025 ] Training epoch: 22
[ Tue Jan  7 07:08:29 2025 ] 	Mean training loss: 1.4105.  Mean training acc: 76.83%.
[ Tue Jan  7 07:08:29 2025 ] 	Learning Rate: 0.00087991
[ Tue Jan  7 07:08:29 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 07:08:29 2025 ] Eval epoch: 22
[ Tue Jan  7 07:08:36 2025 ] 	Mean test loss of 20 batches: 2.185978478193283.
[ Tue Jan  7 07:08:36 2025 ] 	Top1: 55.33%
[ Tue Jan  7 07:08:36 2025 ] 	Top5: 84.80%
[ Tue Jan  7 07:08:36 2025 ] Training epoch: 23
[ Tue Jan  7 07:11:08 2025 ] 	Mean training loss: 1.3913.  Mean training acc: 77.47%.
[ Tue Jan  7 07:11:08 2025 ] 	Learning Rate: 0.00091991
[ Tue Jan  7 07:11:08 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 07:11:08 2025 ] Eval epoch: 23
[ Tue Jan  7 07:11:15 2025 ] 	Mean test loss of 20 batches: 2.266199541091919.
[ Tue Jan  7 07:11:15 2025 ] 	Top1: 53.78%
[ Tue Jan  7 07:11:15 2025 ] 	Top5: 82.67%
[ Tue Jan  7 07:11:15 2025 ] Training epoch: 24
[ Tue Jan  7 07:13:44 2025 ] 	Mean training loss: 1.3696.  Mean training acc: 78.25%.
[ Tue Jan  7 07:13:44 2025 ] 	Learning Rate: 0.00095990
[ Tue Jan  7 07:13:44 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 07:13:44 2025 ] Eval epoch: 24
[ Tue Jan  7 07:13:50 2025 ] 	Mean test loss of 20 batches: 2.2259820640087127.
[ Tue Jan  7 07:13:50 2025 ] 	Top1: 54.55%
[ Tue Jan  7 07:13:50 2025 ] 	Top5: 83.53%
[ Tue Jan  7 07:13:50 2025 ] Training epoch: 25
[ Tue Jan  7 07:16:24 2025 ] 	Mean training loss: 1.3472.  Mean training acc: 79.16%.
[ Tue Jan  7 07:16:24 2025 ] 	Learning Rate: 0.00099990
[ Tue Jan  7 07:16:24 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 07:16:24 2025 ] Eval epoch: 25
[ Tue Jan  7 07:16:31 2025 ] 	Mean test loss of 20 batches: 2.2512607514858245.
[ Tue Jan  7 07:16:31 2025 ] 	Top1: 55.32%
[ Tue Jan  7 07:16:31 2025 ] 	Top5: 84.80%
[ Tue Jan  7 07:16:32 2025 ] Training epoch: 26
[ Tue Jan  7 07:19:03 2025 ] 	Mean training loss: 1.2906.  Mean training acc: 81.27%.
[ Tue Jan  7 07:19:03 2025 ] 	Learning Rate: 0.00084388
[ Tue Jan  7 07:19:03 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 07:19:03 2025 ] Eval epoch: 26
[ Tue Jan  7 07:19:11 2025 ] 	Mean test loss of 20 batches: 2.1751101851463317.
[ Tue Jan  7 07:19:11 2025 ] 	Top1: 56.86%
[ Tue Jan  7 07:19:11 2025 ] 	Top5: 84.82%
[ Tue Jan  7 07:19:11 2025 ] Training epoch: 27
[ Tue Jan  7 07:21:43 2025 ] 	Mean training loss: 1.2587.  Mean training acc: 82.52%.
[ Tue Jan  7 07:21:43 2025 ] 	Learning Rate: 0.00083238
[ Tue Jan  7 07:21:43 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 07:21:43 2025 ] Eval epoch: 27
[ Tue Jan  7 07:21:51 2025 ] 	Mean test loss of 20 batches: 2.202414554357529.
[ Tue Jan  7 07:21:51 2025 ] 	Top1: 56.14%
[ Tue Jan  7 07:21:51 2025 ] 	Top5: 84.48%
[ Tue Jan  7 07:21:51 2025 ] Training epoch: 28
[ Tue Jan  7 07:24:22 2025 ] 	Mean training loss: 1.2373.  Mean training acc: 83.30%.
[ Tue Jan  7 07:24:22 2025 ] 	Learning Rate: 0.00082056
[ Tue Jan  7 07:24:22 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 07:24:22 2025 ] Eval epoch: 28
[ Tue Jan  7 07:24:30 2025 ] 	Mean test loss of 20 batches: 2.251247876882553.
[ Tue Jan  7 07:24:30 2025 ] 	Top1: 55.94%
[ Tue Jan  7 07:24:30 2025 ] 	Top5: 83.12%
[ Tue Jan  7 07:24:30 2025 ] Training epoch: 29
[ Tue Jan  7 07:27:02 2025 ] 	Mean training loss: 1.2205.  Mean training acc: 83.95%.
[ Tue Jan  7 07:27:02 2025 ] 	Learning Rate: 0.00080842
[ Tue Jan  7 07:27:02 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 07:27:02 2025 ] Eval epoch: 29
[ Tue Jan  7 07:27:09 2025 ] 	Mean test loss of 20 batches: 2.187190389633179.
[ Tue Jan  7 07:27:09 2025 ] 	Top1: 57.29%
[ Tue Jan  7 07:27:09 2025 ] 	Top5: 85.05%
[ Tue Jan  7 07:27:09 2025 ] Training epoch: 30
[ Tue Jan  7 07:29:41 2025 ] 	Mean training loss: 1.2038.  Mean training acc: 84.56%.
[ Tue Jan  7 07:29:41 2025 ] 	Learning Rate: 0.00079599
[ Tue Jan  7 07:29:41 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 07:29:41 2025 ] Eval epoch: 30
[ Tue Jan  7 07:29:48 2025 ] 	Mean test loss of 20 batches: 2.1737750351428984.
[ Tue Jan  7 07:29:48 2025 ] 	Top1: 56.66%
[ Tue Jan  7 07:29:48 2025 ] 	Top5: 84.71%
[ Tue Jan  7 07:29:48 2025 ] Training epoch: 31
[ Tue Jan  7 07:32:21 2025 ] 	Mean training loss: 1.1856.  Mean training acc: 85.23%.
[ Tue Jan  7 07:32:21 2025 ] 	Learning Rate: 0.00078326
[ Tue Jan  7 07:32:21 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 07:32:21 2025 ] Eval epoch: 31
[ Tue Jan  7 07:32:29 2025 ] 	Mean test loss of 20 batches: 2.2559724152088165.
[ Tue Jan  7 07:32:29 2025 ] 	Top1: 55.60%
[ Tue Jan  7 07:32:29 2025 ] 	Top5: 83.78%
[ Tue Jan  7 07:32:29 2025 ] Training epoch: 32
[ Tue Jan  7 07:35:02 2025 ] 	Mean training loss: 1.1781.  Mean training acc: 85.39%.
[ Tue Jan  7 07:35:02 2025 ] 	Learning Rate: 0.00077027
[ Tue Jan  7 07:35:02 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 07:35:02 2025 ] Eval epoch: 32
[ Tue Jan  7 07:35:10 2025 ] 	Mean test loss of 20 batches: 2.2582236170768737.
[ Tue Jan  7 07:35:10 2025 ] 	Top1: 56.37%
[ Tue Jan  7 07:35:10 2025 ] 	Top5: 83.64%
[ Tue Jan  7 07:35:10 2025 ] Training epoch: 33
[ Tue Jan  7 07:37:38 2025 ] 	Mean training loss: 1.1583.  Mean training acc: 86.17%.
[ Tue Jan  7 07:37:38 2025 ] 	Learning Rate: 0.00075701
[ Tue Jan  7 07:37:38 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 07:37:38 2025 ] Eval epoch: 33
[ Tue Jan  7 07:37:45 2025 ] 	Mean test loss of 20 batches: 2.151295244693756.
[ Tue Jan  7 07:37:45 2025 ] 	Top1: 57.95%
[ Tue Jan  7 07:37:45 2025 ] 	Top5: 84.64%
[ Tue Jan  7 07:37:45 2025 ] Training epoch: 34
[ Tue Jan  7 07:40:14 2025 ] 	Mean training loss: 1.1424.  Mean training acc: 86.67%.
[ Tue Jan  7 07:40:14 2025 ] 	Learning Rate: 0.00074350
[ Tue Jan  7 07:40:14 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 07:40:14 2025 ] Eval epoch: 34
[ Tue Jan  7 07:40:20 2025 ] 	Mean test loss of 20 batches: 2.2109106123447417.
[ Tue Jan  7 07:40:20 2025 ] 	Top1: 56.53%
[ Tue Jan  7 07:40:20 2025 ] 	Top5: 84.17%
[ Tue Jan  7 07:40:20 2025 ] Training epoch: 35
[ Tue Jan  7 07:42:51 2025 ] 	Mean training loss: 1.1281.  Mean training acc: 87.28%.
[ Tue Jan  7 07:42:51 2025 ] 	Learning Rate: 0.00072976
[ Tue Jan  7 07:42:51 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 07:42:51 2025 ] Eval epoch: 35
[ Tue Jan  7 07:42:59 2025 ] 	Mean test loss of 20 batches: 2.1918132662773133.
[ Tue Jan  7 07:42:59 2025 ] 	Top1: 56.02%
[ Tue Jan  7 07:42:59 2025 ] 	Top5: 84.53%
[ Tue Jan  7 07:42:59 2025 ] Training epoch: 36
[ Tue Jan  7 07:45:32 2025 ] 	Mean training loss: 1.1178.  Mean training acc: 87.46%.
[ Tue Jan  7 07:45:32 2025 ] 	Learning Rate: 0.00071580
[ Tue Jan  7 07:45:32 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 07:45:32 2025 ] Eval epoch: 36
[ Tue Jan  7 07:45:38 2025 ] 	Mean test loss of 20 batches: 2.2132580518722533.
[ Tue Jan  7 07:45:38 2025 ] 	Top1: 56.09%
[ Tue Jan  7 07:45:38 2025 ] 	Top5: 83.75%
[ Tue Jan  7 07:45:38 2025 ] Training epoch: 37
[ Tue Jan  7 07:48:10 2025 ] 	Mean training loss: 1.1065.  Mean training acc: 87.93%.
[ Tue Jan  7 07:48:10 2025 ] 	Learning Rate: 0.00070162
[ Tue Jan  7 07:48:10 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 07:48:11 2025 ] Eval epoch: 37
[ Tue Jan  7 07:48:18 2025 ] 	Mean test loss of 20 batches: 2.174188721179962.
[ Tue Jan  7 07:48:18 2025 ] 	Top1: 57.64%
[ Tue Jan  7 07:48:18 2025 ] 	Top5: 84.41%
[ Tue Jan  7 07:48:18 2025 ] Training epoch: 38
[ Tue Jan  7 07:50:50 2025 ] 	Mean training loss: 1.0964.  Mean training acc: 88.31%.
[ Tue Jan  7 07:50:50 2025 ] 	Learning Rate: 0.00068726
[ Tue Jan  7 07:50:50 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 07:50:50 2025 ] Eval epoch: 38
[ Tue Jan  7 07:50:57 2025 ] 	Mean test loss of 20 batches: 2.1698911249637605.
[ Tue Jan  7 07:50:57 2025 ] 	Top1: 58.04%
[ Tue Jan  7 07:50:57 2025 ] 	Top5: 84.91%
[ Tue Jan  7 07:50:57 2025 ] Training epoch: 39
[ Tue Jan  7 07:53:26 2025 ] 	Mean training loss: 1.0843.  Mean training acc: 88.61%.
[ Tue Jan  7 07:53:26 2025 ] 	Learning Rate: 0.00067271
[ Tue Jan  7 07:53:26 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 07:53:26 2025 ] Eval epoch: 39
[ Tue Jan  7 07:53:33 2025 ] 	Mean test loss of 20 batches: 2.2053000032901764.
[ Tue Jan  7 07:53:33 2025 ] 	Top1: 57.02%
[ Tue Jan  7 07:53:33 2025 ] 	Top5: 84.28%
[ Tue Jan  7 07:53:33 2025 ] Training epoch: 40
[ Tue Jan  7 07:56:02 2025 ] 	Mean training loss: 1.0730.  Mean training acc: 89.10%.
[ Tue Jan  7 07:56:02 2025 ] 	Learning Rate: 0.00065800
[ Tue Jan  7 07:56:02 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 07:56:02 2025 ] Eval epoch: 40
[ Tue Jan  7 07:56:08 2025 ] 	Mean test loss of 20 batches: 2.1918135821819305.
[ Tue Jan  7 07:56:08 2025 ] 	Top1: 57.27%
[ Tue Jan  7 07:56:08 2025 ] 	Top5: 83.98%
[ Tue Jan  7 07:56:08 2025 ] Training epoch: 41
[ Tue Jan  7 07:58:38 2025 ] 	Mean training loss: 1.0622.  Mean training acc: 89.50%.
[ Tue Jan  7 07:58:38 2025 ] 	Learning Rate: 0.00064314
[ Tue Jan  7 07:58:38 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 07:58:38 2025 ] Eval epoch: 41
[ Tue Jan  7 07:58:44 2025 ] 	Mean test loss of 20 batches: 2.2083978950977325.
[ Tue Jan  7 07:58:44 2025 ] 	Top1: 56.57%
[ Tue Jan  7 07:58:44 2025 ] 	Top5: 83.80%
[ Tue Jan  7 07:58:44 2025 ] Training epoch: 42
[ Tue Jan  7 08:01:13 2025 ] 	Mean training loss: 1.0525.  Mean training acc: 89.73%.
[ Tue Jan  7 08:01:13 2025 ] 	Learning Rate: 0.00062814
[ Tue Jan  7 08:01:13 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 08:01:13 2025 ] Eval epoch: 42
[ Tue Jan  7 08:01:20 2025 ] 	Mean test loss of 20 batches: 2.1932696402072906.
[ Tue Jan  7 08:01:20 2025 ] 	Top1: 56.77%
[ Tue Jan  7 08:01:20 2025 ] 	Top5: 83.71%
[ Tue Jan  7 08:01:20 2025 ] Training epoch: 43
[ Tue Jan  7 08:03:52 2025 ] 	Mean training loss: 1.0457.  Mean training acc: 89.99%.
[ Tue Jan  7 08:03:52 2025 ] 	Learning Rate: 0.00061302
[ Tue Jan  7 08:03:52 2025 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Jan  7 08:03:52 2025 ] Eval epoch: 43
[ Tue Jan  7 08:03:59 2025 ] 	Mean test loss of 20 batches: 2.1640221416950225.
[ Tue Jan  7 08:03:59 2025 ] 	Top1: 58.06%
[ Tue Jan  7 08:03:59 2025 ] 	Top5: 85.25%
[ Tue Jan  7 08:03:59 2025 ] Training epoch: 44
[ Tue Jan  7 08:06:30 2025 ] 	Mean training loss: 1.0335.  Mean training acc: 90.43%.
[ Tue Jan  7 08:06:30 2025 ] 	Learning Rate: 0.00059779
[ Tue Jan  7 08:06:30 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 08:06:30 2025 ] Eval epoch: 44
[ Tue Jan  7 08:06:38 2025 ] 	Mean test loss of 20 batches: 2.220990723371506.
[ Tue Jan  7 08:06:38 2025 ] 	Top1: 57.39%
[ Tue Jan  7 08:06:38 2025 ] 	Top5: 84.10%
[ Tue Jan  7 08:06:38 2025 ] Training epoch: 45
[ Tue Jan  7 08:09:09 2025 ] 	Mean training loss: 1.0308.  Mean training acc: 90.47%.
[ Tue Jan  7 08:09:09 2025 ] 	Learning Rate: 0.00058247
[ Tue Jan  7 08:09:09 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:09:09 2025 ] Eval epoch: 45
[ Tue Jan  7 08:09:17 2025 ] 	Mean test loss of 20 batches: 2.188634657859802.
[ Tue Jan  7 08:09:17 2025 ] 	Top1: 57.00%
[ Tue Jan  7 08:09:17 2025 ] 	Top5: 84.41%
[ Tue Jan  7 08:09:17 2025 ] Training epoch: 46
[ Tue Jan  7 08:11:49 2025 ] 	Mean training loss: 1.0259.  Mean training acc: 90.56%.
[ Tue Jan  7 08:11:49 2025 ] 	Learning Rate: 0.00056708
[ Tue Jan  7 08:11:49 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:11:49 2025 ] Eval epoch: 46
[ Tue Jan  7 08:11:57 2025 ] 	Mean test loss of 20 batches: 2.1813610076904295.
[ Tue Jan  7 08:11:57 2025 ] 	Top1: 57.12%
[ Tue Jan  7 08:11:57 2025 ] 	Top5: 84.26%
[ Tue Jan  7 08:11:57 2025 ] Training epoch: 47
[ Tue Jan  7 08:14:27 2025 ] 	Mean training loss: 1.0128.  Mean training acc: 91.14%.
[ Tue Jan  7 08:14:27 2025 ] 	Learning Rate: 0.00055162
[ Tue Jan  7 08:14:27 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:14:28 2025 ] Eval epoch: 47
[ Tue Jan  7 08:14:35 2025 ] 	Mean test loss of 20 batches: 2.2113038301467896.
[ Tue Jan  7 08:14:35 2025 ] 	Top1: 56.25%
[ Tue Jan  7 08:14:35 2025 ] 	Top5: 83.44%
[ Tue Jan  7 08:14:35 2025 ] Training epoch: 48
[ Tue Jan  7 08:17:06 2025 ] 	Mean training loss: 1.0024.  Mean training acc: 91.48%.
[ Tue Jan  7 08:17:06 2025 ] 	Learning Rate: 0.00053612
[ Tue Jan  7 08:17:06 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:17:06 2025 ] Eval epoch: 48
[ Tue Jan  7 08:17:14 2025 ] 	Mean test loss of 20 batches: 2.2280608415603638.
[ Tue Jan  7 08:17:14 2025 ] 	Top1: 56.98%
[ Tue Jan  7 08:17:14 2025 ] 	Top5: 83.42%
[ Tue Jan  7 08:17:14 2025 ] Training epoch: 49
[ Tue Jan  7 08:19:46 2025 ] 	Mean training loss: 1.0009.  Mean training acc: 91.46%.
[ Tue Jan  7 08:19:46 2025 ] 	Learning Rate: 0.00052059
[ Tue Jan  7 08:19:46 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:19:46 2025 ] Eval epoch: 49
[ Tue Jan  7 08:19:54 2025 ] 	Mean test loss of 20 batches: 2.1819604873657226.
[ Tue Jan  7 08:19:54 2025 ] 	Top1: 57.82%
[ Tue Jan  7 08:19:54 2025 ] 	Top5: 84.00%
[ Tue Jan  7 08:19:54 2025 ] Training epoch: 50
[ Tue Jan  7 08:22:26 2025 ] 	Mean training loss: 0.9934.  Mean training acc: 91.74%.
[ Tue Jan  7 08:22:26 2025 ] 	Learning Rate: 0.00050504
[ Tue Jan  7 08:22:26 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:22:27 2025 ] Eval epoch: 50
[ Tue Jan  7 08:22:34 2025 ] 	Mean test loss of 20 batches: 2.209168553352356.
[ Tue Jan  7 08:22:34 2025 ] 	Top1: 57.47%
[ Tue Jan  7 08:22:34 2025 ] 	Top5: 84.14%
[ Tue Jan  7 08:22:34 2025 ] Training epoch: 51
[ Tue Jan  7 08:25:06 2025 ] 	Mean training loss: 0.9795.  Mean training acc: 92.26%.
[ Tue Jan  7 08:25:06 2025 ] 	Learning Rate: 0.00048949
[ Tue Jan  7 08:25:06 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:25:06 2025 ] Eval epoch: 51
[ Tue Jan  7 08:25:14 2025 ] 	Mean test loss of 20 batches: 2.188176470994949.
[ Tue Jan  7 08:25:14 2025 ] 	Top1: 57.64%
[ Tue Jan  7 08:25:14 2025 ] 	Top5: 83.92%
[ Tue Jan  7 08:25:14 2025 ] Training epoch: 52
[ Tue Jan  7 08:27:46 2025 ] 	Mean training loss: 0.9751.  Mean training acc: 92.39%.
[ Tue Jan  7 08:27:46 2025 ] 	Learning Rate: 0.00047396
[ Tue Jan  7 08:27:46 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:27:47 2025 ] Eval epoch: 52
[ Tue Jan  7 08:27:54 2025 ] 	Mean test loss of 20 batches: 2.210395860671997.
[ Tue Jan  7 08:27:54 2025 ] 	Top1: 57.16%
[ Tue Jan  7 08:27:54 2025 ] 	Top5: 84.35%
[ Tue Jan  7 08:27:54 2025 ] Training epoch: 53
[ Tue Jan  7 08:30:24 2025 ] 	Mean training loss: 0.9677.  Mean training acc: 92.52%.
[ Tue Jan  7 08:30:24 2025 ] 	Learning Rate: 0.00045846
[ Tue Jan  7 08:30:24 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:30:24 2025 ] Eval epoch: 53
[ Tue Jan  7 08:30:31 2025 ] 	Mean test loss of 20 batches: 2.2121600687503813.
[ Tue Jan  7 08:30:31 2025 ] 	Top1: 56.98%
[ Tue Jan  7 08:30:31 2025 ] 	Top5: 83.89%
[ Tue Jan  7 08:30:32 2025 ] Training epoch: 54
[ Tue Jan  7 08:33:04 2025 ] 	Mean training loss: 0.9621.  Mean training acc: 92.68%.
[ Tue Jan  7 08:33:04 2025 ] 	Learning Rate: 0.00044300
[ Tue Jan  7 08:33:04 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:33:04 2025 ] Eval epoch: 54
[ Tue Jan  7 08:33:11 2025 ] 	Mean test loss of 20 batches: 2.184705525636673.
[ Tue Jan  7 08:33:11 2025 ] 	Top1: 57.61%
[ Tue Jan  7 08:33:11 2025 ] 	Top5: 83.58%
[ Tue Jan  7 08:33:11 2025 ] Training epoch: 55
[ Tue Jan  7 08:35:44 2025 ] 	Mean training loss: 0.9502.  Mean training acc: 93.17%.
[ Tue Jan  7 08:35:44 2025 ] 	Learning Rate: 0.00042760
[ Tue Jan  7 08:35:44 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 08:35:45 2025 ] Eval epoch: 55
[ Tue Jan  7 08:35:51 2025 ] 	Mean test loss of 20 batches: 2.2161807894706724.
[ Tue Jan  7 08:35:51 2025 ] 	Top1: 57.25%
[ Tue Jan  7 08:35:51 2025 ] 	Top5: 83.94%
[ Tue Jan  7 08:35:51 2025 ] Training epoch: 56
[ Tue Jan  7 08:38:24 2025 ] 	Mean training loss: 0.9448.  Mean training acc: 93.38%.
[ Tue Jan  7 08:38:24 2025 ] 	Learning Rate: 0.00041229
[ Tue Jan  7 08:38:24 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:38:24 2025 ] Eval epoch: 56
[ Tue Jan  7 08:38:32 2025 ] 	Mean test loss of 20 batches: 2.2233689546585085.
[ Tue Jan  7 08:38:32 2025 ] 	Top1: 57.04%
[ Tue Jan  7 08:38:32 2025 ] 	Top5: 83.15%
[ Tue Jan  7 08:38:32 2025 ] Training epoch: 57
[ Tue Jan  7 08:41:03 2025 ] 	Mean training loss: 0.9429.  Mean training acc: 93.40%.
[ Tue Jan  7 08:41:03 2025 ] 	Learning Rate: 0.00039706
[ Tue Jan  7 08:41:03 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:41:03 2025 ] Eval epoch: 57
[ Tue Jan  7 08:41:11 2025 ] 	Mean test loss of 20 batches: 2.209129524230957.
[ Tue Jan  7 08:41:11 2025 ] 	Top1: 58.06%
[ Tue Jan  7 08:41:11 2025 ] 	Top5: 83.83%
[ Tue Jan  7 08:41:11 2025 ] Training epoch: 58
[ Tue Jan  7 08:43:41 2025 ] 	Mean training loss: 0.9360.  Mean training acc: 93.60%.
[ Tue Jan  7 08:43:41 2025 ] 	Learning Rate: 0.00038194
[ Tue Jan  7 08:43:41 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:43:41 2025 ] Eval epoch: 58
[ Tue Jan  7 08:43:49 2025 ] 	Mean test loss of 20 batches: 2.192069262266159.
[ Tue Jan  7 08:43:49 2025 ] 	Top1: 57.72%
[ Tue Jan  7 08:43:49 2025 ] 	Top5: 83.49%
[ Tue Jan  7 08:43:49 2025 ] Training epoch: 59
[ Tue Jan  7 08:46:18 2025 ] 	Mean training loss: 0.9270.  Mean training acc: 93.90%.
[ Tue Jan  7 08:46:18 2025 ] 	Learning Rate: 0.00036694
[ Tue Jan  7 08:46:18 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 08:46:18 2025 ] Eval epoch: 59
[ Tue Jan  7 08:46:26 2025 ] 	Mean test loss of 20 batches: 2.2154219150543213.
[ Tue Jan  7 08:46:26 2025 ] 	Top1: 57.45%
[ Tue Jan  7 08:46:26 2025 ] 	Top5: 83.24%
[ Tue Jan  7 08:46:26 2025 ] Training epoch: 60
[ Tue Jan  7 08:48:57 2025 ] 	Mean training loss: 0.9209.  Mean training acc: 94.16%.
[ Tue Jan  7 08:48:57 2025 ] 	Learning Rate: 0.00035207
[ Tue Jan  7 08:48:57 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 08:48:58 2025 ] Eval epoch: 60
[ Tue Jan  7 08:49:04 2025 ] 	Mean test loss of 20 batches: 2.207528740167618.
[ Tue Jan  7 08:49:04 2025 ] 	Top1: 57.41%
[ Tue Jan  7 08:49:04 2025 ] 	Top5: 83.55%
[ Tue Jan  7 08:49:04 2025 ] Training epoch: 61
[ Tue Jan  7 08:51:34 2025 ] 	Mean training loss: 0.9160.  Mean training acc: 94.28%.
[ Tue Jan  7 08:51:34 2025 ] 	Learning Rate: 0.00033736
[ Tue Jan  7 08:51:34 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 08:51:34 2025 ] Eval epoch: 61
[ Tue Jan  7 08:51:41 2025 ] 	Mean test loss of 20 batches: 2.203544944524765.
[ Tue Jan  7 08:51:41 2025 ] 	Top1: 57.61%
[ Tue Jan  7 08:51:41 2025 ] 	Top5: 83.92%
[ Tue Jan  7 08:51:41 2025 ] Training epoch: 62
[ Tue Jan  7 08:54:11 2025 ] 	Mean training loss: 0.9139.  Mean training acc: 94.33%.
[ Tue Jan  7 08:54:11 2025 ] 	Learning Rate: 0.00032282
[ Tue Jan  7 08:54:11 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 08:54:11 2025 ] Eval epoch: 62
[ Tue Jan  7 08:54:17 2025 ] 	Mean test loss of 20 batches: 2.2137313067913054.
[ Tue Jan  7 08:54:17 2025 ] 	Top1: 57.41%
[ Tue Jan  7 08:54:17 2025 ] 	Top5: 83.73%
[ Tue Jan  7 08:54:17 2025 ] Training epoch: 63
[ Tue Jan  7 08:56:47 2025 ] 	Mean training loss: 0.9058.  Mean training acc: 94.60%.
[ Tue Jan  7 08:56:47 2025 ] 	Learning Rate: 0.00030845
[ Tue Jan  7 08:56:47 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 08:56:47 2025 ] Eval epoch: 63
[ Tue Jan  7 08:56:53 2025 ] 	Mean test loss of 20 batches: 2.214893418550491.
[ Tue Jan  7 08:56:53 2025 ] 	Top1: 58.58%
[ Tue Jan  7 08:56:53 2025 ] 	Top5: 83.15%
[ Tue Jan  7 08:56:53 2025 ] Training epoch: 64
[ Tue Jan  7 08:59:24 2025 ] 	Mean training loss: 0.8946.  Mean training acc: 94.96%.
[ Tue Jan  7 08:59:24 2025 ] 	Learning Rate: 0.00029428
[ Tue Jan  7 08:59:24 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 08:59:24 2025 ] Eval epoch: 64
[ Tue Jan  7 08:59:30 2025 ] 	Mean test loss of 20 batches: 2.2046794414520265.
[ Tue Jan  7 08:59:30 2025 ] 	Top1: 58.36%
[ Tue Jan  7 08:59:30 2025 ] 	Top5: 83.60%
[ Tue Jan  7 08:59:30 2025 ] Training epoch: 65
[ Tue Jan  7 09:02:00 2025 ] 	Mean training loss: 0.8914.  Mean training acc: 95.13%.
[ Tue Jan  7 09:02:00 2025 ] 	Learning Rate: 0.00028031
[ Tue Jan  7 09:02:00 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 09:02:00 2025 ] Eval epoch: 65
[ Tue Jan  7 09:02:06 2025 ] 	Mean test loss of 20 batches: 2.2148594677448274.
[ Tue Jan  7 09:02:06 2025 ] 	Top1: 57.25%
[ Tue Jan  7 09:02:06 2025 ] 	Top5: 83.39%
[ Tue Jan  7 09:02:06 2025 ] Training epoch: 66
[ Tue Jan  7 09:04:36 2025 ] 	Mean training loss: 0.8891.  Mean training acc: 95.17%.
[ Tue Jan  7 09:04:36 2025 ] 	Learning Rate: 0.00026657
[ Tue Jan  7 09:04:36 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 09:04:36 2025 ] Eval epoch: 66
[ Tue Jan  7 09:04:43 2025 ] 	Mean test loss of 20 batches: 2.2244289100170134.
[ Tue Jan  7 09:04:43 2025 ] 	Top1: 57.63%
[ Tue Jan  7 09:04:43 2025 ] 	Top5: 82.76%
[ Tue Jan  7 09:04:43 2025 ] Training epoch: 67
[ Tue Jan  7 09:07:13 2025 ] 	Mean training loss: 0.8822.  Mean training acc: 95.35%.
[ Tue Jan  7 09:07:13 2025 ] 	Learning Rate: 0.00025306
[ Tue Jan  7 09:07:13 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 09:07:13 2025 ] Eval epoch: 67
[ Tue Jan  7 09:07:19 2025 ] 	Mean test loss of 20 batches: 2.205731725692749.
[ Tue Jan  7 09:07:19 2025 ] 	Top1: 57.47%
[ Tue Jan  7 09:07:19 2025 ] 	Top5: 83.83%
[ Tue Jan  7 09:07:19 2025 ] Training epoch: 68
[ Tue Jan  7 09:09:53 2025 ] 	Mean training loss: 0.8757.  Mean training acc: 95.61%.
[ Tue Jan  7 09:09:53 2025 ] 	Learning Rate: 0.00023980
[ Tue Jan  7 09:09:53 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 09:09:53 2025 ] Eval epoch: 68
[ Tue Jan  7 09:10:01 2025 ] 	Mean test loss of 20 batches: 2.220675826072693.
[ Tue Jan  7 09:10:01 2025 ] 	Top1: 57.73%
[ Tue Jan  7 09:10:01 2025 ] 	Top5: 83.21%
[ Tue Jan  7 09:10:01 2025 ] Training epoch: 69
[ Tue Jan  7 09:12:31 2025 ] 	Mean training loss: 0.8681.  Mean training acc: 95.81%.
[ Tue Jan  7 09:12:31 2025 ] 	Learning Rate: 0.00022680
[ Tue Jan  7 09:12:31 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 09:12:31 2025 ] Eval epoch: 69
[ Tue Jan  7 09:12:39 2025 ] 	Mean test loss of 20 batches: 2.211504030227661.
[ Tue Jan  7 09:12:39 2025 ] 	Top1: 57.95%
[ Tue Jan  7 09:12:39 2025 ] 	Top5: 83.53%
[ Tue Jan  7 09:12:39 2025 ] Training epoch: 70
[ Tue Jan  7 09:15:12 2025 ] 	Mean training loss: 0.8648.  Mean training acc: 95.91%.
[ Tue Jan  7 09:15:12 2025 ] 	Learning Rate: 0.00021408
[ Tue Jan  7 09:15:12 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 09:15:12 2025 ] Eval epoch: 70
[ Tue Jan  7 09:15:19 2025 ] 	Mean test loss of 20 batches: 2.207331484556198.
[ Tue Jan  7 09:15:19 2025 ] 	Top1: 58.25%
[ Tue Jan  7 09:15:19 2025 ] 	Top5: 83.26%
[ Tue Jan  7 09:15:19 2025 ] Training epoch: 71
[ Tue Jan  7 09:17:51 2025 ] 	Mean training loss: 0.8591.  Mean training acc: 96.14%.
[ Tue Jan  7 09:17:51 2025 ] 	Learning Rate: 0.00020164
[ Tue Jan  7 09:17:51 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 09:17:51 2025 ] Eval epoch: 71
[ Tue Jan  7 09:17:59 2025 ] 	Mean test loss of 20 batches: 2.222202569246292.
[ Tue Jan  7 09:17:59 2025 ] 	Top1: 57.63%
[ Tue Jan  7 09:17:59 2025 ] 	Top5: 83.24%
[ Tue Jan  7 09:17:59 2025 ] Training epoch: 72
[ Tue Jan  7 09:20:29 2025 ] 	Mean training loss: 0.8569.  Mean training acc: 96.20%.
[ Tue Jan  7 09:20:29 2025 ] 	Learning Rate: 0.00018951
[ Tue Jan  7 09:20:29 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 09:20:29 2025 ] Eval epoch: 72
[ Tue Jan  7 09:20:35 2025 ] 	Mean test loss of 20 batches: 2.2072451233863832.
[ Tue Jan  7 09:20:36 2025 ] 	Top1: 58.04%
[ Tue Jan  7 09:20:36 2025 ] 	Top5: 83.10%
[ Tue Jan  7 09:20:36 2025 ] Training epoch: 73
[ Tue Jan  7 09:23:07 2025 ] 	Mean training loss: 0.8515.  Mean training acc: 96.32%.
[ Tue Jan  7 09:23:07 2025 ] 	Learning Rate: 0.00017768
[ Tue Jan  7 09:23:07 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 09:23:07 2025 ] Eval epoch: 73
[ Tue Jan  7 09:23:14 2025 ] 	Mean test loss of 20 batches: 2.2073063611984254.
[ Tue Jan  7 09:23:14 2025 ] 	Top1: 58.16%
[ Tue Jan  7 09:23:14 2025 ] 	Top5: 83.82%
[ Tue Jan  7 09:23:14 2025 ] Training epoch: 74
[ Tue Jan  7 09:25:43 2025 ] 	Mean training loss: 0.8456.  Mean training acc: 96.50%.
[ Tue Jan  7 09:25:43 2025 ] 	Learning Rate: 0.00016618
[ Tue Jan  7 09:25:43 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 09:25:43 2025 ] Eval epoch: 74
[ Tue Jan  7 09:25:50 2025 ] 	Mean test loss of 20 batches: 2.2116704106330873.
[ Tue Jan  7 09:25:50 2025 ] 	Top1: 58.49%
[ Tue Jan  7 09:25:50 2025 ] 	Top5: 83.30%
[ Tue Jan  7 09:25:50 2025 ] Training epoch: 75
[ Tue Jan  7 09:28:23 2025 ] 	Mean training loss: 0.8416.  Mean training acc: 96.72%.
[ Tue Jan  7 09:28:23 2025 ] 	Learning Rate: 0.00015501
[ Tue Jan  7 09:28:23 2025 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Jan  7 09:28:23 2025 ] Eval epoch: 75
[ Tue Jan  7 09:28:29 2025 ] 	Mean test loss of 20 batches: 2.20942559838295.
[ Tue Jan  7 09:28:29 2025 ] 	Top1: 58.45%
[ Tue Jan  7 09:28:30 2025 ] 	Top5: 83.39%
[ Tue Jan  7 09:28:30 2025 ] Training epoch: 76
[ Tue Jan  7 09:31:03 2025 ] 	Mean training loss: 0.8377.  Mean training acc: 96.89%.
[ Tue Jan  7 09:31:03 2025 ] 	Learning Rate: 0.00014419
[ Tue Jan  7 09:31:03 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 09:31:03 2025 ] Eval epoch: 76
[ Tue Jan  7 09:31:10 2025 ] 	Mean test loss of 20 batches: 2.2289644718170165.
[ Tue Jan  7 09:31:10 2025 ] 	Top1: 58.38%
[ Tue Jan  7 09:31:10 2025 ] 	Top5: 83.24%
[ Tue Jan  7 09:31:10 2025 ] Training epoch: 77
[ Tue Jan  7 09:33:42 2025 ] 	Mean training loss: 0.8355.  Mean training acc: 96.95%.
[ Tue Jan  7 09:33:42 2025 ] 	Learning Rate: 0.00013372
[ Tue Jan  7 09:33:42 2025 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Jan  7 09:33:42 2025 ] Eval epoch: 77
[ Tue Jan  7 09:33:49 2025 ] 	Mean test loss of 20 batches: 2.206617701053619.
[ Tue Jan  7 09:33:49 2025 ] 	Top1: 58.32%
[ Tue Jan  7 09:33:49 2025 ] 	Top5: 83.67%
[ Tue Jan  7 09:33:49 2025 ] Training epoch: 78
[ Tue Jan  7 09:36:21 2025 ] 	Mean training loss: 0.8275.  Mean training acc: 97.19%.
[ Tue Jan  7 09:36:21 2025 ] 	Learning Rate: 0.00012362
[ Tue Jan  7 09:36:21 2025 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Jan  7 09:36:21 2025 ] Eval epoch: 78
[ Tue Jan  7 09:36:28 2025 ] 	Mean test loss of 20 batches: 2.2117625415325164.
[ Tue Jan  7 09:36:28 2025 ] 	Top1: 58.61%
[ Tue Jan  7 09:36:28 2025 ] 	Top5: 82.74%
[ Tue Jan  7 09:36:28 2025 ] Training epoch: 79
[ Tue Jan  7 09:38:58 2025 ] 	Mean training loss: 0.8250.  Mean training acc: 97.23%.
[ Tue Jan  7 09:38:58 2025 ] 	Learning Rate: 0.00011390
[ Tue Jan  7 09:38:58 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 09:38:58 2025 ] Eval epoch: 79
[ Tue Jan  7 09:39:06 2025 ] 	Mean test loss of 20 batches: 2.216436821222305.
[ Tue Jan  7 09:39:06 2025 ] 	Top1: 58.47%
[ Tue Jan  7 09:39:06 2025 ] 	Top5: 83.35%
[ Tue Jan  7 09:39:06 2025 ] Training epoch: 80
[ Tue Jan  7 09:41:36 2025 ] 	Mean training loss: 0.8221.  Mean training acc: 97.30%.
[ Tue Jan  7 09:41:36 2025 ] 	Learning Rate: 0.00010456
[ Tue Jan  7 09:41:36 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 09:41:36 2025 ] Eval epoch: 80
[ Tue Jan  7 09:41:44 2025 ] 	Mean test loss of 20 batches: 2.215369349718094.
[ Tue Jan  7 09:41:44 2025 ] 	Top1: 58.25%
[ Tue Jan  7 09:41:44 2025 ] 	Top5: 83.40%
[ Tue Jan  7 09:41:44 2025 ] Training epoch: 81
[ Tue Jan  7 09:44:15 2025 ] 	Mean training loss: 0.8194.  Mean training acc: 97.42%.
[ Tue Jan  7 09:44:15 2025 ] 	Learning Rate: 0.00009562
[ Tue Jan  7 09:44:15 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 09:44:15 2025 ] Eval epoch: 81
[ Tue Jan  7 09:44:22 2025 ] 	Mean test loss of 20 batches: 2.2152762711048126.
[ Tue Jan  7 09:44:22 2025 ] 	Top1: 58.00%
[ Tue Jan  7 09:44:22 2025 ] 	Top5: 82.99%
[ Tue Jan  7 09:44:23 2025 ] Training epoch: 82
[ Tue Jan  7 09:46:54 2025 ] 	Mean training loss: 0.8161.  Mean training acc: 97.51%.
[ Tue Jan  7 09:46:54 2025 ] 	Learning Rate: 0.00008708
[ Tue Jan  7 09:46:54 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 09:46:54 2025 ] Eval epoch: 82
[ Tue Jan  7 09:47:01 2025 ] 	Mean test loss of 20 batches: 2.204444169998169.
[ Tue Jan  7 09:47:01 2025 ] 	Top1: 59.02%
[ Tue Jan  7 09:47:01 2025 ] 	Top5: 83.48%
[ Tue Jan  7 09:47:01 2025 ] Training epoch: 83
[ Tue Jan  7 09:49:31 2025 ] 	Mean training loss: 0.8110.  Mean training acc: 97.71%.
[ Tue Jan  7 09:49:31 2025 ] 	Learning Rate: 0.00007895
[ Tue Jan  7 09:49:31 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 09:49:31 2025 ] Eval epoch: 83
[ Tue Jan  7 09:49:38 2025 ] 	Mean test loss of 20 batches: 2.2153310537338258.
[ Tue Jan  7 09:49:38 2025 ] 	Top1: 58.23%
[ Tue Jan  7 09:49:38 2025 ] 	Top5: 83.21%
[ Tue Jan  7 09:49:38 2025 ] Training epoch: 84
[ Tue Jan  7 09:52:08 2025 ] 	Mean training loss: 0.8106.  Mean training acc: 97.74%.
[ Tue Jan  7 09:52:08 2025 ] 	Learning Rate: 0.00007125
[ Tue Jan  7 09:52:08 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 09:52:08 2025 ] Eval epoch: 84
[ Tue Jan  7 09:52:15 2025 ] 	Mean test loss of 20 batches: 2.2209150314331056.
[ Tue Jan  7 09:52:15 2025 ] 	Top1: 58.07%
[ Tue Jan  7 09:52:15 2025 ] 	Top5: 82.87%
[ Tue Jan  7 09:52:15 2025 ] Training epoch: 85
[ Tue Jan  7 09:54:44 2025 ] 	Mean training loss: 0.8074.  Mean training acc: 97.78%.
[ Tue Jan  7 09:54:44 2025 ] 	Learning Rate: 0.00006397
[ Tue Jan  7 09:54:44 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 09:54:44 2025 ] Eval epoch: 85
[ Tue Jan  7 09:54:51 2025 ] 	Mean test loss of 20 batches: 2.21715949177742.
[ Tue Jan  7 09:54:51 2025 ] 	Top1: 58.04%
[ Tue Jan  7 09:54:51 2025 ] 	Top5: 83.32%
[ Tue Jan  7 09:54:51 2025 ] Training epoch: 86
[ Tue Jan  7 09:57:21 2025 ] 	Mean training loss: 0.8057.  Mean training acc: 97.91%.
[ Tue Jan  7 09:57:21 2025 ] 	Learning Rate: 0.00005713
[ Tue Jan  7 09:57:21 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 09:57:21 2025 ] Eval epoch: 86
[ Tue Jan  7 09:57:27 2025 ] 	Mean test loss of 20 batches: 2.233579295873642.
[ Tue Jan  7 09:57:27 2025 ] 	Top1: 58.29%
[ Tue Jan  7 09:57:27 2025 ] 	Top5: 82.87%
[ Tue Jan  7 09:57:27 2025 ] Training epoch: 87
[ Tue Jan  7 09:59:57 2025 ] 	Mean training loss: 0.8021.  Mean training acc: 97.97%.
[ Tue Jan  7 09:59:57 2025 ] 	Learning Rate: 0.00005073
[ Tue Jan  7 09:59:57 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 09:59:57 2025 ] Eval epoch: 87
[ Tue Jan  7 10:00:03 2025 ] 	Mean test loss of 20 batches: 2.2220485329627992.
[ Tue Jan  7 10:00:03 2025 ] 	Top1: 58.56%
[ Tue Jan  7 10:00:04 2025 ] 	Top5: 83.05%
[ Tue Jan  7 10:00:04 2025 ] Training epoch: 88
[ Tue Jan  7 10:02:33 2025 ] 	Mean training loss: 0.8002.  Mean training acc: 98.03%.
[ Tue Jan  7 10:02:33 2025 ] 	Learning Rate: 0.00004478
[ Tue Jan  7 10:02:33 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 10:02:33 2025 ] Eval epoch: 88
[ Tue Jan  7 10:02:39 2025 ] 	Mean test loss of 20 batches: 2.209330689907074.
[ Tue Jan  7 10:02:40 2025 ] 	Top1: 58.84%
[ Tue Jan  7 10:02:40 2025 ] 	Top5: 83.28%
[ Tue Jan  7 10:02:40 2025 ] Training epoch: 89
[ Tue Jan  7 10:05:12 2025 ] 	Mean training loss: 0.7981.  Mean training acc: 98.12%.
[ Tue Jan  7 10:05:12 2025 ] 	Learning Rate: 0.00003928
[ Tue Jan  7 10:05:12 2025 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue Jan  7 10:05:12 2025 ] Eval epoch: 89
[ Tue Jan  7 10:05:18 2025 ] 	Mean test loss of 20 batches: 2.222915291786194.
[ Tue Jan  7 10:05:18 2025 ] 	Top1: 58.49%
[ Tue Jan  7 10:05:18 2025 ] 	Top5: 82.90%
[ Tue Jan  7 10:05:18 2025 ] Training epoch: 90
[ Tue Jan  7 10:07:47 2025 ] 	Mean training loss: 0.7966.  Mean training acc: 98.14%.
[ Tue Jan  7 10:07:47 2025 ] 	Learning Rate: 0.00003424
[ Tue Jan  7 10:07:47 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 10:07:47 2025 ] Eval epoch: 90
[ Tue Jan  7 10:07:54 2025 ] 	Mean test loss of 20 batches: 2.2206401228904724.
[ Tue Jan  7 10:07:54 2025 ] 	Top1: 58.61%
[ Tue Jan  7 10:07:54 2025 ] 	Top5: 83.05%
[ Tue Jan  7 10:07:54 2025 ] Training epoch: 91
[ Tue Jan  7 10:10:24 2025 ] 	Mean training loss: 0.7939.  Mean training acc: 98.21%.
[ Tue Jan  7 10:10:24 2025 ] 	Learning Rate: 0.00002967
[ Tue Jan  7 10:10:24 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 10:10:24 2025 ] Eval epoch: 91
[ Tue Jan  7 10:10:30 2025 ] 	Mean test loss of 20 batches: 2.2241064727306368.
[ Tue Jan  7 10:10:30 2025 ] 	Top1: 58.75%
[ Tue Jan  7 10:10:30 2025 ] 	Top5: 82.49%
[ Tue Jan  7 10:10:30 2025 ] Training epoch: 92
[ Tue Jan  7 10:13:00 2025 ] 	Mean training loss: 0.7940.  Mean training acc: 98.25%.
[ Tue Jan  7 10:13:00 2025 ] 	Learning Rate: 0.00002556
[ Tue Jan  7 10:13:00 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 10:13:00 2025 ] Eval epoch: 92
[ Tue Jan  7 10:13:07 2025 ] 	Mean test loss of 20 batches: 2.2198722302913665.
[ Tue Jan  7 10:13:07 2025 ] 	Top1: 58.59%
[ Tue Jan  7 10:13:07 2025 ] 	Top5: 83.03%
[ Tue Jan  7 10:13:07 2025 ] Training epoch: 93
[ Tue Jan  7 10:15:37 2025 ] 	Mean training loss: 0.7908.  Mean training acc: 98.35%.
[ Tue Jan  7 10:15:37 2025 ] 	Learning Rate: 0.00002193
[ Tue Jan  7 10:15:37 2025 ] 	Time consumption: [Data]05%, [Network]95%
[ Tue Jan  7 10:15:37 2025 ] Eval epoch: 93
[ Tue Jan  7 10:15:44 2025 ] 	Mean test loss of 20 batches: 2.2229880571365355.
[ Tue Jan  7 10:15:44 2025 ] 	Top1: 58.66%
[ Tue Jan  7 10:15:44 2025 ] 	Top5: 82.96%
[ Tue Jan  7 10:15:44 2025 ] Training epoch: 94
[ Tue Jan  7 10:18:13 2025 ] 	Mean training loss: 0.7908.  Mean training acc: 98.32%.
[ Tue Jan  7 10:18:13 2025 ] 	Learning Rate: 0.00001878
[ Tue Jan  7 10:18:13 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 10:18:13 2025 ] Eval epoch: 94
[ Tue Jan  7 10:18:20 2025 ] 	Mean test loss of 20 batches: 2.2243780970573424.
[ Tue Jan  7 10:18:20 2025 ] 	Top1: 58.58%
[ Tue Jan  7 10:18:20 2025 ] 	Top5: 82.85%
[ Tue Jan  7 10:18:20 2025 ] Training epoch: 95
[ Tue Jan  7 10:20:50 2025 ] 	Mean training loss: 0.7909.  Mean training acc: 98.32%.
[ Tue Jan  7 10:20:50 2025 ] 	Learning Rate: 0.00001610
[ Tue Jan  7 10:20:50 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 10:20:50 2025 ] Eval epoch: 95
[ Tue Jan  7 10:20:56 2025 ] 	Mean test loss of 20 batches: 2.2209041237831117.
[ Tue Jan  7 10:20:56 2025 ] 	Top1: 58.65%
[ Tue Jan  7 10:20:57 2025 ] 	Top5: 82.87%
[ Tue Jan  7 10:20:57 2025 ] Training epoch: 96
[ Tue Jan  7 10:23:26 2025 ] 	Mean training loss: 0.7894.  Mean training acc: 98.35%.
[ Tue Jan  7 10:23:26 2025 ] 	Learning Rate: 0.00001391
[ Tue Jan  7 10:23:26 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 10:23:26 2025 ] Eval epoch: 96
[ Tue Jan  7 10:23:33 2025 ] 	Mean test loss of 20 batches: 2.2210395991802216.
[ Tue Jan  7 10:23:33 2025 ] 	Top1: 58.52%
[ Tue Jan  7 10:23:33 2025 ] 	Top5: 83.06%
[ Tue Jan  7 10:23:33 2025 ] Training epoch: 97
[ Tue Jan  7 10:26:03 2025 ] 	Mean training loss: 0.7880.  Mean training acc: 98.44%.
[ Tue Jan  7 10:26:03 2025 ] 	Learning Rate: 0.00001220
[ Tue Jan  7 10:26:03 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 10:26:03 2025 ] Eval epoch: 97
[ Tue Jan  7 10:26:10 2025 ] 	Mean test loss of 20 batches: 2.226831483840942.
[ Tue Jan  7 10:26:10 2025 ] 	Top1: 58.47%
[ Tue Jan  7 10:26:10 2025 ] 	Top5: 82.83%
[ Tue Jan  7 10:26:10 2025 ] Training epoch: 98
[ Tue Jan  7 10:28:39 2025 ] 	Mean training loss: 0.7889.  Mean training acc: 98.37%.
[ Tue Jan  7 10:28:39 2025 ] 	Learning Rate: 0.00001098
[ Tue Jan  7 10:28:39 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 10:28:40 2025 ] Eval epoch: 98
[ Tue Jan  7 10:28:46 2025 ] 	Mean test loss of 20 batches: 2.2233610689640044.
[ Tue Jan  7 10:28:46 2025 ] 	Top1: 58.49%
[ Tue Jan  7 10:28:46 2025 ] 	Top5: 82.96%
[ Tue Jan  7 10:28:46 2025 ] Training epoch: 99
[ Tue Jan  7 10:31:15 2025 ] 	Mean training loss: 0.7870.  Mean training acc: 98.49%.
[ Tue Jan  7 10:31:15 2025 ] 	Learning Rate: 0.00001025
[ Tue Jan  7 10:31:15 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 10:31:15 2025 ] Eval epoch: 99
[ Tue Jan  7 10:31:22 2025 ] 	Mean test loss of 20 batches: 2.227509194612503.
[ Tue Jan  7 10:31:22 2025 ] 	Top1: 58.38%
[ Tue Jan  7 10:31:22 2025 ] 	Top5: 82.85%
[ Tue Jan  7 10:31:22 2025 ] Training epoch: 100
[ Tue Jan  7 10:33:51 2025 ] 	Mean training loss: 0.7862.  Mean training acc: 98.48%.
[ Tue Jan  7 10:33:51 2025 ] 	Learning Rate: 0.00001000
[ Tue Jan  7 10:33:51 2025 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jan  7 10:33:51 2025 ] Eval epoch: 100
[ Tue Jan  7 10:33:57 2025 ] 	Mean test loss of 20 batches: 2.2306129038333893.
[ Tue Jan  7 10:33:57 2025 ] 	Top1: 58.22%
[ Tue Jan  7 10:33:57 2025 ] 	Top5: 82.87%
[ Tue Jan  7 10:34:04 2025 ] Best accuracy: 0.5902255639097744
[ Tue Jan  7 10:34:04 2025 ] Epoch number: 82
[ Tue Jan  7 10:34:04 2025 ] Model name: ./output/original_48_4w/
[ Tue Jan  7 10:34:04 2025 ] Model total number of params: 2587230
[ Tue Jan  7 10:34:04 2025 ] Weight decay: 0.1
[ Tue Jan  7 10:34:04 2025 ] Base LR: 0.001
[ Tue Jan  7 10:34:04 2025 ] Batch Size: 288
[ Tue Jan  7 10:34:04 2025 ] Test Batch Size: 288
[ Tue Jan  7 10:34:04 2025 ] seed: 1
