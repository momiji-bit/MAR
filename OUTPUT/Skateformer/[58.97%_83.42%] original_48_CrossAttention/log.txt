[ Sat Jan 25 05:30:46 2025 ] # Parameters: 2394108
[ Sat Jan 25 05:30:46 2025 ] Training epoch: 1
[ Sat Jan 25 05:31:25 2025 ] using warm up, epoch: 10
[ Sat Jan 25 05:31:27 2025 ] Parameters:
{'work_dir': './output/original_48_CrossAttention/', 'model_saved_name': './output/original_48_CrossAttention/runs', 'config': './config/SkateFormer_j_CrossAttention_NEW.yaml', 'weights': None, 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ma52_NEW.Feeder', 'num_worker': 6, 'train_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'train', 'data_type': 'j', 'repeat': 10, 'p': 0.3, 'debug': False, 'partition': True}, 'test_feeder_args': {'data_path': 'new_ma52/json', 'label_path': 'val', 'data_type': 'j', 'repeat': 1, 'partition': True}, 'model': 'model.SkateFormer_CrossAttention.SkateFormer_', 'model_args': {'in_channels': 2, 'num_classes': 52, 'num_people': 1, 'num_points': 48, 'kernel_size': 7, 'num_heads': 16, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.3, 'type_1_size': [8, 12], 'type_2_size': [8, 24], 'type_3_size': [8, 12], 'type_4_size': [8, 24], 'mlp_ratio': 0.8, 'index_t': True}, 'ignore_weights': [], 'base_lr': 0.0005, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 10, 'grad_clip': True, 'grad_max': 1.0, 'device': [0, 1, 2, 3], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 80, 'test_batch_size': 80, 'start_epoch': 0, 'num_epoch': 100, 'weight_decay': 0.01, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Sat Jan 25 05:31:27 2025 ] # Parameters: 2394108
[ Sat Jan 25 05:31:27 2025 ] Training epoch: 1
[ Sat Jan 25 05:40:18 2025 ] 	Mean training loss: 3.5532.  Mean training acc: 10.85%.
[ Sat Jan 25 05:40:18 2025 ] 	Learning Rate: 0.00005005
[ Sat Jan 25 05:40:18 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 05:40:18 2025 ] Eval epoch: 1
[ Sat Jan 25 05:40:30 2025 ] 	Mean test loss of 70 batches: 3.195292329788208.
[ Sat Jan 25 05:40:30 2025 ] 	Top1: 16.72%
[ Sat Jan 25 05:40:30 2025 ] 	Top5: 52.63%
[ Sat Jan 25 05:40:30 2025 ] Training epoch: 2
[ Sat Jan 25 05:49:11 2025 ] 	Mean training loss: 3.1122.  Mean training acc: 18.27%.
[ Sat Jan 25 05:49:11 2025 ] 	Learning Rate: 0.00010004
[ Sat Jan 25 05:49:11 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 05:49:11 2025 ] Eval epoch: 2
[ Sat Jan 25 05:49:23 2025 ] 	Mean test loss of 70 batches: 2.8685214042663576.
[ Sat Jan 25 05:49:23 2025 ] 	Top1: 22.79%
[ Sat Jan 25 05:49:23 2025 ] 	Top5: 65.09%
[ Sat Jan 25 05:49:23 2025 ] Training epoch: 3
[ Sat Jan 25 05:58:06 2025 ] 	Mean training loss: 2.8815.  Mean training acc: 24.19%.
[ Sat Jan 25 05:58:06 2025 ] 	Learning Rate: 0.00015003
[ Sat Jan 25 05:58:06 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 05:58:06 2025 ] Eval epoch: 3
[ Sat Jan 25 05:58:18 2025 ] 	Mean test loss of 70 batches: 2.765851526600974.
[ Sat Jan 25 05:58:18 2025 ] 	Top1: 29.32%
[ Sat Jan 25 05:58:18 2025 ] 	Top5: 69.32%
[ Sat Jan 25 05:58:18 2025 ] Training epoch: 4
[ Sat Jan 25 06:07:01 2025 ] 	Mean training loss: 2.6998.  Mean training acc: 30.18%.
[ Sat Jan 25 06:07:01 2025 ] 	Learning Rate: 0.00020002
[ Sat Jan 25 06:07:01 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 06:07:01 2025 ] Eval epoch: 4
[ Sat Jan 25 06:07:13 2025 ] 	Mean test loss of 70 batches: 2.5380436624799456.
[ Sat Jan 25 06:07:13 2025 ] 	Top1: 36.27%
[ Sat Jan 25 06:07:13 2025 ] 	Top5: 75.94%
[ Sat Jan 25 06:07:13 2025 ] Training epoch: 5
[ Sat Jan 25 06:15:56 2025 ] 	Mean training loss: 2.5497.  Mean training acc: 35.58%.
[ Sat Jan 25 06:15:56 2025 ] 	Learning Rate: 0.00025001
[ Sat Jan 25 06:15:56 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 06:15:56 2025 ] Eval epoch: 5
[ Sat Jan 25 06:16:09 2025 ] 	Mean test loss of 70 batches: 2.404857851777758.
[ Sat Jan 25 06:16:09 2025 ] 	Top1: 42.00%
[ Sat Jan 25 06:16:09 2025 ] 	Top5: 78.71%
[ Sat Jan 25 06:16:09 2025 ] Training epoch: 6
[ Sat Jan 25 06:24:51 2025 ] 	Mean training loss: 2.4084.  Mean training acc: 40.72%.
[ Sat Jan 25 06:24:51 2025 ] 	Learning Rate: 0.00030000
[ Sat Jan 25 06:24:51 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 06:24:51 2025 ] Eval epoch: 6
[ Sat Jan 25 06:25:03 2025 ] 	Mean test loss of 70 batches: 2.354518333503178.
[ Sat Jan 25 06:25:03 2025 ] 	Top1: 43.36%
[ Sat Jan 25 06:25:03 2025 ] 	Top5: 80.36%
[ Sat Jan 25 06:25:03 2025 ] Training epoch: 7
[ Sat Jan 25 06:33:44 2025 ] 	Mean training loss: 2.2931.  Mean training acc: 44.89%.
[ Sat Jan 25 06:33:44 2025 ] 	Learning Rate: 0.00034999
[ Sat Jan 25 06:33:44 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 06:33:44 2025 ] Eval epoch: 7
[ Sat Jan 25 06:33:56 2025 ] 	Mean test loss of 70 batches: 2.211612015111106.
[ Sat Jan 25 06:33:56 2025 ] 	Top1: 48.93%
[ Sat Jan 25 06:33:56 2025 ] 	Top5: 82.65%
[ Sat Jan 25 06:33:56 2025 ] Training epoch: 8
[ Sat Jan 25 06:42:37 2025 ] 	Mean training loss: 2.2001.  Mean training acc: 48.21%.
[ Sat Jan 25 06:42:37 2025 ] 	Learning Rate: 0.00039998
[ Sat Jan 25 06:42:37 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 06:42:37 2025 ] Eval epoch: 8
[ Sat Jan 25 06:42:49 2025 ] 	Mean test loss of 70 batches: 2.2098885553223746.
[ Sat Jan 25 06:42:49 2025 ] 	Top1: 49.79%
[ Sat Jan 25 06:42:49 2025 ] 	Top5: 82.55%
[ Sat Jan 25 06:42:49 2025 ] Training epoch: 9
[ Sat Jan 25 06:51:34 2025 ] 	Mean training loss: 2.1238.  Mean training acc: 50.83%.
[ Sat Jan 25 06:51:34 2025 ] 	Learning Rate: 0.00044997
[ Sat Jan 25 06:51:34 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 06:51:34 2025 ] Eval epoch: 9
[ Sat Jan 25 06:51:46 2025 ] 	Mean test loss of 70 batches: 2.1732386674199784.
[ Sat Jan 25 06:51:46 2025 ] 	Top1: 51.63%
[ Sat Jan 25 06:51:46 2025 ] 	Top5: 83.62%
[ Sat Jan 25 06:51:46 2025 ] Training epoch: 10
[ Sat Jan 25 07:00:30 2025 ] 	Mean training loss: 2.0527.  Mean training acc: 53.26%.
[ Sat Jan 25 07:00:30 2025 ] 	Learning Rate: 0.00049996
[ Sat Jan 25 07:00:30 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 07:00:30 2025 ] Eval epoch: 10
[ Sat Jan 25 07:00:42 2025 ] 	Mean test loss of 70 batches: 2.1240799512181963.
[ Sat Jan 25 07:00:42 2025 ] 	Top1: 52.13%
[ Sat Jan 25 07:00:42 2025 ] 	Top5: 84.30%
[ Sat Jan 25 07:00:42 2025 ] Training epoch: 11
[ Sat Jan 25 07:09:25 2025 ] 	Mean training loss: 1.9648.  Mean training acc: 56.21%.
[ Sat Jan 25 07:09:25 2025 ] 	Learning Rate: 0.00048552
[ Sat Jan 25 07:09:25 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 07:09:25 2025 ] Eval epoch: 11
[ Sat Jan 25 07:09:37 2025 ] 	Mean test loss of 70 batches: 2.1255287885665894.
[ Sat Jan 25 07:09:37 2025 ] 	Top1: 53.81%
[ Sat Jan 25 07:09:37 2025 ] 	Top5: 85.03%
[ Sat Jan 25 07:09:37 2025 ] Training epoch: 12
[ Sat Jan 25 07:18:19 2025 ] 	Mean training loss: 1.8854.  Mean training acc: 59.04%.
[ Sat Jan 25 07:18:19 2025 ] 	Learning Rate: 0.00048280
[ Sat Jan 25 07:18:19 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 07:18:19 2025 ] Eval epoch: 12
[ Sat Jan 25 07:18:32 2025 ] 	Mean test loss of 70 batches: 2.0910108072417124.
[ Sat Jan 25 07:18:32 2025 ] 	Top1: 54.10%
[ Sat Jan 25 07:18:32 2025 ] 	Top5: 85.91%
[ Sat Jan 25 07:18:32 2025 ] Training epoch: 13
[ Sat Jan 25 07:27:14 2025 ] 	Mean training loss: 1.8059.  Mean training acc: 62.03%.
[ Sat Jan 25 07:27:14 2025 ] 	Learning Rate: 0.00047985
[ Sat Jan 25 07:27:14 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 07:27:14 2025 ] Eval epoch: 13
[ Sat Jan 25 07:27:26 2025 ] 	Mean test loss of 70 batches: 2.075096254689353.
[ Sat Jan 25 07:27:26 2025 ] 	Top1: 56.02%
[ Sat Jan 25 07:27:26 2025 ] 	Top5: 86.09%
[ Sat Jan 25 07:27:26 2025 ] Training epoch: 14
[ Sat Jan 25 07:36:07 2025 ] 	Mean training loss: 1.7312.  Mean training acc: 64.56%.
[ Sat Jan 25 07:36:07 2025 ] 	Learning Rate: 0.00047668
[ Sat Jan 25 07:36:07 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 07:36:07 2025 ] Eval epoch: 14
[ Sat Jan 25 07:36:19 2025 ] 	Mean test loss of 70 batches: 2.083652489525931.
[ Sat Jan 25 07:36:19 2025 ] 	Top1: 56.46%
[ Sat Jan 25 07:36:19 2025 ] 	Top5: 86.23%
[ Sat Jan 25 07:36:19 2025 ] Training epoch: 15
[ Sat Jan 25 07:45:00 2025 ] 	Mean training loss: 1.6673.  Mean training acc: 67.07%.
[ Sat Jan 25 07:45:00 2025 ] 	Learning Rate: 0.00047330
[ Sat Jan 25 07:45:00 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 07:45:00 2025 ] Eval epoch: 15
[ Sat Jan 25 07:45:12 2025 ] 	Mean test loss of 70 batches: 2.1585278187479293.
[ Sat Jan 25 07:45:12 2025 ] 	Top1: 55.76%
[ Sat Jan 25 07:45:12 2025 ] 	Top5: 85.77%
[ Sat Jan 25 07:45:12 2025 ] Training epoch: 16
[ Sat Jan 25 07:53:54 2025 ] 	Mean training loss: 1.6066.  Mean training acc: 69.47%.
[ Sat Jan 25 07:53:54 2025 ] 	Learning Rate: 0.00046970
[ Sat Jan 25 07:53:54 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 07:53:54 2025 ] Eval epoch: 16
[ Sat Jan 25 07:54:06 2025 ] 	Mean test loss of 70 batches: 2.1326147709574017.
[ Sat Jan 25 07:54:06 2025 ] 	Top1: 55.66%
[ Sat Jan 25 07:54:06 2025 ] 	Top5: 85.80%
[ Sat Jan 25 07:54:06 2025 ] Training epoch: 17
[ Sat Jan 25 08:02:47 2025 ] 	Mean training loss: 1.5560.  Mean training acc: 71.50%.
[ Sat Jan 25 08:02:47 2025 ] 	Learning Rate: 0.00046588
[ Sat Jan 25 08:02:47 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 08:02:47 2025 ] Eval epoch: 17
[ Sat Jan 25 08:02:59 2025 ] 	Mean test loss of 70 batches: 2.1339298214231217.
[ Sat Jan 25 08:02:59 2025 ] 	Top1: 56.23%
[ Sat Jan 25 08:02:59 2025 ] 	Top5: 85.89%
[ Sat Jan 25 08:02:59 2025 ] Training epoch: 18
[ Sat Jan 25 08:11:39 2025 ] 	Mean training loss: 1.5125.  Mean training acc: 73.24%.
[ Sat Jan 25 08:11:39 2025 ] 	Learning Rate: 0.00046186
[ Sat Jan 25 08:11:39 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 08:11:39 2025 ] Eval epoch: 18
[ Sat Jan 25 08:11:51 2025 ] 	Mean test loss of 70 batches: 2.116858765057155.
[ Sat Jan 25 08:11:51 2025 ] 	Top1: 56.36%
[ Sat Jan 25 08:11:51 2025 ] 	Top5: 85.80%
[ Sat Jan 25 08:11:51 2025 ] Training epoch: 19
[ Sat Jan 25 08:20:33 2025 ] 	Mean training loss: 1.4752.  Mean training acc: 74.62%.
[ Sat Jan 25 08:20:33 2025 ] 	Learning Rate: 0.00045764
[ Sat Jan 25 08:20:33 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 08:20:33 2025 ] Eval epoch: 19
[ Sat Jan 25 08:20:45 2025 ] 	Mean test loss of 70 batches: 2.1631454382623945.
[ Sat Jan 25 08:20:45 2025 ] 	Top1: 57.18%
[ Sat Jan 25 08:20:45 2025 ] 	Top5: 84.98%
[ Sat Jan 25 08:20:45 2025 ] Training epoch: 20
[ Sat Jan 25 08:29:26 2025 ] 	Mean training loss: 1.4363.  Mean training acc: 76.11%.
[ Sat Jan 25 08:29:26 2025 ] 	Learning Rate: 0.00045321
[ Sat Jan 25 08:29:26 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 08:29:26 2025 ] Eval epoch: 20
[ Sat Jan 25 08:29:38 2025 ] 	Mean test loss of 70 batches: 2.1482265830039977.
[ Sat Jan 25 08:29:38 2025 ] 	Top1: 57.57%
[ Sat Jan 25 08:29:38 2025 ] 	Top5: 85.68%
[ Sat Jan 25 08:29:38 2025 ] Training epoch: 21
[ Sat Jan 25 08:38:19 2025 ] 	Mean training loss: 1.4022.  Mean training acc: 77.57%.
[ Sat Jan 25 08:38:19 2025 ] 	Learning Rate: 0.00044859
[ Sat Jan 25 08:38:19 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 08:38:19 2025 ] Eval epoch: 21
[ Sat Jan 25 08:38:31 2025 ] 	Mean test loss of 70 batches: 2.1655159882136754.
[ Sat Jan 25 08:38:31 2025 ] 	Top1: 56.66%
[ Sat Jan 25 08:38:31 2025 ] 	Top5: 85.18%
[ Sat Jan 25 08:38:31 2025 ] Training epoch: 22
[ Sat Jan 25 08:47:13 2025 ] 	Mean training loss: 1.3715.  Mean training acc: 78.71%.
[ Sat Jan 25 08:47:13 2025 ] 	Learning Rate: 0.00044378
[ Sat Jan 25 08:47:13 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 08:47:13 2025 ] Eval epoch: 22
[ Sat Jan 25 08:47:25 2025 ] 	Mean test loss of 70 batches: 2.1784592969076972.
[ Sat Jan 25 08:47:25 2025 ] 	Top1: 57.04%
[ Sat Jan 25 08:47:25 2025 ] 	Top5: 84.75%
[ Sat Jan 25 08:47:25 2025 ] Training epoch: 23
[ Sat Jan 25 08:56:09 2025 ] 	Mean training loss: 1.3480.  Mean training acc: 79.50%.
[ Sat Jan 25 08:56:09 2025 ] 	Learning Rate: 0.00043878
[ Sat Jan 25 08:56:09 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 08:56:09 2025 ] Eval epoch: 23
[ Sat Jan 25 08:56:22 2025 ] 	Mean test loss of 70 batches: 2.1799082704952784.
[ Sat Jan 25 08:56:22 2025 ] 	Top1: 57.30%
[ Sat Jan 25 08:56:22 2025 ] 	Top5: 84.98%
[ Sat Jan 25 08:56:22 2025 ] Training epoch: 24
[ Sat Jan 25 09:05:02 2025 ] 	Mean training loss: 1.3262.  Mean training acc: 80.35%.
[ Sat Jan 25 09:05:02 2025 ] 	Learning Rate: 0.00043360
[ Sat Jan 25 09:05:02 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 09:05:02 2025 ] Eval epoch: 24
[ Sat Jan 25 09:05:14 2025 ] 	Mean test loss of 70 batches: 2.1674793362617493.
[ Sat Jan 25 09:05:14 2025 ] 	Top1: 56.71%
[ Sat Jan 25 09:05:14 2025 ] 	Top5: 85.23%
[ Sat Jan 25 09:05:14 2025 ] Training epoch: 25
[ Sat Jan 25 09:13:56 2025 ] 	Mean training loss: 1.2958.  Mean training acc: 81.65%.
[ Sat Jan 25 09:13:56 2025 ] 	Learning Rate: 0.00042825
[ Sat Jan 25 09:13:56 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 09:13:56 2025 ] Eval epoch: 25
[ Sat Jan 25 09:14:08 2025 ] 	Mean test loss of 70 batches: 2.1999311566352846.
[ Sat Jan 25 09:14:08 2025 ] 	Top1: 57.05%
[ Sat Jan 25 09:14:08 2025 ] 	Top5: 84.78%
[ Sat Jan 25 09:14:08 2025 ] Training epoch: 26
[ Sat Jan 25 09:22:51 2025 ] 	Mean training loss: 1.2797.  Mean training acc: 82.11%.
[ Sat Jan 25 09:22:51 2025 ] 	Learning Rate: 0.00042272
[ Sat Jan 25 09:22:51 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 09:22:51 2025 ] Eval epoch: 26
[ Sat Jan 25 09:23:04 2025 ] 	Mean test loss of 70 batches: 2.177736817087446.
[ Sat Jan 25 09:23:04 2025 ] 	Top1: 57.34%
[ Sat Jan 25 09:23:04 2025 ] 	Top5: 85.18%
[ Sat Jan 25 09:23:04 2025 ] Training epoch: 27
[ Sat Jan 25 09:31:44 2025 ] 	Mean training loss: 1.2589.  Mean training acc: 83.01%.
[ Sat Jan 25 09:31:44 2025 ] 	Learning Rate: 0.00041703
[ Sat Jan 25 09:31:44 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 09:31:44 2025 ] Eval epoch: 27
[ Sat Jan 25 09:31:56 2025 ] 	Mean test loss of 70 batches: 2.1826874017715454.
[ Sat Jan 25 09:31:56 2025 ] 	Top1: 56.70%
[ Sat Jan 25 09:31:56 2025 ] 	Top5: 85.14%
[ Sat Jan 25 09:31:57 2025 ] Training epoch: 28
[ Sat Jan 25 09:40:37 2025 ] 	Mean training loss: 1.2420.  Mean training acc: 83.52%.
[ Sat Jan 25 09:40:37 2025 ] 	Learning Rate: 0.00041117
[ Sat Jan 25 09:40:37 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 09:40:37 2025 ] Eval epoch: 28
[ Sat Jan 25 09:40:49 2025 ] 	Mean test loss of 70 batches: 2.1668192437716893.
[ Sat Jan 25 09:40:49 2025 ] 	Top1: 57.39%
[ Sat Jan 25 09:40:49 2025 ] 	Top5: 84.78%
[ Sat Jan 25 09:40:49 2025 ] Training epoch: 29
[ Sat Jan 25 09:49:29 2025 ] 	Mean training loss: 1.2248.  Mean training acc: 84.30%.
[ Sat Jan 25 09:49:29 2025 ] 	Learning Rate: 0.00040517
[ Sat Jan 25 09:49:29 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 09:49:29 2025 ] Eval epoch: 29
[ Sat Jan 25 09:49:41 2025 ] 	Mean test loss of 70 batches: 2.1844376019069127.
[ Sat Jan 25 09:49:41 2025 ] 	Top1: 57.61%
[ Sat Jan 25 09:49:41 2025 ] 	Top5: 84.96%
[ Sat Jan 25 09:49:41 2025 ] Training epoch: 30
[ Sat Jan 25 09:58:23 2025 ] 	Mean training loss: 1.2073.  Mean training acc: 84.90%.
[ Sat Jan 25 09:58:23 2025 ] 	Learning Rate: 0.00039901
[ Sat Jan 25 09:58:23 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 09:58:23 2025 ] Eval epoch: 30
[ Sat Jan 25 09:58:35 2025 ] 	Mean test loss of 70 batches: 2.170871697153364.
[ Sat Jan 25 09:58:35 2025 ] 	Top1: 57.55%
[ Sat Jan 25 09:58:35 2025 ] 	Top5: 84.87%
[ Sat Jan 25 09:58:35 2025 ] Training epoch: 31
[ Sat Jan 25 10:07:15 2025 ] 	Mean training loss: 1.1924.  Mean training acc: 85.30%.
[ Sat Jan 25 10:07:15 2025 ] 	Learning Rate: 0.00039271
[ Sat Jan 25 10:07:15 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 10:07:15 2025 ] Eval epoch: 31
[ Sat Jan 25 10:07:27 2025 ] 	Mean test loss of 70 batches: 2.1670020699501036.
[ Sat Jan 25 10:07:27 2025 ] 	Top1: 57.63%
[ Sat Jan 25 10:07:27 2025 ] 	Top5: 85.28%
[ Sat Jan 25 10:07:27 2025 ] Training epoch: 32
[ Sat Jan 25 10:16:07 2025 ] 	Mean training loss: 1.1797.  Mean training acc: 85.72%.
[ Sat Jan 25 10:16:07 2025 ] 	Learning Rate: 0.00038628
[ Sat Jan 25 10:16:07 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 10:16:07 2025 ] Eval epoch: 32
[ Sat Jan 25 10:16:19 2025 ] 	Mean test loss of 70 batches: 2.2004873701504297.
[ Sat Jan 25 10:16:19 2025 ] 	Top1: 58.04%
[ Sat Jan 25 10:16:19 2025 ] 	Top5: 84.62%
[ Sat Jan 25 10:16:19 2025 ] Training epoch: 33
[ Sat Jan 25 10:25:00 2025 ] 	Mean training loss: 1.1679.  Mean training acc: 86.24%.
[ Sat Jan 25 10:25:00 2025 ] 	Learning Rate: 0.00037972
[ Sat Jan 25 10:25:00 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 10:25:00 2025 ] Eval epoch: 33
[ Sat Jan 25 10:25:12 2025 ] 	Mean test loss of 70 batches: 2.1586945039885386.
[ Sat Jan 25 10:25:12 2025 ] 	Top1: 57.47%
[ Sat Jan 25 10:25:12 2025 ] 	Top5: 85.07%
[ Sat Jan 25 10:25:12 2025 ] Training epoch: 34
[ Sat Jan 25 10:33:53 2025 ] 	Mean training loss: 1.1483.  Mean training acc: 87.01%.
[ Sat Jan 25 10:33:53 2025 ] 	Learning Rate: 0.00037303
[ Sat Jan 25 10:33:53 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 10:33:53 2025 ] Eval epoch: 34
[ Sat Jan 25 10:34:06 2025 ] 	Mean test loss of 70 batches: 2.1713063376290456.
[ Sat Jan 25 10:34:06 2025 ] 	Top1: 57.55%
[ Sat Jan 25 10:34:06 2025 ] 	Top5: 84.73%
[ Sat Jan 25 10:34:06 2025 ] Training epoch: 35
[ Sat Jan 25 10:42:45 2025 ] 	Mean training loss: 1.1404.  Mean training acc: 87.17%.
[ Sat Jan 25 10:42:45 2025 ] 	Learning Rate: 0.00036623
[ Sat Jan 25 10:42:45 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 10:42:45 2025 ] Eval epoch: 35
[ Sat Jan 25 10:42:57 2025 ] 	Mean test loss of 70 batches: 2.192695609160832.
[ Sat Jan 25 10:42:57 2025 ] 	Top1: 57.20%
[ Sat Jan 25 10:42:57 2025 ] 	Top5: 84.28%
[ Sat Jan 25 10:42:57 2025 ] Training epoch: 36
[ Sat Jan 25 10:51:37 2025 ] 	Mean training loss: 1.1244.  Mean training acc: 87.76%.
[ Sat Jan 25 10:51:37 2025 ] 	Learning Rate: 0.00035932
[ Sat Jan 25 10:51:37 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 10:51:37 2025 ] Eval epoch: 36
[ Sat Jan 25 10:51:49 2025 ] 	Mean test loss of 70 batches: 2.1848984633173263.
[ Sat Jan 25 10:51:49 2025 ] 	Top1: 57.72%
[ Sat Jan 25 10:51:49 2025 ] 	Top5: 84.10%
[ Sat Jan 25 10:51:49 2025 ] Training epoch: 37
[ Sat Jan 25 11:00:28 2025 ] 	Mean training loss: 1.1147.  Mean training acc: 88.06%.
[ Sat Jan 25 11:00:28 2025 ] 	Learning Rate: 0.00035231
[ Sat Jan 25 11:00:28 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 11:00:28 2025 ] Eval epoch: 37
[ Sat Jan 25 11:00:40 2025 ] 	Mean test loss of 70 batches: 2.181624417645591.
[ Sat Jan 25 11:00:40 2025 ] 	Top1: 57.70%
[ Sat Jan 25 11:00:40 2025 ] 	Top5: 84.66%
[ Sat Jan 25 11:00:40 2025 ] Training epoch: 38
[ Sat Jan 25 11:09:19 2025 ] 	Mean training loss: 1.1008.  Mean training acc: 88.65%.
[ Sat Jan 25 11:09:19 2025 ] 	Learning Rate: 0.00034520
[ Sat Jan 25 11:09:19 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 11:09:19 2025 ] Eval epoch: 38
[ Sat Jan 25 11:09:31 2025 ] 	Mean test loss of 70 batches: 2.1964739901678905.
[ Sat Jan 25 11:09:31 2025 ] 	Top1: 57.39%
[ Sat Jan 25 11:09:31 2025 ] 	Top5: 84.62%
[ Sat Jan 25 11:09:31 2025 ] Training epoch: 39
[ Sat Jan 25 11:18:12 2025 ] 	Mean training loss: 1.0938.  Mean training acc: 88.83%.
[ Sat Jan 25 11:18:12 2025 ] 	Learning Rate: 0.00033800
[ Sat Jan 25 11:18:12 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 11:18:12 2025 ] Eval epoch: 39
[ Sat Jan 25 11:18:25 2025 ] 	Mean test loss of 70 batches: 2.191160680566515.
[ Sat Jan 25 11:18:25 2025 ] 	Top1: 57.61%
[ Sat Jan 25 11:18:25 2025 ] 	Top5: 84.46%
[ Sat Jan 25 11:18:25 2025 ] Training epoch: 40
[ Sat Jan 25 11:27:06 2025 ] 	Mean training loss: 1.0841.  Mean training acc: 89.26%.
[ Sat Jan 25 11:27:06 2025 ] 	Learning Rate: 0.00033071
[ Sat Jan 25 11:27:06 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 11:27:06 2025 ] Eval epoch: 40
[ Sat Jan 25 11:27:19 2025 ] 	Mean test loss of 70 batches: 2.200424553666796.
[ Sat Jan 25 11:27:19 2025 ] 	Top1: 57.43%
[ Sat Jan 25 11:27:19 2025 ] 	Top5: 84.85%
[ Sat Jan 25 11:27:19 2025 ] Training epoch: 41
[ Sat Jan 25 11:36:00 2025 ] 	Mean training loss: 1.0723.  Mean training acc: 89.54%.
[ Sat Jan 25 11:36:00 2025 ] 	Learning Rate: 0.00032336
[ Sat Jan 25 11:36:00 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 11:36:00 2025 ] Eval epoch: 41
[ Sat Jan 25 11:36:12 2025 ] 	Mean test loss of 70 batches: 2.160160868508475.
[ Sat Jan 25 11:36:12 2025 ] 	Top1: 58.25%
[ Sat Jan 25 11:36:12 2025 ] 	Top5: 84.64%
[ Sat Jan 25 11:36:12 2025 ] Training epoch: 42
[ Sat Jan 25 11:44:51 2025 ] 	Mean training loss: 1.0619.  Mean training acc: 90.02%.
[ Sat Jan 25 11:44:51 2025 ] 	Learning Rate: 0.00031593
[ Sat Jan 25 11:44:51 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 11:44:51 2025 ] Eval epoch: 42
[ Sat Jan 25 11:45:03 2025 ] 	Mean test loss of 70 batches: 2.19601640530995.
[ Sat Jan 25 11:45:03 2025 ] 	Top1: 57.30%
[ Sat Jan 25 11:45:03 2025 ] 	Top5: 84.60%
[ Sat Jan 25 11:45:03 2025 ] Training epoch: 43
[ Sat Jan 25 11:53:43 2025 ] 	Mean training loss: 1.0522.  Mean training acc: 90.31%.
[ Sat Jan 25 11:53:43 2025 ] 	Learning Rate: 0.00030845
[ Sat Jan 25 11:53:43 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 11:53:43 2025 ] Eval epoch: 43
[ Sat Jan 25 11:53:55 2025 ] 	Mean test loss of 70 batches: 2.1865861909730095.
[ Sat Jan 25 11:53:55 2025 ] 	Top1: 57.75%
[ Sat Jan 25 11:53:55 2025 ] 	Top5: 84.28%
[ Sat Jan 25 11:53:55 2025 ] Training epoch: 44
[ Sat Jan 25 12:02:36 2025 ] 	Mean training loss: 1.0440.  Mean training acc: 90.53%.
[ Sat Jan 25 12:02:36 2025 ] 	Learning Rate: 0.00030091
[ Sat Jan 25 12:02:36 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 12:02:36 2025 ] Eval epoch: 44
[ Sat Jan 25 12:02:49 2025 ] 	Mean test loss of 70 batches: 2.196228531428746.
[ Sat Jan 25 12:02:49 2025 ] 	Top1: 57.95%
[ Sat Jan 25 12:02:49 2025 ] 	Top5: 84.34%
[ Sat Jan 25 12:02:49 2025 ] Training epoch: 45
[ Sat Jan 25 12:11:28 2025 ] 	Mean training loss: 1.0374.  Mean training acc: 90.86%.
[ Sat Jan 25 12:11:28 2025 ] 	Learning Rate: 0.00029333
[ Sat Jan 25 12:11:28 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 12:11:28 2025 ] Eval epoch: 45
[ Sat Jan 25 12:11:40 2025 ] 	Mean test loss of 70 batches: 2.196032842567989.
[ Sat Jan 25 12:11:40 2025 ] 	Top1: 58.16%
[ Sat Jan 25 12:11:40 2025 ] 	Top5: 83.80%
[ Sat Jan 25 12:11:40 2025 ] Training epoch: 46
[ Sat Jan 25 12:20:21 2025 ] 	Mean training loss: 1.0274.  Mean training acc: 91.24%.
[ Sat Jan 25 12:20:21 2025 ] 	Learning Rate: 0.00028571
[ Sat Jan 25 12:20:21 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 12:20:21 2025 ] Eval epoch: 46
[ Sat Jan 25 12:20:33 2025 ] 	Mean test loss of 70 batches: 2.202875246320452.
[ Sat Jan 25 12:20:33 2025 ] 	Top1: 57.63%
[ Sat Jan 25 12:20:33 2025 ] 	Top5: 83.66%
[ Sat Jan 25 12:20:33 2025 ] Training epoch: 47
[ Sat Jan 25 12:29:19 2025 ] 	Mean training loss: 1.0195.  Mean training acc: 91.48%.
[ Sat Jan 25 12:29:19 2025 ] 	Learning Rate: 0.00027806
[ Sat Jan 25 12:29:19 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 12:29:19 2025 ] Eval epoch: 47
[ Sat Jan 25 12:29:31 2025 ] 	Mean test loss of 70 batches: 2.200323448862348.
[ Sat Jan 25 12:29:31 2025 ] 	Top1: 57.63%
[ Sat Jan 25 12:29:31 2025 ] 	Top5: 84.09%
[ Sat Jan 25 12:29:31 2025 ] Training epoch: 48
[ Sat Jan 25 12:38:11 2025 ] 	Mean training loss: 1.0123.  Mean training acc: 91.67%.
[ Sat Jan 25 12:38:11 2025 ] 	Learning Rate: 0.00027039
[ Sat Jan 25 12:38:11 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 12:38:11 2025 ] Eval epoch: 48
[ Sat Jan 25 12:38:24 2025 ] 	Mean test loss of 70 batches: 2.203079330921173.
[ Sat Jan 25 12:38:24 2025 ] 	Top1: 58.02%
[ Sat Jan 25 12:38:24 2025 ] 	Top5: 84.55%
[ Sat Jan 25 12:38:24 2025 ] Training epoch: 49
[ Sat Jan 25 12:47:13 2025 ] 	Mean training loss: 1.0025.  Mean training acc: 91.95%.
[ Sat Jan 25 12:47:13 2025 ] 	Learning Rate: 0.00026270
[ Sat Jan 25 12:47:13 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 12:47:13 2025 ] Eval epoch: 49
[ Sat Jan 25 12:47:25 2025 ] 	Mean test loss of 70 batches: 2.1634846227509636.
[ Sat Jan 25 12:47:25 2025 ] 	Top1: 58.47%
[ Sat Jan 25 12:47:25 2025 ] 	Top5: 84.98%
[ Sat Jan 25 12:47:25 2025 ] Training epoch: 50
[ Sat Jan 25 12:56:05 2025 ] 	Mean training loss: 0.9984.  Mean training acc: 92.15%.
[ Sat Jan 25 12:56:05 2025 ] 	Learning Rate: 0.00025501
[ Sat Jan 25 12:56:05 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 12:56:05 2025 ] Eval epoch: 50
[ Sat Jan 25 12:56:17 2025 ] 	Mean test loss of 70 batches: 2.1776790125029426.
[ Sat Jan 25 12:56:17 2025 ] 	Top1: 58.52%
[ Sat Jan 25 12:56:17 2025 ] 	Top5: 84.16%
[ Sat Jan 25 12:56:17 2025 ] Training epoch: 51
[ Sat Jan 25 13:04:55 2025 ] 	Mean training loss: 0.9896.  Mean training acc: 92.45%.
[ Sat Jan 25 13:04:55 2025 ] 	Learning Rate: 0.00024731
[ Sat Jan 25 13:04:55 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 13:04:55 2025 ] Eval epoch: 51
[ Sat Jan 25 13:05:08 2025 ] 	Mean test loss of 70 batches: 2.1829921552113123.
[ Sat Jan 25 13:05:08 2025 ] 	Top1: 57.89%
[ Sat Jan 25 13:05:08 2025 ] 	Top5: 84.19%
[ Sat Jan 25 13:05:08 2025 ] Training epoch: 52
[ Sat Jan 25 13:13:49 2025 ] 	Mean training loss: 0.9782.  Mean training acc: 92.79%.
[ Sat Jan 25 13:13:49 2025 ] 	Learning Rate: 0.00023962
[ Sat Jan 25 13:13:49 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 13:13:49 2025 ] Eval epoch: 52
[ Sat Jan 25 13:14:01 2025 ] 	Mean test loss of 70 batches: 2.2002535598618644.
[ Sat Jan 25 13:14:01 2025 ] 	Top1: 57.66%
[ Sat Jan 25 13:14:01 2025 ] 	Top5: 83.69%
[ Sat Jan 25 13:14:01 2025 ] Training epoch: 53
[ Sat Jan 25 13:22:42 2025 ] 	Mean training loss: 0.9744.  Mean training acc: 93.02%.
[ Sat Jan 25 13:22:42 2025 ] 	Learning Rate: 0.00023195
[ Sat Jan 25 13:22:42 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 13:22:42 2025 ] Eval epoch: 53
[ Sat Jan 25 13:22:55 2025 ] 	Mean test loss of 70 batches: 2.1836927550179617.
[ Sat Jan 25 13:22:55 2025 ] 	Top1: 57.98%
[ Sat Jan 25 13:22:55 2025 ] 	Top5: 83.98%
[ Sat Jan 25 13:22:55 2025 ] Training epoch: 54
[ Sat Jan 25 13:31:35 2025 ] 	Mean training loss: 0.9672.  Mean training acc: 93.17%.
[ Sat Jan 25 13:31:35 2025 ] 	Learning Rate: 0.00022430
[ Sat Jan 25 13:31:35 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 13:31:35 2025 ] Eval epoch: 54
[ Sat Jan 25 13:31:47 2025 ] 	Mean test loss of 70 batches: 2.1901523045131137.
[ Sat Jan 25 13:31:47 2025 ] 	Top1: 58.29%
[ Sat Jan 25 13:31:47 2025 ] 	Top5: 84.05%
[ Sat Jan 25 13:31:47 2025 ] Training epoch: 55
[ Sat Jan 25 13:40:25 2025 ] 	Mean training loss: 0.9606.  Mean training acc: 93.39%.
[ Sat Jan 25 13:40:25 2025 ] 	Learning Rate: 0.00021668
[ Sat Jan 25 13:40:25 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 13:40:26 2025 ] Eval epoch: 55
[ Sat Jan 25 13:40:38 2025 ] 	Mean test loss of 70 batches: 2.187709675516401.
[ Sat Jan 25 13:40:38 2025 ] 	Top1: 58.34%
[ Sat Jan 25 13:40:38 2025 ] 	Top5: 84.07%
[ Sat Jan 25 13:40:38 2025 ] Training epoch: 56
[ Sat Jan 25 13:49:19 2025 ] 	Mean training loss: 0.9540.  Mean training acc: 93.64%.
[ Sat Jan 25 13:49:19 2025 ] 	Learning Rate: 0.00020910
[ Sat Jan 25 13:49:19 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 13:49:19 2025 ] Eval epoch: 56
[ Sat Jan 25 13:49:31 2025 ] 	Mean test loss of 70 batches: 2.193915729863303.
[ Sat Jan 25 13:49:31 2025 ] 	Top1: 58.34%
[ Sat Jan 25 13:49:31 2025 ] 	Top5: 83.53%
[ Sat Jan 25 13:49:31 2025 ] Training epoch: 57
[ Sat Jan 25 13:58:09 2025 ] 	Mean training loss: 0.9502.  Mean training acc: 93.69%.
[ Sat Jan 25 13:58:09 2025 ] 	Learning Rate: 0.00020156
[ Sat Jan 25 13:58:09 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 13:58:09 2025 ] Eval epoch: 57
[ Sat Jan 25 13:58:21 2025 ] 	Mean test loss of 70 batches: 2.185105427673885.
[ Sat Jan 25 13:58:21 2025 ] 	Top1: 58.52%
[ Sat Jan 25 13:58:21 2025 ] 	Top5: 84.00%
[ Sat Jan 25 13:58:21 2025 ] Training epoch: 58
[ Sat Jan 25 14:07:01 2025 ] 	Mean training loss: 0.9434.  Mean training acc: 94.04%.
[ Sat Jan 25 14:07:01 2025 ] 	Learning Rate: 0.00019408
[ Sat Jan 25 14:07:01 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 14:07:01 2025 ] Eval epoch: 58
[ Sat Jan 25 14:07:13 2025 ] 	Mean test loss of 70 batches: 2.2009257810456413.
[ Sat Jan 25 14:07:13 2025 ] 	Top1: 58.22%
[ Sat Jan 25 14:07:13 2025 ] 	Top5: 83.57%
[ Sat Jan 25 14:07:13 2025 ] Training epoch: 59
[ Sat Jan 25 14:15:51 2025 ] 	Mean training loss: 0.9341.  Mean training acc: 94.22%.
[ Sat Jan 25 14:15:51 2025 ] 	Learning Rate: 0.00018665
[ Sat Jan 25 14:15:51 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 14:15:51 2025 ] Eval epoch: 59
[ Sat Jan 25 14:16:03 2025 ] 	Mean test loss of 70 batches: 2.1876983983176097.
[ Sat Jan 25 14:16:03 2025 ] 	Top1: 58.66%
[ Sat Jan 25 14:16:03 2025 ] 	Top5: 84.03%
[ Sat Jan 25 14:16:03 2025 ] Training epoch: 60
[ Sat Jan 25 14:24:45 2025 ] 	Mean training loss: 0.9303.  Mean training acc: 94.37%.
[ Sat Jan 25 14:24:45 2025 ] 	Learning Rate: 0.00017930
[ Sat Jan 25 14:24:45 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 14:24:45 2025 ] Eval epoch: 60
[ Sat Jan 25 14:24:57 2025 ] 	Mean test loss of 70 batches: 2.204372818129403.
[ Sat Jan 25 14:24:57 2025 ] 	Top1: 58.25%
[ Sat Jan 25 14:24:57 2025 ] 	Top5: 84.09%
[ Sat Jan 25 14:24:57 2025 ] Training epoch: 61
[ Sat Jan 25 14:33:38 2025 ] 	Mean training loss: 0.9279.  Mean training acc: 94.49%.
[ Sat Jan 25 14:33:38 2025 ] 	Learning Rate: 0.00017201
[ Sat Jan 25 14:33:38 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 14:33:38 2025 ] Eval epoch: 61
[ Sat Jan 25 14:33:51 2025 ] 	Mean test loss of 70 batches: 2.191272096974509.
[ Sat Jan 25 14:33:51 2025 ] 	Top1: 58.06%
[ Sat Jan 25 14:33:51 2025 ] 	Top5: 83.53%
[ Sat Jan 25 14:33:51 2025 ] Training epoch: 62
[ Sat Jan 25 14:42:31 2025 ] 	Mean training loss: 0.9201.  Mean training acc: 94.68%.
[ Sat Jan 25 14:42:31 2025 ] 	Learning Rate: 0.00016481
[ Sat Jan 25 14:42:31 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 14:42:31 2025 ] Eval epoch: 62
[ Sat Jan 25 14:42:44 2025 ] 	Mean test loss of 70 batches: 2.1913120116506306.
[ Sat Jan 25 14:42:44 2025 ] 	Top1: 57.81%
[ Sat Jan 25 14:42:44 2025 ] 	Top5: 83.53%
[ Sat Jan 25 14:42:44 2025 ] Training epoch: 63
[ Sat Jan 25 14:51:26 2025 ] 	Mean training loss: 0.9146.  Mean training acc: 94.86%.
[ Sat Jan 25 14:51:26 2025 ] 	Learning Rate: 0.00015770
[ Sat Jan 25 14:51:26 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 14:51:26 2025 ] Eval epoch: 63
[ Sat Jan 25 14:51:38 2025 ] 	Mean test loss of 70 batches: 2.20210428919111.
[ Sat Jan 25 14:51:38 2025 ] 	Top1: 58.27%
[ Sat Jan 25 14:51:38 2025 ] 	Top5: 83.87%
[ Sat Jan 25 14:51:38 2025 ] Training epoch: 64
[ Sat Jan 25 15:00:20 2025 ] 	Mean training loss: 0.9120.  Mean training acc: 95.02%.
[ Sat Jan 25 15:00:20 2025 ] 	Learning Rate: 0.00015069
[ Sat Jan 25 15:00:20 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 15:00:20 2025 ] Eval epoch: 64
[ Sat Jan 25 15:00:32 2025 ] 	Mean test loss of 70 batches: 2.1989737136023386.
[ Sat Jan 25 15:00:32 2025 ] 	Top1: 58.74%
[ Sat Jan 25 15:00:32 2025 ] 	Top5: 83.73%
[ Sat Jan 25 15:00:32 2025 ] Training epoch: 65
[ Sat Jan 25 15:09:11 2025 ] 	Mean training loss: 0.9076.  Mean training acc: 95.11%.
[ Sat Jan 25 15:09:11 2025 ] 	Learning Rate: 0.00014378
[ Sat Jan 25 15:09:11 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 15:09:11 2025 ] Eval epoch: 65
[ Sat Jan 25 15:09:23 2025 ] 	Mean test loss of 70 batches: 2.1882586734635487.
[ Sat Jan 25 15:09:23 2025 ] 	Top1: 58.52%
[ Sat Jan 25 15:09:23 2025 ] 	Top5: 83.62%
[ Sat Jan 25 15:09:23 2025 ] Training epoch: 66
[ Sat Jan 25 15:18:05 2025 ] 	Mean training loss: 0.9012.  Mean training acc: 95.29%.
[ Sat Jan 25 15:18:05 2025 ] 	Learning Rate: 0.00013698
[ Sat Jan 25 15:18:05 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 15:18:05 2025 ] Eval epoch: 66
[ Sat Jan 25 15:18:17 2025 ] 	Mean test loss of 70 batches: 2.2030546103204998.
[ Sat Jan 25 15:18:17 2025 ] 	Top1: 58.61%
[ Sat Jan 25 15:18:17 2025 ] 	Top5: 83.76%
[ Sat Jan 25 15:18:17 2025 ] Training epoch: 67
[ Sat Jan 25 15:26:58 2025 ] 	Mean training loss: 0.8979.  Mean training acc: 95.37%.
[ Sat Jan 25 15:26:58 2025 ] 	Learning Rate: 0.00013029
[ Sat Jan 25 15:26:58 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 15:26:58 2025 ] Eval epoch: 67
[ Sat Jan 25 15:27:10 2025 ] 	Mean test loss of 70 batches: 2.1988746438707625.
[ Sat Jan 25 15:27:10 2025 ] 	Top1: 57.86%
[ Sat Jan 25 15:27:10 2025 ] 	Top5: 83.51%
[ Sat Jan 25 15:27:10 2025 ] Training epoch: 68
[ Sat Jan 25 15:35:48 2025 ] 	Mean training loss: 0.8947.  Mean training acc: 95.48%.
[ Sat Jan 25 15:35:48 2025 ] 	Learning Rate: 0.00012373
[ Sat Jan 25 15:35:48 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 15:35:48 2025 ] Eval epoch: 68
[ Sat Jan 25 15:36:00 2025 ] 	Mean test loss of 70 batches: 2.201688723904746.
[ Sat Jan 25 15:36:00 2025 ] 	Top1: 58.13%
[ Sat Jan 25 15:36:00 2025 ] 	Top5: 83.32%
[ Sat Jan 25 15:36:00 2025 ] Training epoch: 69
[ Sat Jan 25 15:44:38 2025 ] 	Mean training loss: 0.8873.  Mean training acc: 95.74%.
[ Sat Jan 25 15:44:38 2025 ] 	Learning Rate: 0.00011729
[ Sat Jan 25 15:44:38 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 15:44:38 2025 ] Eval epoch: 69
[ Sat Jan 25 15:44:50 2025 ] 	Mean test loss of 70 batches: 2.209739191191537.
[ Sat Jan 25 15:44:50 2025 ] 	Top1: 58.15%
[ Sat Jan 25 15:44:50 2025 ] 	Top5: 83.23%
[ Sat Jan 25 15:44:50 2025 ] Training epoch: 70
[ Sat Jan 25 15:53:29 2025 ] 	Mean training loss: 0.8825.  Mean training acc: 95.96%.
[ Sat Jan 25 15:53:29 2025 ] 	Learning Rate: 0.00011100
[ Sat Jan 25 15:53:29 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 15:53:29 2025 ] Eval epoch: 70
[ Sat Jan 25 15:53:42 2025 ] 	Mean test loss of 70 batches: 2.1978064605167935.
[ Sat Jan 25 15:53:42 2025 ] 	Top1: 58.56%
[ Sat Jan 25 15:53:42 2025 ] 	Top5: 83.60%
[ Sat Jan 25 15:53:42 2025 ] Training epoch: 71
[ Sat Jan 25 16:02:21 2025 ] 	Mean training loss: 0.8782.  Mean training acc: 96.04%.
[ Sat Jan 25 16:02:21 2025 ] 	Learning Rate: 0.00010484
[ Sat Jan 25 16:02:21 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 16:02:21 2025 ] Eval epoch: 71
[ Sat Jan 25 16:02:33 2025 ] 	Mean test loss of 70 batches: 2.1863568135670253.
[ Sat Jan 25 16:02:33 2025 ] 	Top1: 58.97%
[ Sat Jan 25 16:02:33 2025 ] 	Top5: 83.42%
[ Sat Jan 25 16:02:33 2025 ] Training epoch: 72
[ Sat Jan 25 16:11:14 2025 ] 	Mean training loss: 0.8775.  Mean training acc: 96.03%.
[ Sat Jan 25 16:11:14 2025 ] 	Learning Rate: 0.00009884
[ Sat Jan 25 16:11:14 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 16:11:14 2025 ] Eval epoch: 72
[ Sat Jan 25 16:11:26 2025 ] 	Mean test loss of 70 batches: 2.1968653883252824.
[ Sat Jan 25 16:11:26 2025 ] 	Top1: 58.86%
[ Sat Jan 25 16:11:26 2025 ] 	Top5: 83.55%
[ Sat Jan 25 16:11:26 2025 ] Training epoch: 73
[ Sat Jan 25 16:20:08 2025 ] 	Mean training loss: 0.8723.  Mean training acc: 96.27%.
[ Sat Jan 25 16:20:08 2025 ] 	Learning Rate: 0.00009298
[ Sat Jan 25 16:20:08 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 16:20:08 2025 ] Eval epoch: 73
[ Sat Jan 25 16:20:20 2025 ] 	Mean test loss of 70 batches: 2.2093960183007377.
[ Sat Jan 25 16:20:20 2025 ] 	Top1: 58.74%
[ Sat Jan 25 16:20:20 2025 ] 	Top5: 83.48%
[ Sat Jan 25 16:20:20 2025 ] Training epoch: 74
[ Sat Jan 25 16:29:03 2025 ] 	Mean training loss: 0.8705.  Mean training acc: 96.30%.
[ Sat Jan 25 16:29:03 2025 ] 	Learning Rate: 0.00008729
[ Sat Jan 25 16:29:03 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 16:29:03 2025 ] Eval epoch: 74
[ Sat Jan 25 16:29:15 2025 ] 	Mean test loss of 70 batches: 2.206829471247537.
[ Sat Jan 25 16:29:15 2025 ] 	Top1: 57.91%
[ Sat Jan 25 16:29:15 2025 ] 	Top5: 83.40%
[ Sat Jan 25 16:29:15 2025 ] Training epoch: 75
[ Sat Jan 25 16:37:57 2025 ] 	Mean training loss: 0.8668.  Mean training acc: 96.39%.
[ Sat Jan 25 16:37:57 2025 ] 	Learning Rate: 0.00008176
[ Sat Jan 25 16:37:57 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 16:37:57 2025 ] Eval epoch: 75
[ Sat Jan 25 16:38:09 2025 ] 	Mean test loss of 70 batches: 2.2084637437547956.
[ Sat Jan 25 16:38:09 2025 ] 	Top1: 58.38%
[ Sat Jan 25 16:38:09 2025 ] 	Top5: 82.98%
[ Sat Jan 25 16:38:09 2025 ] Training epoch: 76
[ Sat Jan 25 16:46:50 2025 ] 	Mean training loss: 0.8651.  Mean training acc: 96.45%.
[ Sat Jan 25 16:46:50 2025 ] 	Learning Rate: 0.00007641
[ Sat Jan 25 16:46:50 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 16:46:50 2025 ] Eval epoch: 76
[ Sat Jan 25 16:47:02 2025 ] 	Mean test loss of 70 batches: 2.211458223206656.
[ Sat Jan 25 16:47:02 2025 ] 	Top1: 58.59%
[ Sat Jan 25 16:47:02 2025 ] 	Top5: 83.17%
[ Sat Jan 25 16:47:02 2025 ] Training epoch: 77
[ Sat Jan 25 16:55:41 2025 ] 	Mean training loss: 0.8618.  Mean training acc: 96.46%.
[ Sat Jan 25 16:55:41 2025 ] 	Learning Rate: 0.00007123
[ Sat Jan 25 16:55:41 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 16:55:41 2025 ] Eval epoch: 77
[ Sat Jan 25 16:55:54 2025 ] 	Mean test loss of 70 batches: 2.2054204327719553.
[ Sat Jan 25 16:55:54 2025 ] 	Top1: 58.09%
[ Sat Jan 25 16:55:54 2025 ] 	Top5: 83.26%
[ Sat Jan 25 16:55:54 2025 ] Training epoch: 78
[ Sat Jan 25 17:04:33 2025 ] 	Mean training loss: 0.8578.  Mean training acc: 96.70%.
[ Sat Jan 25 17:04:33 2025 ] 	Learning Rate: 0.00006623
[ Sat Jan 25 17:04:33 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 17:04:33 2025 ] Eval epoch: 78
[ Sat Jan 25 17:04:45 2025 ] 	Mean test loss of 70 batches: 2.202217216151101.
[ Sat Jan 25 17:04:45 2025 ] 	Top1: 58.68%
[ Sat Jan 25 17:04:45 2025 ] 	Top5: 83.28%
[ Sat Jan 25 17:04:45 2025 ] Training epoch: 79
[ Sat Jan 25 17:13:23 2025 ] 	Mean training loss: 0.8545.  Mean training acc: 96.80%.
[ Sat Jan 25 17:13:23 2025 ] 	Learning Rate: 0.00006142
[ Sat Jan 25 17:13:23 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 17:13:23 2025 ] Eval epoch: 79
[ Sat Jan 25 17:13:35 2025 ] 	Mean test loss of 70 batches: 2.1942155548504423.
[ Sat Jan 25 17:13:35 2025 ] 	Top1: 58.93%
[ Sat Jan 25 17:13:35 2025 ] 	Top5: 83.42%
[ Sat Jan 25 17:13:35 2025 ] Training epoch: 80
[ Sat Jan 25 17:22:15 2025 ] 	Mean training loss: 0.8503.  Mean training acc: 96.94%.
[ Sat Jan 25 17:22:15 2025 ] 	Learning Rate: 0.00005679
[ Sat Jan 25 17:22:15 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 17:22:15 2025 ] Eval epoch: 80
[ Sat Jan 25 17:22:27 2025 ] 	Mean test loss of 70 batches: 2.205572496141706.
[ Sat Jan 25 17:22:28 2025 ] 	Top1: 58.25%
[ Sat Jan 25 17:22:28 2025 ] 	Top5: 83.28%
[ Sat Jan 25 17:22:28 2025 ] Training epoch: 81
[ Sat Jan 25 17:31:06 2025 ] 	Mean training loss: 0.8501.  Mean training acc: 96.88%.
[ Sat Jan 25 17:31:06 2025 ] 	Learning Rate: 0.00005237
[ Sat Jan 25 17:31:06 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 17:31:06 2025 ] Eval epoch: 81
[ Sat Jan 25 17:31:18 2025 ] 	Mean test loss of 70 batches: 2.2186427559171404.
[ Sat Jan 25 17:31:18 2025 ] 	Top1: 58.11%
[ Sat Jan 25 17:31:18 2025 ] 	Top5: 83.17%
[ Sat Jan 25 17:31:18 2025 ] Training epoch: 82
[ Sat Jan 25 17:40:00 2025 ] 	Mean training loss: 0.8465.  Mean training acc: 96.99%.
[ Sat Jan 25 17:40:00 2025 ] 	Learning Rate: 0.00004814
[ Sat Jan 25 17:40:00 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 17:40:00 2025 ] Eval epoch: 82
[ Sat Jan 25 17:40:12 2025 ] 	Mean test loss of 70 batches: 2.2145971468516756.
[ Sat Jan 25 17:40:12 2025 ] 	Top1: 58.18%
[ Sat Jan 25 17:40:12 2025 ] 	Top5: 83.49%
[ Sat Jan 25 17:40:12 2025 ] Training epoch: 83
[ Sat Jan 25 17:48:51 2025 ] 	Mean training loss: 0.8461.  Mean training acc: 97.06%.
[ Sat Jan 25 17:48:51 2025 ] 	Learning Rate: 0.00004412
[ Sat Jan 25 17:48:51 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 17:48:51 2025 ] Eval epoch: 83
[ Sat Jan 25 17:49:04 2025 ] 	Mean test loss of 70 batches: 2.2113263079098293.
[ Sat Jan 25 17:49:04 2025 ] 	Top1: 58.36%
[ Sat Jan 25 17:49:04 2025 ] 	Top5: 83.14%
[ Sat Jan 25 17:49:04 2025 ] Training epoch: 84
[ Sat Jan 25 17:57:43 2025 ] 	Mean training loss: 0.8430.  Mean training acc: 97.14%.
[ Sat Jan 25 17:57:43 2025 ] 	Learning Rate: 0.00004031
[ Sat Jan 25 17:57:43 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 17:57:43 2025 ] Eval epoch: 84
[ Sat Jan 25 17:57:55 2025 ] 	Mean test loss of 70 batches: 2.210459661483765.
[ Sat Jan 25 17:57:56 2025 ] 	Top1: 58.27%
[ Sat Jan 25 17:57:56 2025 ] 	Top5: 83.28%
[ Sat Jan 25 17:57:56 2025 ] Training epoch: 85
[ Sat Jan 25 18:06:43 2025 ] 	Mean training loss: 0.8428.  Mean training acc: 97.08%.
[ Sat Jan 25 18:06:43 2025 ] 	Learning Rate: 0.00003671
[ Sat Jan 25 18:06:43 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 18:06:43 2025 ] Eval epoch: 85
[ Sat Jan 25 18:06:56 2025 ] 	Mean test loss of 70 batches: 2.2076314551489693.
[ Sat Jan 25 18:06:56 2025 ] 	Top1: 58.16%
[ Sat Jan 25 18:06:56 2025 ] 	Top5: 83.46%
[ Sat Jan 25 18:06:56 2025 ] Training epoch: 86
[ Sat Jan 25 18:15:42 2025 ] 	Mean training loss: 0.8389.  Mean training acc: 97.28%.
[ Sat Jan 25 18:15:42 2025 ] 	Learning Rate: 0.00003332
[ Sat Jan 25 18:15:42 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 18:15:42 2025 ] Eval epoch: 86
[ Sat Jan 25 18:15:54 2025 ] 	Mean test loss of 70 batches: 2.213951763084957.
[ Sat Jan 25 18:15:54 2025 ] 	Top1: 58.38%
[ Sat Jan 25 18:15:54 2025 ] 	Top5: 83.32%
[ Sat Jan 25 18:15:54 2025 ] Training epoch: 87
[ Sat Jan 25 18:24:33 2025 ] 	Mean training loss: 0.8368.  Mean training acc: 97.34%.
[ Sat Jan 25 18:24:33 2025 ] 	Learning Rate: 0.00003015
[ Sat Jan 25 18:24:33 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 18:24:33 2025 ] Eval epoch: 87
[ Sat Jan 25 18:24:45 2025 ] 	Mean test loss of 70 batches: 2.2164417794772557.
[ Sat Jan 25 18:24:45 2025 ] 	Top1: 57.89%
[ Sat Jan 25 18:24:45 2025 ] 	Top5: 83.17%
[ Sat Jan 25 18:24:45 2025 ] Training epoch: 88
[ Sat Jan 25 18:33:26 2025 ] 	Mean training loss: 0.8362.  Mean training acc: 97.35%.
[ Sat Jan 25 18:33:26 2025 ] 	Learning Rate: 0.00002721
[ Sat Jan 25 18:33:26 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 18:33:26 2025 ] Eval epoch: 88
[ Sat Jan 25 18:33:39 2025 ] 	Mean test loss of 70 batches: 2.2075363636016845.
[ Sat Jan 25 18:33:39 2025 ] 	Top1: 58.15%
[ Sat Jan 25 18:33:39 2025 ] 	Top5: 83.37%
[ Sat Jan 25 18:33:39 2025 ] Training epoch: 89
[ Sat Jan 25 18:42:16 2025 ] 	Mean training loss: 0.8342.  Mean training acc: 97.38%.
[ Sat Jan 25 18:42:16 2025 ] 	Learning Rate: 0.00002449
[ Sat Jan 25 18:42:16 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 18:42:16 2025 ] Eval epoch: 89
[ Sat Jan 25 18:42:29 2025 ] 	Mean test loss of 70 batches: 2.2087607894624983.
[ Sat Jan 25 18:42:29 2025 ] 	Top1: 58.54%
[ Sat Jan 25 18:42:29 2025 ] 	Top5: 83.49%
[ Sat Jan 25 18:42:29 2025 ] Training epoch: 90
[ Sat Jan 25 18:51:09 2025 ] 	Mean training loss: 0.8330.  Mean training acc: 97.45%.
[ Sat Jan 25 18:51:09 2025 ] 	Learning Rate: 0.00002199
[ Sat Jan 25 18:51:09 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 18:51:09 2025 ] Eval epoch: 90
[ Sat Jan 25 18:51:21 2025 ] 	Mean test loss of 70 batches: 2.2112481457846505.
[ Sat Jan 25 18:51:21 2025 ] 	Top1: 58.06%
[ Sat Jan 25 18:51:21 2025 ] 	Top5: 83.15%
[ Sat Jan 25 18:51:21 2025 ] Training epoch: 91
[ Sat Jan 25 19:00:00 2025 ] 	Mean training loss: 0.8321.  Mean training acc: 97.44%.
[ Sat Jan 25 19:00:00 2025 ] 	Learning Rate: 0.00001973
[ Sat Jan 25 19:00:00 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 19:00:00 2025 ] Eval epoch: 91
[ Sat Jan 25 19:00:12 2025 ] 	Mean test loss of 70 batches: 2.2094806500843593.
[ Sat Jan 25 19:00:12 2025 ] 	Top1: 58.34%
[ Sat Jan 25 19:00:12 2025 ] 	Top5: 83.48%
[ Sat Jan 25 19:00:12 2025 ] Training epoch: 92
[ Sat Jan 25 19:08:50 2025 ] 	Mean training loss: 0.8335.  Mean training acc: 97.38%.
[ Sat Jan 25 19:08:50 2025 ] 	Learning Rate: 0.00001770
[ Sat Jan 25 19:08:50 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 19:08:50 2025 ] Eval epoch: 92
[ Sat Jan 25 19:09:02 2025 ] 	Mean test loss of 70 batches: 2.2064993296350752.
[ Sat Jan 25 19:09:03 2025 ] 	Top1: 58.40%
[ Sat Jan 25 19:09:03 2025 ] 	Top5: 83.23%
[ Sat Jan 25 19:09:03 2025 ] Training epoch: 93
[ Sat Jan 25 19:17:41 2025 ] 	Mean training loss: 0.8313.  Mean training acc: 97.45%.
[ Sat Jan 25 19:17:41 2025 ] 	Learning Rate: 0.00001590
[ Sat Jan 25 19:17:41 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 19:17:41 2025 ] Eval epoch: 93
[ Sat Jan 25 19:17:54 2025 ] 	Mean test loss of 70 batches: 2.212448101384299.
[ Sat Jan 25 19:17:54 2025 ] 	Top1: 58.22%
[ Sat Jan 25 19:17:54 2025 ] 	Top5: 83.15%
[ Sat Jan 25 19:17:54 2025 ] Training epoch: 94
[ Sat Jan 25 19:26:33 2025 ] 	Mean training loss: 0.8315.  Mean training acc: 97.50%.
[ Sat Jan 25 19:26:33 2025 ] 	Learning Rate: 0.00001434
[ Sat Jan 25 19:26:33 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 19:26:33 2025 ] Eval epoch: 94
[ Sat Jan 25 19:26:45 2025 ] 	Mean test loss of 70 batches: 2.2106710042272297.
[ Sat Jan 25 19:26:45 2025 ] 	Top1: 58.32%
[ Sat Jan 25 19:26:45 2025 ] 	Top5: 83.17%
[ Sat Jan 25 19:26:45 2025 ] Training epoch: 95
[ Sat Jan 25 19:35:24 2025 ] 	Mean training loss: 0.8296.  Mean training acc: 97.57%.
[ Sat Jan 25 19:35:24 2025 ] 	Learning Rate: 0.00001302
[ Sat Jan 25 19:35:24 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 19:35:24 2025 ] Eval epoch: 95
[ Sat Jan 25 19:35:36 2025 ] 	Mean test loss of 70 batches: 2.2066860726901463.
[ Sat Jan 25 19:35:36 2025 ] 	Top1: 58.09%
[ Sat Jan 25 19:35:36 2025 ] 	Top5: 83.23%
[ Sat Jan 25 19:35:36 2025 ] Training epoch: 96
[ Sat Jan 25 19:44:16 2025 ] 	Mean training loss: 0.8300.  Mean training acc: 97.53%.
[ Sat Jan 25 19:44:16 2025 ] 	Learning Rate: 0.00001193
[ Sat Jan 25 19:44:16 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 19:44:16 2025 ] Eval epoch: 96
[ Sat Jan 25 19:44:28 2025 ] 	Mean test loss of 70 batches: 2.208191810335432.
[ Sat Jan 25 19:44:28 2025 ] 	Top1: 58.32%
[ Sat Jan 25 19:44:28 2025 ] 	Top5: 83.24%
[ Sat Jan 25 19:44:28 2025 ] Training epoch: 97
[ Sat Jan 25 19:53:08 2025 ] 	Mean training loss: 0.8260.  Mean training acc: 97.67%.
[ Sat Jan 25 19:53:08 2025 ] 	Learning Rate: 0.00001109
[ Sat Jan 25 19:53:08 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 19:53:08 2025 ] Eval epoch: 97
[ Sat Jan 25 19:53:20 2025 ] 	Mean test loss of 70 batches: 2.207553495679583.
[ Sat Jan 25 19:53:20 2025 ] 	Top1: 58.27%
[ Sat Jan 25 19:53:20 2025 ] 	Top5: 83.44%
[ Sat Jan 25 19:53:20 2025 ] Training epoch: 98
[ Sat Jan 25 20:01:58 2025 ] 	Mean training loss: 0.8278.  Mean training acc: 97.52%.
[ Sat Jan 25 20:01:58 2025 ] 	Learning Rate: 0.00001048
[ Sat Jan 25 20:01:58 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 20:01:58 2025 ] Eval epoch: 98
[ Sat Jan 25 20:02:10 2025 ] 	Mean test loss of 70 batches: 2.205833148956299.
[ Sat Jan 25 20:02:10 2025 ] 	Top1: 58.36%
[ Sat Jan 25 20:02:10 2025 ] 	Top5: 83.05%
[ Sat Jan 25 20:02:10 2025 ] Training epoch: 99
[ Sat Jan 25 20:10:51 2025 ] 	Mean training loss: 0.8267.  Mean training acc: 97.68%.
[ Sat Jan 25 20:10:51 2025 ] 	Learning Rate: 0.00001012
[ Sat Jan 25 20:10:51 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 20:10:51 2025 ] Eval epoch: 99
[ Sat Jan 25 20:11:03 2025 ] 	Mean test loss of 70 batches: 2.2062555057661872.
[ Sat Jan 25 20:11:03 2025 ] 	Top1: 58.18%
[ Sat Jan 25 20:11:03 2025 ] 	Top5: 83.01%
[ Sat Jan 25 20:11:03 2025 ] Training epoch: 100
[ Sat Jan 25 20:19:42 2025 ] 	Mean training loss: 0.8265.  Mean training acc: 97.63%.
[ Sat Jan 25 20:19:42 2025 ] 	Learning Rate: 0.00001000
[ Sat Jan 25 20:19:42 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Sat Jan 25 20:19:42 2025 ] Eval epoch: 100
[ Sat Jan 25 20:19:55 2025 ] 	Mean test loss of 70 batches: 2.209595140389034.
[ Sat Jan 25 20:19:55 2025 ] 	Top1: 58.22%
[ Sat Jan 25 20:19:55 2025 ] 	Top5: 82.96%
[ Sat Jan 25 20:20:07 2025 ] Best accuracy: 0.58968850698174
[ Sat Jan 25 20:20:07 2025 ] Epoch number: 71
[ Sat Jan 25 20:20:07 2025 ] Model name: ./output/original_48_CrossAttention/
[ Sat Jan 25 20:20:07 2025 ] Model total number of params: 2394108
[ Sat Jan 25 20:20:07 2025 ] Weight decay: 0.01
[ Sat Jan 25 20:20:07 2025 ] Base LR: 0.0005
[ Sat Jan 25 20:20:07 2025 ] Batch Size: 80
[ Sat Jan 25 20:20:07 2025 ] Test Batch Size: 80
[ Sat Jan 25 20:20:07 2025 ] seed: 1
